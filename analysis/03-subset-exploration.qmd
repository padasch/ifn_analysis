---
title: "Subset Exploration"
editor_options: 
  chunk_output_type: console
---

```{r message=FALSE, warning=FALSE}
source(here::here("R/_setup.R"))
```

# Data Cleaning
## Widen data to one tree per row
```{r}
# Get raw data
data <- suppressWarnings(f_get_raw_data_list())
l_raw_data <- data[[1]]
l_metadata <- data[[2]]

# Wrangle coordinates 
df_loc <- f_attach_wgs_coords_to_raw_placette(l_raw_data$placette)
```

```{r}
# Get tree sampling index
idx_tree  <- f_get_tree_index(l_raw_data)

# Get tree dataframe and attach indeces
df_tree <- 
  l_raw_data$arbre |>
  left_join(idx_tree, by = join_by(idp, a)) |> 
  mutate(
    tree_id  = paste0(idp, "_", a),
    visite = NA,
    visite = ifelse(revisit_state == "revisited" & campagne == visit_1, 1, visite),
    visite = ifelse(revisit_state == "revisited" & campagne == visit_2, 2, visite),
    visite = ifelse(revisit_state == "not_revisited", 1, visite),
    visite = ifelse(revisit_state == "newly_sampled", 2, visite)
    ) |>
  relocate(idp, a, tree_id, campagne, visite,
           visit_1, visit_2, revisit_state, veget, 
           veget5, where(is.numeric))
```

```{r, eval=FALSE}
# Make wide location dataset
# Get dataframes stating which variable is sampled how often and when
loc_vars  <- get_measurement_frequency_of_vars(df_loc,  "location")
tree_vars <- get_measurement_frequency_of_vars(df_tree, "tree")

# Widen dataframes
df_loc_wide  <- widen_dataframe(df_loc,  loc_vars,  "location")
df_tree_wide <- widen_dataframe(df_tree, tree_vars, "tree")

# Quality check for duplicates:
if (length(unique(df_loc_wide$idp)) != nrow(df_loc_wide)) {stop("QC FAILED!")}
if (length(unique(df_tree_wide$tree_id)) != nrow(df_tree_wide)) {stop("QC FAILED!")}
```

## Wrangle recruitment data
```{r, eval=FALSE}
# Correction for newly grown trees. Below, their state is assigned to their first
# measurement but that occurred during the second visit. To keep data consistent,
# we have to add the information on newly_sampled trees to the second visit

# Get index for newly sampled trees
idx <- which(df_tree_wide$revisit_state == "newly_sampled")

# Split datasets
df_split_new  <- df_tree_wide[idx, ]
df_split_keep <- df_tree_wide[-idx, ]

# Overwrite data so that the variables have the same meaning like revisited trees

# - Overwrite veget with veget5. veget is all "alive" for newly sampled trees,
#   because otherwise they would not have grown to be included in the census
df_split_new$veget5 <- df_split_new$veget
df_split_new$veget  <- "0"

# - Overwrite circumference growth
#   Making the assumption that C13 was = at first visit because 
df_split_new$c13_1 <- df_split_new$c13_2
df_split_new$c13_1 <- 0

# - Overwrite sampling campagnes and visits
df_split_new$campagne_1 <- df_split_new$campagne_2 - 5

df_split_new$visit_1 <- df_split_new$campagne_1
df_split_new$visit_2 <- df_split_new$campagne_2

df_split_new$visite_1 <- 1
df_split_new$visite_2 <- 2

# - No need to overwrite additional variables because they are all NA anyways
# df_split_new |> select(where(~!all(is.na(.)))) |> names()

# Update big dataframe
df_tree_wide_cleaned <- bind_rows(df_split_new, df_split_keep)
```

```{r, eval=FALSE}
# Combine and clean dataframes to one large wide one with one tree per row
vars_clean   <- c("idp", "visite_1", "visite_2", "campagne_1", "campagne_2")
df_loc_wide_fin  <- df_loc_wide  |> mutate(across(all_of(vars_clean), factor))
df_tree_wide_fin <- df_tree_wide_cleaned |> mutate(across(all_of(vars_clean), factor))

df_comb <- 
  left_join(
    df_tree_wide_fin, 
    df_loc_wide_fin, 
    by = c(vars_clean))

# Fixing some factorial variables
df_comb$campagne_1 <- as.double(as.character(df_comb$campagne_1))
df_comb$campagne_2 <- as.double(as.character(df_comb$campagne_2))

df_comb <- 
  df_comb |> 
  mutate(
    census_interval = paste0(campagne_1, "-", campagne_2),
    census_interval = as.factor(census_interval)
  )

# Save data
load_or_save_latest_file(df_comb, "save")
```

```{r}
# Load data
load_or_save_latest_file(df_comb, "load")
head(df_comb)
```

## Add tree-level information
### Status
```{r}
# Use df_tmp
df_tmp <- df_comb

# Get key-value dictionary
tree_state_dict <- get_tree_state_dictionary()

# Attach dictionary
df_tmp <- 
  
  # Take updated dataframe
  df_tmp |> 
  
  # Attach information on state of tree at first visit
  left_join(
    tree_state_dict |> 
      select(-mode_of_death) |> 
      rename(veget = ign_code,
             tree_state_1 = tree_state,
             alive_but_injured_1 = alive_but_injured),
    by = join_by(veget)) |> 
  
  # Attach information on state of tree at second visit
  left_join(
    tree_state_dict |> 
      rename(veget5 = ign_code,
             tree_state_2 = tree_state,
             alive_but_injured_2 = alive_but_injured),
    by = join_by(veget5)) 

# Add info on tree state change
df_comb_tree_state <- 
  df_tmp |> 
  mutate(
    tree_state_1      = ifelse(revisit_state == "newly_sampled", "new", tree_state_1),
    tree_state_change = as.factor(paste0(tree_state_1, "_", tree_state_2))
    ) 
```

### Species
```{r}
# Use df_tmp
df_tmp <- df_comb_tree_state

# Get key-class dictionary
tree_class_dict <- get_tree_class_dictionary(l_raw_data, l_metadata)

# Attach dictionary
df_comb_tree_class <- 
  df_tmp |> 
  left_join(tree_class_dict |> 
              rename(espar = lvl_french) |> 
              mutate(tree_class = as.factor(tree_class)),
            by = join_by(espar))
```

### Size & age class
```{r}
# Define criteria for age breaks
age_max     <- 100
age_stepsize <- 15

height_max     <- 25
height_stepsize <- 5
  
age_breaks     <- c(seq(0, age_max, age_stepsize), Inf)
age_breaks_txt <- c(paste0("<", age_breaks[2:(length(age_breaks) - 1)], "yrs"),
                    paste0("≥", age_breaks[(length(age_breaks) - 1)], "yrs"))

height_breaks     <- c(seq(0, height_max, height_stepsize), Inf)
height_breaks_txt <- c(paste0("<", height_breaks[2:(length(height_breaks) - 1)], "m"),
                       paste0("≥", height_breaks[(length(height_breaks) - 1)], "m"))

df_plus_age_height_classes <- 
  df_comb_tree_class |> 
  mutate(
    age_class    = cut(age13,  age_breaks,    age_breaks_txt, include.lowest = TRUE),
    height_class = cut(htot,   height_breaks, height_breaks_txt, include.lowest = TRUE)
    )
```

### Add Shadow Growth of Circumference
#### Cut Trees
```{r}
# Create temporary df for this section
df_tmp <- df_plus_age_height_classes

# Split datasets into cut and not cut
idx <- which(df_tmp$tree_state_2 == "cut")

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5/2,
           shadow_growth = "yes") |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_cut <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = "no")
      )
} else {
  df_comb_shadow_cut <- df_tmp
}
```

#### Not re-measured dead trees
```{r}
df_tmp <- df_comb_shadow_cut

# Create subset for not re-measured dead trees
idx <- which(df_tmp$tree_state_2 == "dead" & is.na(df_tmp$c13_2))

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5/2,
           shadow_growth = "yes") |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_dead <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = "no"))
} else {
  df_comb_shadow_dead <- df_tmp
}
```

#### Not re-measured alive trees
```{r}
df_tmp <- df_comb_shadow_dead

# Create subset for not re-measured alive trees
idx <- which(df_tmp$tree_state_2 == "alive" & is.na(df_tmp$c13_2))

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5,
           shadow_growth = "yes") |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_alive <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = "no"))
} else {
  df_comb_shadow_alive <- df_tmp
}
```

### Calculate ∆ C13, DBH, BA
```{r}
# Create df_tmp
df_tmp <- df_comb_shadow_alive

# Attach size related variables
df_size_change <- 
  df_tmp |> 
  # Attach size related variables
  mutate(
    # Add plot size variable (plot of radius 25m)
    plot_area = 25^2 * pi / 10^5, # (25m)^2 * pi / 10000 [m^2/ha] = [ha]
    
    # C13
    c13_change_abs_yr  = ( c13_2 - c13_1 ) / 5,
    c13_change_perc_yr =  c13_change_abs_yr / c13_1 * 100,
    
    # Diameter
    dbh_1              = c13_1 / pi,
    dbh_2              = c13_2 / pi,
    dbh_change_abs_yr  = ( dbh_2 - dbh_1 ) / 5,
    dbh_change_perc_yr =  dbh_change_abs_yr / dbh_1 * 100,
    
    # Basal Area
    ba_1               = pi * ( dbh_1 / 2 ) ^ 2 / plot_area,
    ba_2               = pi * ( dbh_2 / 2 ) ^ 2 / plot_area,
    ba_change_abs_yr   = ( ba_2 - ba_1 ) / 5,
    ba_change_perc_yr  =  ba_change_abs_yr / ba_1 * 100,
    
    # Growth rates
    avg_growth_height_meter_per_yr = htot / age13,
    avg_growth_ba_per_year         = ba_1 / age13
  ) |> 
  select(-plot_area) |> 
  
  # Replace changes in percent with NA for newly sampled trees because their initial size is 
  # assumed to be zero and dividing by zero gives non-sense infinity.
  mutate(
    c13_change_perc_yr = ifelse(c13_change_perc_yr == Inf, NA, c13_change_perc_yr), 
    dbh_change_perc_yr = ifelse(dbh_change_perc_yr == Inf, NA, dbh_change_perc_yr), 
    ba_change_perc_yr  = ifelse(ba_change_perc_yr  == Inf, NA, ba_change_perc_yr)
  )
```

## Add site-level information

```{r}
df_before_adding_vars <- df_size_change

# Aggregate data to plot level to speed things up
df_tmp <-
  df_before_adding_vars |> 
  select(idp, uta1, uta2, autut_1, autut_2, utip_1, utip_2, csa_1, csa_2) |> 
  distinct() |> 
  mutate(
    xxx = ifelse(
      (is.na(uta1) &
      is.na(uta2) &
      is.na(autut_1) &
      is.na(autut_2) &
      is.na(utip_1) &
      is.na(utip_2) &
      is.na(csa_1) &
      is.na(csa_2)),
      "drop",
      "keep"
    )
  ) |> 
  filter(xxx == "keep") |> 
  select(-xxx)
```

```{r}
# Land Use Classification
df_landuse <- 
  df_tmp |> 
  rowwise() |> 
  mutate(
    uta1         = classify_uta(uta1),
    uta2         = classify_uta(uta2),
    autut_1      = classify_autut(autut_1),
    autut_2      = classify_autut(autut_2),
    utip_1       = classify_utip(utip_1),
    utip_2       = classify_utip(utip_2)
    )

df_landuse_merged <- 
  df_landuse |> 
  mutate(
    land_use = classify_land_use(uta1, uta2, utip_1, utip_2, autut_1, autut_2),
    land_use = as.factor(land_use)
  )

# ______________________________________________________________________________
# Land Use Change
df_change <- 
  df_landuse_merged |> 
  rowwise() |> 
  mutate(
    land_use_change = classify_land_use_intensity_change(land_use, autut_2),
    cover_change    = classify_tree_cover_change(csa_1, csa_2),
    land_use_change = as.factor(land_use_change),
    cover_change    = as.factor(cover_change)
  ) |> 
  select(idp, land_use, land_use_change, cover_change)

df_luc_final <- 
  left_join(
    df_before_adding_vars,
    df_change,
    by = join_by(idp)
  )

# ______________________________________________________________________________
# Natural Impact 
# TODO: Is this relevant at all or is the data not good enough as it is?

# ______________________________________________________________________________
# Human Impact
df_tmp <-
  df_luc_final |> 
  select(idp, prelev5, def5, gest, elag, nlisi5, instp5, andain) |> 
  distinct() |> 
  mutate(
    xxx = ifelse(
      (is.na(prelev5) &
        is.na(def5) &
        is.na(gest) &
        is.na(elag) &
        is.na(nlisi5) &
        is.na(instp5) &
        is.na(andain)),
      "drop",
      "keep"
    )
  ) |> 
  filter(xxx == "keep") |> 
  select(-xxx)

df_tmp_human <- 
  df_tmp |> 
  rowwise() |> 
  mutate(
    tmp = classify_human_activity(prelev5, def5, gest, elag, nlisi5, instp5, andain),
  ) |> 
  unnest(tmp)

df_fin_human <- 
  left_join(
    df_luc_final,
    df_tmp_human,
    by = join_by(idp, prelev5, def5, gest, elag, nlisi5, instp5, andain)
  )

# ______________________________________________________________________________
# Geographic Information
df_tmp <- df_fin_human
df_geo <- df_tmp |> mutate(gre = substr(ser, 1,1))

# ______________________________________________________________________________
# Final df
df_after_adding_vars <- df_geo
```

```{r}
columns_only_in_new_df   <- setdiff(names(df_after_adding_vars), names(df_before_adding_vars))
columns_only_in_final_df <- setdiff(names(df_before_adding_vars), names(df_after_adding_vars))
columns_not_in_both      <- base::union(columns_only_in_new_df, columns_only_in_final_df)

# Print or use the result as needed
message("> New variables added to dataset: \n  ", paste0(columns_not_in_both, collapse = ", "))
```

## Add other NFI Data
```{r}
df_tmp <- df_after_adding_vars
l_raw_data |> names()

# Add information on tree coverage
df_tmp <- 
  df_tmp |> 
  left_join(
    l_raw_data$couvert |> 
      filter(strate == "R") |> # Stratum must be recensable
      rename(campagne_1 = campagne, espar = espar_c),
    by = join_by(campagne_1, idp, espar)
  )

# Add information on ecology
df_tmp <- 
  df_tmp |> 
  left_join(
    l_raw_data$ecologie |> select(-campagne),
    by = join_by(idp)
  ) 

# - l_raw_data$habitat
#   not really useful, maybe the variable `hab` but there are multiple values for the same site
#   and thus an aggregation mechanism would be needed. Data unlikely of explanatory value.
# - l_raw_data$flore
#   may hold interesting data on the influence from invasive species but the data structure right
#   now is not useful and would needed to be aggregated to a new variable. Data unlikely of explanatory value.
# - l_raw_data$bois_mort
#   Data unlikely of explanatory value.

df_allnfidata <- df_tmp
```

## Check encoding of variables
```{r}
df_tmp <- df_allnfidata

# ______________________________________________________________________________
# Encode all characters as factors
character_vars <- df_tmp |> select_if(is.character) |> names()
message("> Character variables in the dataset turned into factors:\n  ", paste0(character_vars, sep = "\n  "))
for (var in character_vars) {df_tmp[[var]] <- as.factor(df_tmp[[var]])}
df_factorised <- df_tmp

# ______________________________________________________________________________
# Turn falsely numerical into factors
# df_factorised |> select(where(is.numeric)) |> names() |> paste(collapse = '",\n"') |> cat()

turn_to_factor <- 
  c(
    # "visit_1",
    # "visit_2",
    # "hrb",
    # "campagne_1",
    # "campagne_2",
    # "c13_1",
    # "c13_2",
    "q1",
    "q2",
    "q3",
    # "age13",
    # "age",
    # "c0",
    # "htot",
    # "hdec",
    "ddec",
    "lfsd",
    # "v",
    # "w",
    "r",
    # "ir5",
    # "ir1",
    # "lon_fr",
    # "lat_fr",
    "anpyr",
    # "lat",
    # "lon",
    "bplant_1",
    "bplant_2",
    "iplant_1",
    "iplant_2",
    "videpeuplier_1",
    "videpeuplier_2"
    # "elisi",
    # "c13_change_abs_yr",
    # "c13_change_perc_yr",
    # "dbh_1",
    # "dbh_2",
    # "dbh_change_abs_yr",
    # "dbh_change_perc_yr",
    # "ba_1",
    # "ba_2",
    # "ba_change_abs_yr",
    # "ba_change_perc_yr",
    # "avg_growth_height_meter_per_yr",
    # "avg_growth_ba_per_year",
    # "tca",
    # "tcl",
    # "expo",
    # "msud",
    # "masque",
    # "pent2",
    # "prof1",
    # "prof2"
  )

df_tmp <- df_factorised |> mutate(across(all_of(turn_to_factor), as.factor))

# ______________________________________________________________________________
# Check factors with more than 200 lvls, which should likely be numerical values!
#   Should only return idp and tree_id
# df_tmp |>
#   select_if(is.factor)  |>
#   summarise(across(everything(), ~sum(nlevels(.)) > 50))  |>
#   gather()  |>
#   filter(value)  |>
#   pull(key)
# 
# df_tmp |>
#   select_if(is.factor)  |>
#   summarise(across(everything(), ~sum(nlevels(.)) == 11))  |>
#   gather()  |>
#   filter(value)  |>
#   pull(key)

df_cleaned_encoding <- df_tmp
```

### Save RDS
```{r}
nfi_dataset_raw <- df_cleaned_encoding
load_or_save_latest_file(nfi_dataset_raw, "save")
```

## Create final dataset for analysis
```{r}
filter_raw_nfi_data() # does: load_or_save_latest_file(nfi_dataset_for_analysis, "save")
```

# Visuals
```{r}
# Code adapted from: 
# https://stackoverflow.com/questions/35921590/leaflet-on-r-how-to-create-layers-and-colors-for-each-factor-level-in-dataframe

load_or_save_latest_file(nfi_dataset_for_analysis, "load")
df <- 
  nfi_dataset_for_analysis |>
  mutate(campagne_1 = as.double(as.character(campagne_1))) |> 
  filter(campagne_1 > 2009) |> 
  select(lat, lon, campagne_1) |> 
  distinct()

groups     <-  as.character(unique(df$campagne_1))
groups_col <-  colorFactor(palette = "viridis", domain = df$campagne_1)

map <- 
  leaflet(df) |> 
  addProviderTiles(
    providers$Esri.WorldImagery,
    group = "World Imagery") |>
  addProviderTiles(
    providers$Esri.WorldTopoMap, 
    group = "World Topo")

for (g in groups){
  df_i <-  df |> filter(campagne_1 == g)
  
  map <- 
    map |> 
    addCircleMarkers(
      data = df_i, 
      lng = ~lon, 
      lat = ~lat, 
      color = ~groups_col(campagne_1),
      group = g, 
      label = ~paste("Status: ", campagne_1),
      opacity = 0.9)
}

map |> 
  addLayersControl(
    overlayGroups = groups,
    baseGroups = c("World Imagery", "World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE)) |> 
  # addRectangles(
  #   lng1 = l_subreg$min_lon, 
  #   lat1 = l_subreg$min_lat,
  #   lng2 = l_subreg$max_lon, 
  #   lat2 = l_subreg$max_lat,
  #   color = "black",
  #   fillColor = "transparent",
  #   opacity = 1
  # ) |> 
  addLegend(
    pal = groups_col,
    values = groups,
    title = "First Visit",
    position = "topleft") |> 
  addScaleBar()
```

