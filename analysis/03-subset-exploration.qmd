---
title: "Subset Exploration"
editor_options: 
  chunk_output_type: inline
---

```{r message=FALSE, warning=FALSE}
source(here::here("R/_setup.R"))
```

```{r}
compare_dataset_dims <- function(df1, df2){
  cat("df1: ", dim(df1),
      "\ndf2: ", dim(df2))
}
```

# Data Cleaning
## Widen data to one tree per row
```{r}
# Get raw data
data <- suppressWarnings(f_get_raw_data_list())
l_raw_data <- data[[1]]
l_metadata <- data[[2]]

# Wrangle coordinates 
df_loc <- f_attach_wgs_coords_to_raw_placette(l_raw_data$placette)
```

```{r}
# Get tree sampling index
idx_tree  <- f_get_tree_index(l_raw_data)

# Get tree dataframe and attach indeces
df_tree <- 
  l_raw_data$arbre |>
  left_join(idx_tree, by = join_by(idp, a)) |> 
  mutate(
    tree_id  = paste0(idp, "_", a),
    visite = NA,
    visite = ifelse(revisit_state == "revisited" & campagne == visit_1, 1, visite),
    visite = ifelse(revisit_state == "revisited" & campagne == visit_2, 2, visite),
    visite = ifelse(revisit_state == "not_revisited", 1, visite),
    visite = ifelse(revisit_state == "newly_sampled", 2, visite)
    ) |>
  relocate(idp, a, tree_id, campagne, visite,
           visit_1, visit_2, revisit_state, veget, 
           veget5, where(is.numeric))
```

```{r, eval=FALSE}
# Make wide location dataset
# Get dataframes stating which variable is sampled how often and when
loc_vars  <- get_measurement_frequency_of_vars(df_loc,  "location")
tree_vars <- get_measurement_frequency_of_vars(df_tree, "tree")

# Widen dataframes
df_loc_wide  <- widen_dataframe(df_loc,  loc_vars,  "location")
df_tree_wide <- widen_dataframe(df_tree, tree_vars, "tree")

# Quality check for duplicates:
if (length(unique(df_loc_wide$idp)) != nrow(df_loc_wide)) {stop("QC FAILED!")}
if (length(unique(df_tree_wide$tree_id)) != nrow(df_tree_wide)) {stop("QC FAILED!")}
```

## Wrangle recruitment data
```{r, eval=FALSE}
# Correction for newly grown trees. Below, their state is assigned to their first
# measurement but that occurred during the second visit. To keep data consistent,
# we have to add the information on newly_sampled trees to the second visit

# Get index for newly sampled trees
idx <- which(df_tree_wide$revisit_state == "newly_sampled")

# Split datasets
df_split_new  <- df_tree_wide[idx, ]
df_split_keep <- df_tree_wide[-idx, ]

# Overwrite data so that the variables have the same meaning like revisited trees

# - Overwrite veget with veget5. veget is all "alive" for newly sampled trees,
#   because otherwise they would not have grown to be included in the census
df_split_new$veget5 <- df_split_new$veget
df_split_new$veget  <- "0"

# - Overwrite circumference growth
#   Making the assumption that C13 was = at first visit because 
df_split_new$c13_1 <- df_split_new$c13_2
df_split_new$c13_1 <- 0

# - Overwrite sampling campagnes and visits
df_split_new$campagne_1 <- df_split_new$campagne_2 - 5

df_split_new$visit_1 <- df_split_new$campagne_1
df_split_new$visit_2 <- df_split_new$campagne_2

df_split_new$visite_1 <- 1
df_split_new$visite_2 <- 2

# - No need to overwrite additional variables because they are all NA anyways
# df_split_new |> select(where(~!all(is.na(.)))) |> names()

# Update big dataframe
df_tree_wide_cleaned <- bind_rows(df_split_new, df_split_keep)
```

```{r, eval=FALSE}
# Combine and clean dataframes to one large wide one with one tree per row
vars_clean   <- c("idp", "visite_1", "visite_2", "campagne_1", "campagne_2")
df_loc_wide_fin  <- df_loc_wide  |> mutate(across(all_of(vars_clean), factor))
df_tree_wide_fin <- df_tree_wide_cleaned |> mutate(across(all_of(vars_clean), factor))

df_comb <- 
  left_join(
    df_tree_wide_fin, 
    df_loc_wide_fin, 
    by = c(vars_clean))

# Fixing some factorial variables
df_comb$campagne_1 <- as.double(as.character(df_comb$campagne_1))
df_comb$campagne_2 <- as.double(as.character(df_comb$campagne_2))

df_comb <- 
  df_comb |> 
  mutate(
    census_interval = paste0(campagne_1, "-", campagne_2),
    census_interval = as.factor(census_interval)
  )

# Save data
load_or_save_latest_file(df_comb, "save")
```

```{r}
# Load data
df_comb <- load_or_save_latest_file(df_comb, "load")
head(df_comb)
dim(df_comb)
```

## âš ï¸ DEBUG
```{r}
if (FALSE) {
  message("RUNNING ON REDUCED DATASET!!!")
  set.seed(1)
  df_comb <- df_comb |> filter(between(campagne_1, 2010, 2016))
  df_comb <- df_comb |> slice_sample(n = round(nrow(df_comb) * 0.05))
}
```


## TREE-LEVEL
### Status
```{r}
# Use df_tmp
df_tmp <- df_comb

# Get key-value dictionary
tree_state_dict <- get_tree_state_dictionary()

# Attach dictionary
df_tmp <- 
  
  # Take updated dataframe
  df_tmp |> 
  
  # Attach information on state of tree at first visit
  left_join(
    tree_state_dict |> 
      select(-mode_of_death) |> 
      rename(veget = ign_code,
             tree_state_1 = tree_state,
             alive_but_injured_1 = alive_but_injured),
    by = join_by(veget)) |> 
  
  # Attach information on state of tree at second visit
  left_join(
    tree_state_dict |> 
      rename(veget5 = ign_code,
             tree_state_2 = tree_state,
             alive_but_injured_2 = alive_but_injured),
    by = join_by(veget5)) 

# Add info on tree state change
df_comb_tree_state <- 
  df_tmp |> 
  mutate(
    tree_state_1      = ifelse(revisit_state == "newly_sampled", "new", tree_state_1),
    tree_state_change = as.factor(paste0(tree_state_1, "_", tree_state_2))
    )

compare_dataset_dims(df_comb, df_comb_tree_state)
```

### Species
```{r}
# Use df_tmp
df_tmp <- df_comb_tree_state

# Get key-class dictionary
tree_class_dict <- get_tree_class_dictionary(l_raw_data, l_metadata)

# Attach dictionary
df_comb_tree_class <- 
  df_tmp |> 
  left_join(tree_class_dict |> 
              rename(espar = lvl_french) |> 
              mutate(tree_class = as.factor(tree_class)),
            by = join_by(espar))

# Reduce species information in NFI to number lvl
# Take espar as vector
espar <- df_comb_tree_class$espar

# Extracting only the numbers
numbers <- espar %>% 
  str_extract_all(pattern = "\\d+") %>% 
  map(~ if (length(.) > 0) as.numeric(.[1]) else NA) %>%
  unlist()

df_comb_tree_class$espar_red <- as.factor(numbers)

compare_dataset_dims(df_comb_tree_state, df_comb_tree_class)
```

# ðŸš§ 2024-01-07
> Today, I removed the following calculations to speed this up and transition to python!

Removed:
  - Size and Age Class
  - Tree Growth
  - Shadow Growth
  - Forest Structure
  
Keeping for now:
  - Land Use
  - Human Impact
  - Geographic Information (adding WGS84 coordinates)
  - Other NFI Data
  
```{r}
# Debug shortcut
df_after_adding_site_information_forest <- df_comb_tree_class
```

### Land Use

```{r}
df_before_adding_site_level_vars <- df_after_adding_site_information_forest

# Aggregate data to plot level to speed things up
df_tmp <-
  df_before_adding_site_level_vars |> 
  select(idp, uta1, uta2, autut_1, autut_2, utip_1, utip_2, csa_1, csa_2) |> 
  distinct() |> 
  mutate(
    xxx = ifelse(
      (is.na(uta1) &
      is.na(uta2) &
      is.na(autut_1) &
      is.na(autut_2) &
      is.na(utip_1) &
      is.na(utip_2) &
      is.na(csa_1) &
      is.na(csa_2)),
      "drop",
      "keep"
    )
  ) |> 
  filter(xxx == "keep") |> 
  select(-xxx)
```

```{r}
# Land Use Classification
df_landuse <- 
  df_tmp |> 
  rowwise() |> 
  mutate(
    uta1         = classify_uta(uta1),
    uta2         = classify_uta(uta2),
    autut_1      = classify_autut(autut_1),
    autut_2      = classify_autut(autut_2),
    utip_1       = classify_utip(utip_1),
    utip_2       = classify_utip(utip_2)
    )

df_landuse_merged <- 
  df_landuse |> 
  mutate(
    land_use = classify_land_use(uta1, uta2, utip_1, utip_2, autut_1, autut_2),
    land_use = as.factor(land_use)
  )

# ______________________________________________________________________________
# Land Use Change
df_change <- 
  df_landuse_merged |> 
  rowwise() |> 
  mutate(
    land_use_change = classify_land_use_intensity_change(land_use, autut_2),
    cover_change    = classify_tree_cover_change(csa_1, csa_2),
    land_use_change = as.factor(land_use_change),
    cover_change    = as.factor(cover_change)
  ) |> 
  select(idp, land_use, land_use_change, cover_change)

df_luc_final <- 
  left_join(
    df_before_adding_site_level_vars,
    df_change,
    by = join_by(idp)
  )
```

### Human Impact
```{r}
# ______________________________________________________________________________
# Human Impact
df_tmp <-
  df_luc_final |> 
  select(idp, prelev5, def5, gest, elag, nlisi5, instp5, andain) |> 
  distinct() |> 
  mutate(
    xxx = ifelse(
      (is.na(prelev5) &
        is.na(def5) &
        is.na(gest) &
        is.na(elag) &
        is.na(nlisi5) &
        is.na(instp5) &
        is.na(andain)),
      "drop",
      "keep"
    )
  ) |> 
  filter(xxx == "keep") |> 
  select(-xxx)

df_tmp_human <- 
  df_tmp |> 
  rowwise() |> 
  mutate(
    tmp = classify_human_activity(prelev5, def5, gest, elag, nlisi5, instp5, andain),
  ) |> 
  unnest(tmp)

df_fin_human <- 
  left_join(
    df_luc_final,
    df_tmp_human,
    by = join_by(idp, prelev5, def5, gest, elag, nlisi5, instp5, andain)
  )

compare_dataset_dims(df_before_adding_site_level_vars, df_luc_final)
```

### Geographic Information
```{r}
# Geographic Information
df_tmp <- df_fin_human
df_geo <- df_tmp |> mutate(gre = substr(ser, 1,1))

compare_dataset_dims(df_fin_human, df_geo)
```

### QC
```{r}
# Final dataframe after adding site level vars to ensure connection to code below:
df_after_adding_site_level_vars <- df_geo
compare_dataset_dims(df_before_adding_site_level_vars, df_after_adding_site_level_vars)
```

```{r}
# columns_only_in_new_df   <- setdiff(names(df_after_adding_site_level_vars), names(df_before_adding_site_information))
# columns_only_in_final_df <- setdiff(names(df_before_adding_site_information), names(df_after_adding_site_level_vars))
# columns_not_in_both      <- base::union(columns_only_in_new_df, columns_only_in_final_df)
# 
# # Print or use the result as needed
# message("> New variables added to dataset: \n  - ", paste0(columns_not_in_both, collapse = "\n  - "))
```

## Add other NFI Data
```{r}
df_tmp <- df_after_adding_site_level_vars
l_raw_data |> names()

# Add information on tree coverage (data comes aggregated per nfi species per plot)
df_couvert <- 
  df_tmp |> 
  left_join(
    l_raw_data$couvert |> 
      filter(strate == "R") |> # Stratum must be recensable
      rename(campagne_1 = campagne, espar = espar_c),
    by = join_by(campagne_1, idp, espar)
  )

# Extract location-level information from species-level tree coverage data
## 2024-01-07 SKIPPING THIS FOR NOW
# stop("the next lines cause error for some reason...")
# df_llcover <-
#   df_couvert |> 
#   select(idp, espar_red, tca, tcl) |> 
#   distinct() |> 
#   nest(data = -idp) |> 
#   mutate(
#     dominant_tca = map(data, ~get_dominant_factor_per_plot(.,group_var = "tca"),.progress = TRUE),
#     dominant_tcl = map(data, ~get_dominant_factor_per_plot(.,group_var = "tcl"),.progress = TRUE)
#   ) |> 
#   unnest(c(dominant_tca, dominant_tcl)) |> 
#   select(-data)
# 
# df_couvert_merged <- 
#   df_couvert |> 
#   left_join(df_llcover, by = join_by("idp"))
# END SKIP
df_couvert_merged <- df_couvert
compare_dataset_dims(df_couvert, df_couvert_merged)

# Add information on ecology
df_ecology <- 
  df_couvert_merged |> 
  left_join(
    l_raw_data$ecologie |> select(-campagne),
    by = join_by(idp)
  ) 

compare_dataset_dims(df_ecology, df_couvert_merged)

# - l_raw_data$habitat
#   not really useful, maybe the variable `hab` but there are multiple values for the same site
#   and thus an aggregation mechanism would be needed. Data unlikely of explanatory value.
# - l_raw_data$flore
#   may hold interesting data on the influence from invasive species but the data structure right
#   now is not useful and would needed to be aggregated to a new variable. Data unlikely of explanatory value.
# - l_raw_data$bois_mort
#   Data unlikely of explanatory value.

df_allnfidata <- df_ecology

compare_dataset_dims(df_after_adding_site_level_vars, df_allnfidata)
```

## Final QC
```{r}
compare_dataset_dims(df_comb, df_allnfidata)
```

## Save RDS
```{r}
nfi_dataset_raw <- df_allnfidata
load_or_save_latest_file(nfi_dataset_raw, "save")
```

## Create final dataset for analysis
```{r}
# load_or_save_latest_file(nfi_dataset_raw, "load")
nfi_dataset_for_analysis <- filter_raw_nfi_data(nfi_dataset_raw)
load_or_save_latest_file(nfi_dataset_for_analysis, "save")
message("\n  ... Done! Saved nfi_dataset_for_analysis.")
```

---

```{r}
xxx <- load_or_save_latest_file(nfi_dataset_for_analysis, "load")
xxx |> 
  nest(data = -idp) |>
  mutate(mortality = map_lgl(data, ~filter(., tree_state_change == "alive_dead") |> nrow() > 0)) |>
  filter(mortality) |> 
  nrow()
```

# Visuals
```{r}
# Code adapted from: 
# https://stackoverflow.com/questions/35921590/leaflet-on-r-how-to-create-layers-and-colors-for-each-factor-level-in-dataframe

load_or_save_latest_file(nfi_dataset_for_analysis, "load")
df <- 
  nfi_dataset_for_analysis |>
  mutate(campagne_1 = as.double(as.character(campagne_1))) |> 
  filter(campagne_1 > 2009) |> 
  select(lat, lon, campagne_1) |> 
  distinct()

groups     <-  as.character(unique(df$campagne_1))
groups_col <-  colorFactor(palette = "viridis", domain = df$campagne_1)

map <- 
  leaflet(df) |> 
  addProviderTiles(
    providers$Esri.WorldImagery,
    group = "World Imagery") |>
  addProviderTiles(
    providers$Esri.WorldTopoMap, 
    group = "World Topo")

for (g in groups){
  df_i <-  df |> filter(campagne_1 == g)
  
  map <- 
    map |> 
    addCircleMarkers(
      data = df_i, 
      lng = ~lon, 
      lat = ~lat, 
      color = ~groups_col(campagne_1),
      group = g, 
      label = ~paste("Status: ", campagne_1),
      opacity = 0.9)
}

map |> 
  addLayersControl(
    overlayGroups = groups,
    baseGroups = c("World Imagery", "World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE)) |> 
  # addRectangles(
  #   lng1 = l_subreg$min_lon, 
  #   lat1 = l_subreg$min_lat,
  #   lng2 = l_subreg$max_lon, 
  #   lat2 = l_subreg$max_lat,
  #   color = "black",
  #   fillColor = "transparent",
  #   opacity = 1
  # ) |> 
  addLegend(
    pal = groups_col,
    values = groups,
    title = "First Visit",
    position = "topleft") |> 
  addScaleBar()
```

