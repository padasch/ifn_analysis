---
title: "Subset Exploration"
editor_options: 
  chunk_output_type: console
---

```{r message=FALSE, warning=FALSE}
# Source files and packages
source(here::here("R/_setup.R"))

# Create today's figure directory
dir_tmp <- get_todays_file_directory("figures")
```

## Summary

-   For this subset analysis, we will focus only on sites that were revisited and that have explicit information on the change in circumference (re-measured circumference or indicator why circumference was not re-measured).

## Create Clean Dataset

### Expand data to one tree per row
```{r}
# Get raw data
data <- suppressWarnings(f_get_raw_data_list())
l_raw_data <- data[[1]]
l_metadata <- data[[2]]

# Wrangle coordinates 
df_loc <- f_attach_wgs_coords_to_raw_placette(l_raw_data$placette)
```

```{r}
# Get tree sampling index
idx_tree  <- f_get_tree_index(l_raw_data)

# Get tree dataframe and attach indeces
df_tree <- 
  l_raw_data$arbre |>
  left_join(idx_tree, by = join_by(idp, a)) |> 
  mutate(
    tree_id  = paste0(idp, "_", a),
    visite = NA,
    visite = ifelse(revisit_state == "revisited" & campagne == visit_1, 1, visite),
    visite = ifelse(revisit_state == "revisited" & campagne == visit_2, 2, visite),
    visite = ifelse(revisit_state == "not_revisited", 1, visite),
    visite = ifelse(revisit_state == "newly_sampled", 2, visite)
    ) |>
  relocate(idp, a, tree_id, campagne, visite,
           visit_1, visit_2, revisit_state, veget, 
           veget5, where(is.numeric))
```

```{r, eval=FALSE}
# Make wide location dataset
# Get dataframes stating which variable is sampled how often and when
loc_vars  <- get_measurement_frequency_of_vars(df_loc,  "location")
tree_vars <- get_measurement_frequency_of_vars(df_tree, "tree")

# Widen dataframes
df_loc_wide  <- widen_dataframe(df_loc,  loc_vars,  "location")
df_tree_wide <- widen_dataframe(df_tree, tree_vars, "tree")

# Quality check for duplicates:
if (length(unique(df_loc_wide$idp)) != nrow(df_loc_wide)) {stop("QC FAILED!")}
if (length(unique(df_tree_wide$tree_id)) != nrow(df_tree_wide)) {stop("QC FAILED!")}
```

### Recruitment - Merge Data Structures
```{r, eval=FALSE}
# Correction for newly grown trees. Below, their state is assigned to their first
# measurement but that occurred during the second visit. To keep data consistent,
# we have to add the information on newly_sampled trees to the second visit

# Get index for newly sampled trees
idx <- which(df_tree_wide$revisit_state == "newly_sampled")

# Split datasets
df_split_new  <- df_tree_wide[idx, ]
df_split_keep <- df_tree_wide[-idx, ]

# Overwrite data so that the variables have the same meaning like revisited trees

# - Overwrite veget with veget5 (veget is all "alive" for newly sampled trees),
# because otherwise they would not have grown to be included in the census
df_split_new$veget5 <- df_split_new$veget
df_split_new$veget  <- "0"

# - Overwrite circumference growth
df_split_new$c13_1 <- df_split_new$c13_2
df_split_new$c13_1 <- 0

# - Overwrite sampling campagnes and visits
df_split_new$campagne_1 <- df_split_new$campagne_2 - 5

df_split_new$visit_1 <- df_split_new$campagne_1
df_split_new$visit_2 <- df_split_new$campagne_2

df_split_new$visite_1 <- 1
df_split_new$visite_2 <- 2

# - No need to overwrite additional variables because they are all NA anyways
# df_split_new |> select(where(~!all(is.na(.)))) |> names()

# Update big dataframe
df_tree_wide_cleaned <- bind_rows(df_split_new, df_split_keep)
```

```{r, eval=FALSE}
# Combine and clean dataframes to one large wide one with one tree per row
vars_clean   <- c("idp", "visite_1", "visite_2", "campagne_1", "campagne_2")
df_loc_wide_fin  <- df_loc_wide  |> mutate(across(all_of(vars_clean), factor))
df_tree_wide_fin <- df_tree_wide_cleaned |> mutate(across(all_of(vars_clean), factor))

df_comb <- 
  left_join(
    df_tree_wide_fin, 
    df_loc_wide_fin, 
    by = c(vars_clean))

# Fixing some factorial variables
df_comb$campagne_1 <- as.double(as.character(df_comb$campagne_1))
df_comb$campagne_2 <- as.double(as.character(df_comb$campagne_2))

# Save data
load_or_save_latest_file("df_comb", "save")
```

```{r}
# Load data
load_or_save_latest_file("df_comb", "load")
head(df_comb)
```

### Attach tree information
#### Attach tree state information
```{r}
# Get key-value dictionary
tree_state_dict <- get_tree_state_dictionary()

# Attach dictionary
df_comb_tree_state <- 
  
  # Take updated dataframe
  df_comb |> 
  
  # Attach information on state of tree at first visit
  left_join(
    tree_state_dict |> 
      rename(veget = ign_code,
             tree_state_1 = tree_state,
             alive_but_injured_1 = alive_but_injured,
             mode_of_death_1 = mode_of_death),
    by = join_by(veget)) |> 
  
  # Attach information on state of tree at second visit
  left_join(
    tree_state_dict |> 
      rename(veget5 = ign_code,
             tree_state_2 = tree_state,
             alive_but_injured_2 = alive_but_injured,
             mode_of_death_2 = mode_of_death),
    by = join_by(veget5)) 
```

#### Attach tree class information
```{r}
# Get key-class dictionary
tree_class_dict <- get_tree_class_dictionary(l_raw_data, l_metadata)

# Attach dictionary
df_comb_tree_class <- 
  df_comb_tree_state |> 
  left_join(tree_class_dict |> 
              rename(espar = lvl_french) |> 
              mutate(tree_class = as.factor(tree_class)),
            by = join_by(espar))
```

### Filter for relevant trees
```{r}
df_comb_filtered <-
  df_comb_tree_class |> 
  filter(
    
    # Data for first visits before 2009 is not cleaned yet, so removing it for now
    campagne_1 > 2009,
    
    # Keep revisited trees with a first c13 measurement
    (revisit_state == "revisited" & !is.na(c13_1)) | 
      
    # Keep trees that have been newly sampled and measured
    (revisit_state == "newly_sampled" & !is.na(c13_2)),
    
    # Remove trees that have been dead or cut at first visit already
    !(revisit_state == "revisited" & (tree_state_1 %in% c("dead", "cut"))),
    
    # Remove trees that have not been found again for some reason
    !(revisit_state == "revisited" & veget5 == "N"),
    
    # Keep only trees that belong to the target stand
    !(identical(cible, NA) | identical(cible, 0)),
    
    # Remove trees that are missing xy-coordinates
    !is.na(lat),
    !is.na(lon)
    
    # Trees that were fully measured and not simplified
    # simplif == 0
    ) 
```

### Attach GEO information
```{r}
# Get temporary dataframe
df_tmp <- df_comb_filtered

# Get information on region, based on coordinates
df_geo <- match_coordinates_to_french_region(df_tmp)

# Match region code number with region name
df_comb_geo <- 
  left_join(
    df_tmp,
    df_geo |> 
      rename(dep = CC_2,
             dep_name = NAME_2,
             region_code = GID_1,
             region_name = NAME_1) |> 
      select(dep, dep_name, region_code, region_name) |> 
      distinct(),
    by = join_by(dep)
  )
```

### Calculate Shadow Growth of Circumference

TODO: THIS SHOULD BE DONE EARLIER, ACTUALLY BEFORE THE ASSESSMENT OF REVISITED OR NOT REVISITED! THEN, WE CAN USE THE SHADOW GROWTH FOR TREES THAT HAVE BEEN RE-ASSESSED AS HAVING SURVIVED/DIED/CUT. ELSE, THEY SHOULD BE DROPPED.

#### Cut Trees
```{r}
# Create temporary df for this section
df_tmp <- df_comb_geo

# Split datasets into cut and not cut
idx <- which(df_tmp$tree_state_2 == "cut")

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5 / 2,
           shadow_growth = TRUE) |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_cut <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = FALSE)
      )
} else {
  df_comb_shadow_cut <- df_tmp
}
```

#### Not re-measured dead trees
```{r}
# Create temporary df
df_tmp <- df_comb_shadow_cut

# Split datasets into cut and not cut
idx <- which(df_tmp$tree_state_2 == "dead" & is.na(df_tmp$c13_2))

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5 / 2,
           shadow_growth = TRUE) |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_dead <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = FALSE))
} else {
  df_comb_shadow_dead <- df_tmp
}
```

#### Not re-measured alive trees
```{r}
# Create temporary df
df_tmp <- df_comb_shadow_dead

# Split datasets into trees that survived
idx <- which(df_tmp$tree_state_2 == "alive" & is.na(df_tmp$c13_2))

# Do splitting only if index is not empty
if (length(idx) != 0) {
  
  df_edit <- df_tmp[idx, ] 
  df_keep <- df_tmp[-idx, ]  
  
  # Calculate the circumference achieved until a tree was cut
  # Calculation based on `ifn_wood_harvest_removal.pdf`
  # Drop data if growth could not be back-calculated
  df_edit <- 
    df_edit |> 
    mutate(c13_2 = c13_1 + ir5,
           shadow_growth = TRUE) |> 
    drop_na(c13_2)
  
  # Combine datasets again
  df_comb_shadow_alive <- 
    bind_rows(
      df_edit,
      df_keep |> mutate(shadow_growth = FALSE))
} else {
  df_comb_shadow_alive <- df_tmp
}
```

```{r}
# QC
df_comb_shadow_alive |> 
  filter(revisit_state == "newly_sampled") |> 
  relocate(c13_1, c13_2, tree_state_1, tree_state_2, revisit_state, tree_id)
```

### Calculate growth, biomass, etc.
```{r}
# Get temporary df
df_tmp <- df_comb_shadow_alive

# Attache size related variables
df_comb_size <- 
  df_tmp |> 
  # Attach size related variables
  mutate(
    # Add plot size variable
    plot_area = 25^2 * pi / 10^5, # (25m)^2 * pi / 10000 [m^2/ha] = [ha]
    
    # Diameter
    dbh_1 = c13_1 / pi,
    dbh_2 = c13_2 / pi,
    
    # Basal Area
    ba_1  = pi * ( dbh_1 / 2 ) ^ 2 / plot_area,
    ba_2  = pi * ( dbh_2 / 2 ) ^ 2 / plot_area
  ) |> 
  select(-plot_area)
```

#### Quality controls
```{r}
# Remove all alive trees that have a change of -0.05/yr, because that is likely
# and measurement error and trees should not shrink substantially.
df_comb_qc <- 
  df_comb_size |> 
  mutate(c13_change = ( dbh_2 - dbh_1 ) / dbh_1 / 5 ,
         c13_change = round(c13_change * 100)
         ) |>
  filter(c13_change > -5)
```

## Define most dominant genus per department
```{r}
df_dominant_species <-  
  df_comb_qc |> 
  group_by(dep) |> 
  nest() |> 
  mutate(top_genus = map_chr(data,
                                  ~pull(.,genus_lat) |> 
                                    table() |> 
                                    sort(decreasing = TRUE) |> 
                                    names() |> 
                                    head(3) |> 
                                    paste0(collapse = ", ")
                                    )) |> 
  mutate(top_species = map_chr(data,
                                  ~pull(.,species_lat) |> 
                                    table() |> 
                                    sort(decreasing = TRUE) |> 
                                    names() |> 
                                    head(5) |> 
                                    paste0(collapse = ", ")
                                    )) |> 
  select(-data)
```

## Create Maps of Change
### Species Selection
```{r}
df_comb_qc$genus_lat |> table() |> sort(decreasing = T) |> head(10)
df_comb_qc$species_lat |> table() |> sort(decreasing = T) |> head(10)
```

```{r}
# Subset for given species
selected_species <- "Fagus sylvatica"
species_classification_level <- "species_lat"

selected_species <- "Quercus"
species_classification_level <- "genus_lat"

# Could be made more flexible with family and other levels
if (str_detect(species_classification_level, "species")) {
  idx_majority <- 
    df_dominant_species |> 
    filter(str_detect(top_species, selected_species)) |> 
    pull(dep)
  
} else if (str_detect(species_classification_level, "genus")) {
  idx_majority <- 
    df_dominant_species |> 
    filter(str_detect(top_genus, selected_species)) |> 
    pull(dep)
}

# Make subset
df_species <- 
  df_comb_qc |> 
  filter(str_detect(get(species_classification_level), selected_species))

# df_species <- 
#   df_comb_qc |> 
#   filter(order_lat == "Fagales")

# QC
if (nrow(df_species) == 0) stop("Empty df!")
```

### Hexmaps
#### Using R hexmap

```{r}
df_plot <- 
  calculate_growth_mortality_per_hexagon(
    df_species,
    n_polygons_per_degree = 15,
    min_ntrees_per_polygon = 5
  )
```

```{r}
create_hexmap_from_aggregated_data("n_mor_yr", df_plot, "save")
```

### WIP ---

```{r}
# geom_hex(bins=59) +
  # stat_summary_hex(bins = 59, aes(z = sum(v1, v2))) +
  stat_summary_hex(bins = 59, fun = ~ sum(v1, 2)) +
  ggplot2::annotate(
    "text",
    x = -27,
    y = 72,
    label = "Where people tweet about #Surf",
    colour = "black",
    size = 5,
    alpha = 1,
    hjust = 0
  ) +
  ggplot2::annotate(
    "segment",
    x = -27,
    xend = 10,
    y = 70,
    yend = 70,
    colour = "black",
    size = 0.2,
    alpha = 1
  ) +
  theme_void() +
  xlim(-30, 70) +
  ylim(24, 72) +
  #  scale_fill_viridis(
  #   option="B",
  #   trans = "log",
  #   # breaks = c(1,7,54,403,3000),
  #   name="Tweet # recorded in 8 months",
  #   guide = guide_legend( keyheight = unit(2.5, units = "mm"), keywidth=unit(10, units = "mm"), label.position = "bottom", title.position = 'top', nrow=1)
  # )  +
  ggtitle("") +
  theme(
    legend.position = c(0.8, 0.09),
    legend.title = element_text(color = "black", size = 8),
    text = element_text(color = "#22211d"),
    plot.background = element_rect(fill = "#f5f5f2", color = NA),
    panel.background = element_rect(fill = "#f5f5f2", color = NA),
    legend.background = element_rect(fill = "#f5f5f2", color = NA),
    plot.title = element_text(
      size = 13,
      hjust = 0.1,
      color = "#4e4d47",
      margin = margin(
        b = -0.1,
        t = 0.4,
        l = 2,
        unit = "cm"
      )
    ),
  )
```

### Attach influence information
#### Attach nature influence

```{r} 
# Make temporary dataframe
df_tmp <- df_comb

# DEBUG
set.seed(123) 
df_tmp <- df_comb |> slice_sample(n = 200000)

# Get environmental variables
env_vars <- get_vars("nature")

# Run code - takes very long!
tic()

df_comb_nature <- 
  df_tmp |> 
  nest(data = c(tree_id, env_vars)) |> 
  mutate(env_impact = map(data, ~get_nature_impact_information(.),
                          .progress = TRUE)) |> 
  select(env_impact) |> 
  unnest(env_impact) |> 
  right_join(df_tmp |> select(-env_vars), by = join_by(tree_id))
  
toc()
beep()

# Save data
load_or_save_latest_file("df_comb_nature", "save")
```

#### Attach human influence
```{r}

```


### Classifications of Tree Status, Class, Human / Nature Influence

```{r}


# Classification for human influence

# Classification for natural influence

```


```{r}
# Attach information on vegetation state
df_treid <- 
  df_treid |> 
  left_join(code_veget5 |> rename(veget = lvl),
            by = join_by(veget)) |> 
  left_join(code_veget5 |> rename(veget5 = lvl,
                                  tree_status5 = tree_status),
            by = join_by(veget5))
```

### Break location data to tree-level

```{r}
df_loc_wide <- f_widen_location_data(l_raw_data$placette)
```

### Widen data to one tree per row



I wanted to finally create a uniform approach to widening the tree data but I got stuck with not knowing thiwch variables can be extended and which ones not... Really not sure if it important for going forward to differentiate this. Mostly the data is NA anywas and can be ignored? So, I should just continue with my subset analysis and see if everything works as expected there?

When getting back to this. First try to rerun the code and check if it actually works. I think adding the 'espar' variable to the tree-level data breaks things. Maybe that would then actually be 'location' data. But then again, I should just create a list that I know has to stay constant. And for everything less certain, we widen the data and drop the NAs.

```{r}
# Select variables to widen, to drop, to keep
vars_location_tree <- f_get_fixed_vars_per_level(level = "location_tree")
vars_to_keep       <- df_subset |> select( any_of(vars_location_tree)) |>  names()
vars_to_widen      <- df_subset |> select(-any_of(vars_location_tree)) |>  names()

# Widen dataframe
df_tre_wide <- 
  df_treid |> 
  pivot_wider(
    id_cols = vars_to_keep,
    names_from  = visit_nr,
    values_from = vars_to_widen) |> 
  select(-where(~all(is.na(.))))

# Clean up data frame
## For trees that were sampled the first time in the second campaign, there is 
## the variable veget_2 included (state of vegetation at first sight but second
## sampling campaign). This information can be simply merged into veget_1 without
## loosing information. Also overwrite the state variable for second visit to be 
## the same as for the first visit because, there will be no second visit, and it
## is the latest knowledge on the state. The same applies for "tree_status" variable.
newly_sampled_rows <- df_tre_wide$revisit_state == "newly_sampled"

df_tre_wide$veget_1[newly_sampled_rows]        <- df_tre_wide$veget_2[newly_sampled_rows]
df_tre_wide$veget5_2[newly_sampled_rows]       <- df_tre_wide$veget_2[newly_sampled_rows]
df_tre_wide$tree_status_1[newly_sampled_rows]  <- df_tre_wide$tree_status_2[newly_sampled_rows]
df_tre_wide$tree_status5_2[newly_sampled_rows] <- df_tre_wide$tree_status_2[newly_sampled_rows]

## Clean up names
df_tre_wide_clean <- 
  df_tre_wide |> 
  select(-veget_2, -tree_status_2) |> 
  rename_with(~ gsub("_1$", "_v1", .), ends_with("_1")) |>
  rename_with(~ gsub("_2$", "_v2", .), ends_with("_2")) |> 
  rename(veget_v2 = veget5_v2,
         tree_status_v2 = tree_status5_v2)

## Quality check if widening worked: No tree_id should be doubled:
qc <- length(unique(df_tre_wide_clean$tree_id)) == nrow(df_tre_wide_clean)
if (!qc) {stop("Duplicated tree_id in wide dataframe!")}

# Attach location data and keep only relevant variables
irr_vars <- f_get_list_of_irrelevant_vars()
irr_vars <- c(irr_vars, paste0(irr_vars, "_v2"))

df_comb <- 
  left_join(df_tre_wide_clean, 
            df_loc_wide,
            by = join_by(idp)) |> 
  select(-any_of(irr_vars))

# Attach new variables 
df_fin <- 
  df_comb |> 
  mutate(
    
    # TODO ADD VOLUME
    # TODO ADD IR5 (increment grown within past 5 years)
    
    # Diameter
    dbh_v1 = c13_v1 / pi,
    dbh_v2 = c13_v2 / pi,
    
    # Basal Area
    ba_v1  = pi * ( dbh_v1 / 2 ) ^ 2,
    ba_v2  = pi * ( dbh_v2 / 2 ) ^ 2,
    
    # Changes
    d_c13  = c13_v2 - c13_v1,
    d_htot = htot_v2 - htot_v1,
    d_dbh  = dbh_v2 - dbh_v1,
    d_ba   = ba_v2  - ba_v1
    )
```

# --- WIP

### Filter for first visits 2010 or after

```{r}
# Filter for trees that were visited the first time from 2010 onwards
# meaning the second visit was in 2015.
df_subset <- 
  df_treid |> 
  filter(
    visit_2 > 2014,
    (revisit_state == "newly_sampled" |
       revisit_state == "revisited")
    )

# Make df wide
vars_location_tree <- f_get_fixed_vars_per_level(level = "location_tree")
vars_to_keep       <- df_subset |> select( any_of(vars_location_tree)) |>  names()
vars_to_widen      <- df_subset |> select(-any_of(vars_location_tree)) |>  names()

df_wide <- 
  df_subset |> 
  # arrange(tree_id) |> slice(1:1000) |> 
  pivot_wider(
    id_cols = vars_to_keep,
    names_from  = visit_nr,
    values_from = vars_to_widen) |> 
  select(-where(~all(is.na(.))))

# For trees that were sampled the first time in the second campaign, there is 
# the variable veget_2 included (state of vegetation at first sight but second
# sampling campaign). This information can be simply merged into veget_1 without
# loosing information. Also overwrite the state variable for second visit to be 
# the same as for the first visit because, there will be no second visit, and it
# is the latest knowledge on the state. 
# The same applies for "tree_status" variable.
for (i in 1:nrow(df_wide)) {
  if (df_wide$revisit_state[i] == "newly_sampled") {
    df_wide$veget_1[i]        <- df_wide$veget_2[i]
    df_wide$veget5_2[i]       <- df_wide$veget_2[i]
    df_wide$tree_status_1[i]  <- df_wide$tree_status_2[i]
    df_wide$tree_status5_2[i] <- df_wide$tree_status_2[i]
  }
}

df_wide_fin <- 
  df_wide |> 
  select(-veget_2, -tree_status_2) |> 
  rename_with(~ gsub("_1$", "_v1", .), ends_with("_1")) |>
  rename_with(~ gsub("_2$", "_v2", .), ends_with("_2")) |> 
  rename(veget_v2 = veget5_v2,
         tree_status_v2 = tree_status5_v2)

# Attach location data and keep only relevant variables
irr_vars <- f_get_list_of_irrelevant_vars()
irr_vars <- c(irr_vars, paste0(irr_vars, "_v2"))

# Clean up dataframe and calculate change in c13
df_comb <- 
  left_join(df_wide_fin, 
            df_loc_wide,
            by = join_by(idp)) |> 
  select(-any_of(irr_vars)) |> 
  mutate(d_c13 = c13_v2 - c13_v1)

# Split dataset into re-measured and not re-remeasured
df_measured_1  <- df_comb |> filter( is.na(d_c13)) 
df_measured_2  <- df_comb |> filter(!is.na(d_c13)) 
```

### Wrangle data with only one c13 measurement

#### Trees that were re-visited but not re-measured

TODO: What should be done with the not re-measured trees that were alive or dead?

```{r}
# For trees that were cut at revisit
df_tmp <- 
  df_measured_1 |> 
  filter(revisit_state == "revisited") 

# Set change in c13 at second visit to zero and add 
# to dataframe with two c13 measuremnts
df_attach_cutted_trees <- 
  df_tmp |> 
  filter(tree_status_v2 == "cut" |
         tree_status_v2 == "dead") |> 
  mutate(
    c13_v2 = 0,
    d_c13 = c13_v2 - c13_v1
    )

# Quality controls
df_tmp$tree_status_v2 |> table()
df_attach_cutted_trees$tree_status_v2 |> table()
```

#### Trees that were newly recruited
```{r}
# Get dataframe for newly grown trees
df_tmp <- 
  df_measured_1 |> 
  filter(revisit_state == "newly_sampled") 

# Set change in c13 at second visit to zero and add 
# to dataframe with two c13 measuremnts
df_attach_new_trees <- 
  df_tmp |> 
  mutate(
    c13_v1 = 0,
    d_c13 = c13_v2 - c13_v1
    )

# Quality controls
df_tmp$tree_status_v1 |> table()
df_attach_new_trees$tree_status_v1 |> table()
```

### Create final subset df

```{r}
df_measured_2_ext <- 
  rbind(df_measured_2,
        df_attach_cutted_trees,
        df_attach_new_trees)

# Check that no tree is doubled:
qc <- df_measured_2_ext |> pull(tree_id) |> duplicated() |> all()
if (qc) stop("Duplicated trees in the dataset!")
```

## Subset Plots

### Leaflet
```{r}
# Code adapted from: 
# https://stackoverflow.com/questions/35921590/leaflet-on-r-how-to-create-layers-and-colors-for-each-factor-level-in-dataframe

# Define coordinates for subregion
l_subreg <- list(
  min_lon = 5.542038,
  max_lon = 6.917511,
  min_lat = 45.005973,
  max_lat = 45.556079
)

# Get dataframe of interest:
# df_tmp <- 
#   df_measured_2_ext |>
  

df_tmp <- 
  df_measured_2_ext |> 
  dplyr::filter(between(lon, l_subreg$min_lon, l_subreg$max_lon),
                between(lat, l_subreg$min_lat, l_subreg$max_lat)) |> 
   select(idp, visit_v1, visit_v2, d_c13, tree_status_v2, lat, lon)

df_map <- 
  df_tmp |> 
  nest(data = c(tree_status_v2, d_c13, visit_v1)) |> 
  mutate(
    d_c13   = map_dbl(data, ~mean(.$d_c13)),
    n_trees = map_dbl(data, ~nrow(.)),
    n_dead  = map_dbl(data, ~nrow(filter(., tree_status_v2 == "dead"))),
    n_alive  = map_dbl(data, ~nrow(filter(., tree_status_v2 == "alive"))),
    n_cut  = map_dbl(data, ~nrow(filter(., tree_status_v2 == "cut"))),
    perc_dead  = round(n_dead  / n_trees * 100),
    perc_alive = round(n_alive / n_trees * 100),
    perc_cut   = round(n_cut   / n_trees * 100),
    stand_status = case_when(
                              n_alive > n_cut & n_alive > n_dead ~ "alive",
                              n_cut > n_alive & n_cut > n_dead ~ "cut",
                              n_dead > n_alive & n_dead > n_cut ~ "dead",
                              TRUE ~ "equal"),
         stand_status = as.factor(stand_status)
  )

# Avoid overlaps
df_map$lat <- jitter(df_map$lat, factor = 0.0001)
df_map$lon <- jitter(df_map$lon, factor = 0.0001)

# Define groups for plotting
groups     <-  as.character(unique(df_map$stand_status))
groups_col <-  colorFactor(palette = "viridis", 
                           domain = df_map$stand_status)
map <- 
  leaflet(df_map) |> 
  addProviderTiles(
    providers$Esri.WorldImagery,
    group = "World Imagery") |>
  addProviderTiles(
    providers$Esri.WorldTopoMap, 
    group = "World Topo")

for (g in groups) {
  df_i <-  df_map |> filter(stand_status == g)
  
  map <- 
    map |> 
    addCircleMarkers(
    # addMarkers(
      data = df_i, 
      lng = ~lon, 
      lat = ~lat, 
      color = ~groups_col(stand_status),
      group = g, 
      label = ~paste("Plot ID:", idp,
                     "| 2nd visit: ", visit_v2,
                     "| Stand Status: ", stand_status,
                     "| d c13: ", round(d_c13, 3),
                     "| Trees alive: ", round(n_alive/n_trees * 100), "%",
                     "| Trees dead: ", round(n_cut/n_trees * 100), "%",
                     "| Trees cut: ", round(n_dead/n_trees * 100), "%"),
      opacity = 0.9)
}

map |> 
  addLayersControl(
    overlayGroups = groups,
    baseGroups = c("World Imagery", "World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE)) |> 
  addRectangles(
    lng1 = l_subreg$min_lon, 
    lat1 = l_subreg$min_lat,
    lng2 = l_subreg$max_lon, 
    lat2 = l_subreg$max_lat,
    fillColor = "transparent"
  ) |> 
  addLegend(
    pal = groups_col,
    values = groups,
    title = "Stand Status",
    position = "topleft")
```


### Change in c13
```{r}
#| layout-nrow: 1
data <- data.frame(
  lon = df_measured_2_ext$lon,  # Your longitude values
  lat = df_measured_2_ext$lat,   # Your latitude values
  value = df_measured_2_ext$d_c13       # Your value data
)

n_breaks <- 100

mean_values <- 
  aggregate(
    value ~ cut(lon, breaks = n_breaks) + cut(lat, breaks = n_breaks), 
    data, 
    mean)

colnames(mean_values) <- c("lon", "lat", "value")

ggplot() +
  geom_tile(data = mean_values, aes(x = lon, y = lat, fill = value)) +
  # scale_fill_viridis_c(option = "magma") +
  scico::scale_fill_scico(
    palette = "vikO",
    limits = c(-4, 4)
    ) +
  labs(title = "Change in c13 from 2010-2020",
       caption = "Subset from revisited sites from 2010 onwards. Shown are mean values of binned trees",
       fill  = "Average change in c13 from 2010-2020 [m]: \n") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = .6),
        plot.subtitle = element_text(hjust = .6),
        plot.caption = element_text(hjust = .6),
        panel.grid = element_blank())

p1 <- 
  ggplot() +
  geom_histogram(data = data, aes(x = value), bins = 250) +
  labs(title = "Counts of delta c13",
       x = "delta c13") +
  geom_vline(xintercept = 0, color = "red") +
  xlim(-3, 2) +
  theme_classic()

p2 <- 
  ggplot() +
  geom_histogram(data = mean_values, aes(x = value), bins = 1000) +
  geom_vline(xintercept = 0, color = "red") +
  labs(subtitle = "Mean values plotted in the map",
       y = NULL,
       x = NULL)  +
  theme_classic()

p1 + inset_element(p2, 0.1, 0.5, 0.5, 0.95)
```

**Locations where trees shrank**

```{r}
#| layout-nrow: 1
#| layout-col: 2

data <- 
  df_measured_2_ext |> 
  select(lon, lat, d_c13) |> 
  rename(value = d_c13) |> 
  filter(value < 0) |> 
  data.frame()

n_breaks <- 100

mean_values <- 
  aggregate(
    value ~ cut(lon, breaks = n_breaks) + cut(lat, breaks = n_breaks), 
    data, 
    mean)

colnames(mean_values) <- c("lon", "lat", "value")

ggplot() +
  geom_tile(data = mean_values, aes(x = lon, y = lat, fill = value)) +
  scale_fill_gradientn(colors = rev(RColorBrewer::brewer.pal(5, "Reds"))) +
  labs(title = "Decrease in c13 from 2010-2020",
       caption = "Subset from revisited sites from 2010 onwards. Shown are mean values of binned trees",
       fill  = "Average change in c13 from 2010-2020 [m]: \n") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = .6),
        plot.subtitle = element_text(hjust = .6),
        panel.grid = element_blank())
```

```{r}
#| layout-nrow: 1
#| 
## Locations where trees grew
data <- df_measured_2_ext |> 
  select(lon, lat, d_c13) |> 
  rename(value = d_c13) |> 
  filter(value > 0) |> 
  data.frame()

n_breaks <- 100

mean_values <- 
  aggregate(
    value ~ cut(lon, breaks = n_breaks) + cut(lat, breaks = n_breaks), 
    data, 
    mean)

colnames(mean_values) <- c("lon", "lat", "value")

ggplot() +
  geom_tile(data = mean_values, aes(x = lon, y = lat, fill = value)) +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(5, "Blues")) +
  labs(title = "Increase in c13 from 2010-2020 (growth and new trees)",
       caption = "Subset from revisited sites from 2010 onwards. Shown are mean values of binned trees",
       fill  = "Average change in c13 from 2010-2020 [m]: \n") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = .6),
        plot.subtitle = element_text(hjust = .6),
        panel.grid = element_blank())


## Locations where NEW trees grew
data <- 
  df_measured_2_ext |> 
  filter(revisit_state == "newly_sampled") |> 
  select(lon, lat, d_c13) |> 
  rename(value = d_c13) |> 
  filter(value > 0) |> 
  data.frame()

n_breaks <- 100

mean_values <- 
  aggregate(
    value ~ cut(lon, breaks = n_breaks) + cut(lat, breaks = n_breaks), 
    data, 
    mean)

colnames(mean_values) <- c("lon", "lat", "value")

ggplot() +
  geom_tile(data = mean_values, aes(x = lon, y = lat, fill = value)) +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(5, "Blues")) +
  labs(title   = "Increase in c13 from 2010-2020 (new trees only)",
       caption = "Subset from revisited sites from 2010 onwards. Shown are mean values of binned trees",
       fill    = "Average change in c13 from 2010-2020 [m]: \n") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = .6),
        plot.subtitle = element_text(hjust = .6),
        panel.grid = element_blank())
```


```{r}
knitr::knit_exit()
```

# Subset Analysis

# NO RENDER BELOW ---
