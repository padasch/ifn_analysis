{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Patterns of Change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import h3pandas\n",
    "\n",
    "# Data visualisation\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import f\n",
    "\n",
    "# My functions\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from run_mp import *\n",
    "from utilities import *\n",
    "from random_forest_utils import *\n",
    "\n",
    "# Other\n",
    "from os import error\n",
    "import warnings\n",
    "import chime\n",
    "from pyprojroot import here\n",
    "\n",
    "chime.theme(\"mario\")\n",
    "\n",
    "# Magic\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_rerunning_all_sites = False\n",
    "run_only_subset = False\n",
    "subset_fraction = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549255, 193)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NFI data\n",
    "nfi_raw = get_final_nfi_data_for_analysis()\n",
    "nfi_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics of Change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At site-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 1 : all --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_all-height_all, skipping it\n",
      " - File already exists: species_all-height_10-15, skipping it\n",
      " - File already exists: species_all-height_0-10, skipping it\n",
      " - File already exists: species_all-height_15-20, skipping it\n",
      " - File already exists: species_all-height_20-25, skipping it\n",
      " - File already exists: species_all-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 2 : Quercus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_quercus-height_all, skipping it\n",
      " - File already exists: species_quercus-height_10-15, skipping it\n",
      " - File already exists: species_quercus-height_0-10, skipping it\n",
      " - File already exists: species_quercus-height_15-20, skipping it\n",
      " - File already exists: species_quercus-height_20-25, skipping it\n",
      " - File already exists: species_quercus-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 3 : Pinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_pinus-height_all, skipping it\n",
      " - File already exists: species_pinus-height_10-15, skipping it\n",
      " - File already exists: species_pinus-height_0-10, skipping it\n",
      " - File already exists: species_pinus-height_15-20, skipping it\n",
      " - File already exists: species_pinus-height_20-25, skipping it\n",
      " - File already exists: species_pinus-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 4 : Fagus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_fagus-height_all, skipping it\n",
      " - File already exists: species_fagus-height_10-15, skipping it\n",
      " - File already exists: species_fagus-height_0-10, skipping it\n",
      " - File already exists: species_fagus-height_15-20, skipping it\n",
      " - File already exists: species_fagus-height_20-25, skipping it\n",
      " - File already exists: species_fagus-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 5 : Carpinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_carpinus-height_all, skipping it\n",
      " - File already exists: species_carpinus-height_10-15, skipping it\n",
      " - File already exists: species_carpinus-height_0-10, skipping it\n",
      " - File already exists: species_carpinus-height_15-20, skipping it\n",
      " - File already exists: species_carpinus-height_20-25, skipping it\n",
      " - File already exists: species_carpinus-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 6 : Castanea --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_castanea-height_all, skipping it\n",
      " - File already exists: species_castanea-height_10-15, skipping it\n",
      " - File already exists: species_castanea-height_0-10, skipping it\n",
      " - File already exists: species_castanea-height_15-20, skipping it\n",
      " - File already exists: species_castanea-height_20-25, skipping it\n",
      " - File already exists: species_castanea-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 7 : Picea --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_picea-height_all, skipping it\n",
      " - File already exists: species_picea-height_10-15, skipping it\n",
      " - File already exists: species_picea-height_0-10, skipping it\n",
      " - File already exists: species_picea-height_15-20, skipping it\n",
      " - File already exists: species_picea-height_20-25, skipping it\n",
      " - File already exists: species_picea-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 8 : Abies --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_abies-height_all, skipping it\n",
      " - File already exists: species_abies-height_10-15, skipping it\n",
      " - File already exists: species_abies-height_0-10, skipping it\n",
      " - File already exists: species_abies-height_15-20, skipping it\n",
      " - File already exists: species_abies-height_20-25, skipping it\n",
      " - File already exists: species_abies-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 9 : Fraxinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_fraxinus-height_all, skipping it\n",
      " - File already exists: species_fraxinus-height_10-15, skipping it\n",
      " - File already exists: species_fraxinus-height_0-10, skipping it\n",
      " - File already exists: species_fraxinus-height_15-20, skipping it\n",
      " - File already exists: species_fraxinus-height_20-25, skipping it\n",
      " - File already exists: species_fraxinus-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 10 : Acer --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_acer-height_all, skipping it\n",
      " - File already exists: species_acer-height_10-15, skipping it\n",
      " - File already exists: species_acer-height_0-10, skipping it\n",
      " - File already exists: species_acer-height_15-20, skipping it\n",
      " - File already exists: species_acer-height_20-25, skipping it\n",
      " - File already exists: species_acer-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 11 : Betula --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_betula-height_all, skipping it\n",
      " - File already exists: species_betula-height_10-15, skipping it\n",
      " - File already exists: species_betula-height_0-10, skipping it\n",
      " - File already exists: species_betula-height_15-20, skipping it\n",
      " - File already exists: species_betula-height_20-25, skipping it\n",
      " - File already exists: species_betula-height_25+, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 12 : Populus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_populus-height_all, skipping it\n",
      " - File already exists: species_populus-height_10-15, skipping it\n",
      " - File already exists: species_populus-height_0-10, skipping it\n",
      " - File already exists: species_populus-height_15-20, skipping it\n",
      " - File already exists: species_populus-height_20-25, skipping it\n",
      " - File already exists: species_populus-height_25+, skipping it\n"
     ]
    }
   ],
   "source": [
    "# * Get input df --------------------------------------------------------------\n",
    "df_in = nfi_raw.copy()\n",
    "if run_only_subset:\n",
    "    all_sites = df_in[\"idp\"].unique().tolist()\n",
    "    subset_sites = np.random.choice(\n",
    "        all_sites, int(len(all_sites) * subset_fraction), replace=False\n",
    "    ).tolist()\n",
    "    df_in = df_in.query(\"idp in @subset_sites\")\n",
    "\n",
    "# * Get factorial setup -------------------------------------------------------\n",
    "# ! Pick only idp level here but loop over all species and heights\n",
    "all_regions = [\"idp\"]  # [\"idp\", \"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "\n",
    "# Pick top 10 species + populus\n",
    "all_species = (\n",
    "    df_in[\"genus_lat\"]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .index.tolist()\n",
    ")\n",
    "all_species = [\"all\"] + all_species\n",
    "if \"Populus\" not in all_species:\n",
    "    all_species.append(\"Populus\")\n",
    "\n",
    "# Pick all height classes\n",
    "all_heights = [\"all\"] + df_in[\"tree_height_class\"].value_counts().index.tolist()\n",
    "all_heights.remove(\"Missing\")\n",
    "\n",
    "# * Run loop ------------------------------------------------------------------\n",
    "# Imports\n",
    "from utilities import calculate_growth_mortality_optimized\n",
    "from run_mp import run_mp\n",
    "\n",
    "species_counter = 0\n",
    "# Loop over species\n",
    "for my_species in all_species:\n",
    "    # Verbose\n",
    "    species_counter = species_counter + 1\n",
    "    display(f\" --- Working on species Nr. {species_counter} : {my_species} --- \")\n",
    "    # Loop over heights\n",
    "    for my_height in all_heights:\n",
    "        # Get new df\n",
    "        df_loop = df_in.copy()\n",
    "\n",
    "        # ! Filter df\n",
    "        # Filter for species\n",
    "        if my_species != \"all\":\n",
    "            df_loop = df_loop.query(f\"genus_lat == '{my_species}'\")\n",
    "\n",
    "        # Filter for height\n",
    "        if my_height != \"all\":\n",
    "            df_loop = df_loop.query(f\"tree_height_class == '{my_height}'\")\n",
    "\n",
    "        # Loop over regions\n",
    "        for my_region in all_regions:\n",
    "            # ! Get filename and print it\n",
    "            if run_only_subset:\n",
    "                my_dir = here(\n",
    "                    str.lower(\n",
    "                        f\"data/tmp/nfi/growth_and_mortality_data/idp/subset_{round(subset_fraction*100)}%_of_sites\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                my_dir = here(str.lower(f\"data/tmp/nfi/growth_and_mortality_data/idp\"))\n",
    "            os.makedirs(my_dir, exist_ok=True)\n",
    "            my_file = str.lower(f\"species_{my_species}-height_{my_height}\")\n",
    "            my_dirfile = f\"{my_dir}/{my_file}.feather\"\n",
    "\n",
    "            # Check if file already exists, if so skip current loop\n",
    "            if os.path.isfile(my_dirfile) and not force_rerunning_all_sites:\n",
    "                print(f\" - File already exists: {my_file}, skipping it\")\n",
    "                continue\n",
    "\n",
    "            # Verbose\n",
    "            print(str.lower(f\"\\n - Working on: {my_file}\"))\n",
    "\n",
    "            # ! Add grouping variable\n",
    "            my_region_tmp = my_region\n",
    "\n",
    "            # IDP holds year information, so no need to add there\n",
    "            # But grouping for other regions need this time information\n",
    "            if my_region != \"idp\":\n",
    "                my_region = my_region + \"_year\"\n",
    "                df_loop[my_region] = (\n",
    "                    df_loop[my_region_tmp].astype(str)\n",
    "                    + \"_\"\n",
    "                    + df_loop[\"campagne_1\"].astype(str)\n",
    "                )\n",
    "\n",
    "            # ! Create list and run mp\n",
    "            df_list = [\n",
    "                group for name, group in df_loop.groupby(my_region, as_index=False)\n",
    "            ]\n",
    "            df_mp = run_mp(\n",
    "                calculate_growth_mortality_optimized,\n",
    "                df_list,\n",
    "                combine_func=pd.concat,\n",
    "                progress_bar=True,\n",
    "                num_cores=10,\n",
    "                grouping_variable=my_region,\n",
    "            )\n",
    "\n",
    "            # ! Save df\n",
    "            df_mp.reset_index(drop=True).to_feather(my_dirfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At region-level - directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 1 : all --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_all-height_all_region-reg, skipping it\n",
      " - File already exists: species_all-height_all_region-dep, skipping it\n",
      " - File already exists: species_all-height_all_region-gre, skipping it\n",
      " - File already exists: species_all-height_all_region-ser, skipping it\n",
      " - File already exists: species_all-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 2 : Quercus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_quercus-height_all_region-reg, skipping it\n",
      " - File already exists: species_quercus-height_all_region-dep, skipping it\n",
      " - File already exists: species_quercus-height_all_region-gre, skipping it\n",
      " - File already exists: species_quercus-height_all_region-ser, skipping it\n",
      " - File already exists: species_quercus-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 3 : Pinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_pinus-height_all_region-reg, skipping it\n",
      " - File already exists: species_pinus-height_all_region-dep, skipping it\n",
      " - File already exists: species_pinus-height_all_region-gre, skipping it\n",
      " - File already exists: species_pinus-height_all_region-ser, skipping it\n",
      " - File already exists: species_pinus-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 4 : Fagus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_fagus-height_all_region-reg, skipping it\n",
      " - File already exists: species_fagus-height_all_region-dep, skipping it\n",
      " - File already exists: species_fagus-height_all_region-gre, skipping it\n",
      " - File already exists: species_fagus-height_all_region-ser, skipping it\n",
      " - File already exists: species_fagus-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 5 : Carpinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_carpinus-height_all_region-reg, skipping it\n",
      " - File already exists: species_carpinus-height_all_region-dep, skipping it\n",
      " - File already exists: species_carpinus-height_all_region-gre, skipping it\n",
      " - File already exists: species_carpinus-height_all_region-ser, skipping it\n",
      " - File already exists: species_carpinus-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 6 : Castanea --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_castanea-height_all_region-reg, skipping it\n",
      " - File already exists: species_castanea-height_all_region-dep, skipping it\n",
      " - File already exists: species_castanea-height_all_region-gre, skipping it\n",
      " - File already exists: species_castanea-height_all_region-ser, skipping it\n",
      " - File already exists: species_castanea-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 7 : Picea --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_picea-height_all_region-reg, skipping it\n",
      " - File already exists: species_picea-height_all_region-dep, skipping it\n",
      " - File already exists: species_picea-height_all_region-gre, skipping it\n",
      " - File already exists: species_picea-height_all_region-ser, skipping it\n",
      " - File already exists: species_picea-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 8 : Abies --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_abies-height_all_region-reg, skipping it\n",
      " - File already exists: species_abies-height_all_region-dep, skipping it\n",
      " - File already exists: species_abies-height_all_region-gre, skipping it\n",
      " - File already exists: species_abies-height_all_region-ser, skipping it\n",
      " - File already exists: species_abies-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 9 : Fraxinus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_fraxinus-height_all_region-reg, skipping it\n",
      " - File already exists: species_fraxinus-height_all_region-dep, skipping it\n",
      " - File already exists: species_fraxinus-height_all_region-gre, skipping it\n",
      " - File already exists: species_fraxinus-height_all_region-ser, skipping it\n",
      " - File already exists: species_fraxinus-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 10 : Acer --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_acer-height_all_region-reg, skipping it\n",
      " - File already exists: species_acer-height_all_region-dep, skipping it\n",
      " - File already exists: species_acer-height_all_region-gre, skipping it\n",
      " - File already exists: species_acer-height_all_region-ser, skipping it\n",
      " - File already exists: species_acer-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 11 : Betula --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_betula-height_all_region-reg, skipping it\n",
      " - File already exists: species_betula-height_all_region-dep, skipping it\n",
      " - File already exists: species_betula-height_all_region-gre, skipping it\n",
      " - File already exists: species_betula-height_all_region-ser, skipping it\n",
      " - File already exists: species_betula-height_all_region-hex, skipping it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' --- Working on species Nr. 12 : Populus --- '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - File already exists: species_populus-height_all_region-reg, skipping it\n",
      " - File already exists: species_populus-height_all_region-dep, skipping it\n",
      " - File already exists: species_populus-height_all_region-gre, skipping it\n",
      " - File already exists: species_populus-height_all_region-ser, skipping it\n",
      " - File already exists: species_populus-height_all_region-hex, skipping it\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# * Get input df --------------------------------------------------------------\n",
    "df_in = nfi_raw.copy()\n",
    "if run_only_subset:\n",
    "    all_sites = df_in[\"idp\"].unique().tolist()\n",
    "    subset_sites = np.random.choice(\n",
    "        all_sites, int(len(all_sites) * subset_fraction), replace=False\n",
    "    ).tolist()\n",
    "    df_in = df_in.query(\"idp in @subset_sites\")\n",
    "\n",
    "# * Get factorial setup -------------------------------------------------------\n",
    "# ! Loop over all regions (not idp) but not over all heights, would take too long for now...\n",
    "all_regions = [\"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "\n",
    "# Pick top 10 species + populus\n",
    "all_species = (\n",
    "    df_in[\"genus_lat\"]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    "    .index.tolist()\n",
    ")\n",
    "all_species = [\"all\"] + all_species\n",
    "if \"Populus\" not in all_species:\n",
    "    all_species.append(\"Populus\")\n",
    "\n",
    "# Pick all height classes\n",
    "# + df_in[\"tree_height_class\"].value_counts().index.tolist()all_heights.remove(\"Missing\")\n",
    "all_heights = [\"all\"]\n",
    "\n",
    "# * Run loop ------------------------------------------------------------------\n",
    "# Imports\n",
    "from utilities import calculate_growth_mortality_optimized\n",
    "from run_mp import run_mp\n",
    "\n",
    "# Loop over species\n",
    "species_counter = 0\n",
    "for my_species in all_species:\n",
    "    # Verbose\n",
    "    species_counter = species_counter + 1\n",
    "    display(f\" --- Working on species Nr. {species_counter} : {my_species} --- \")\n",
    "\n",
    "    # Loop over heights\n",
    "    for my_height in all_heights:\n",
    "        # Get new df\n",
    "        df_loop = df_in.copy()\n",
    "\n",
    "        # ! Filter df\n",
    "        # Filter for species\n",
    "        if my_species != \"all\":\n",
    "            df_loop = df_loop.query(f\"genus_lat == '{my_species}'\")\n",
    "\n",
    "        # Filter for height\n",
    "        if my_height != \"all\":\n",
    "            df_loop = df_loop.query(f\"tree_height_class == '{my_height}'\")\n",
    "\n",
    "        # Loop over regions\n",
    "        for my_region in all_regions:\n",
    "            # ! Get filename and print it\n",
    "            if run_only_subset:\n",
    "                my_dir = here(\n",
    "                    str.lower(\n",
    "                        f\"data/tmp/nfi/growth_and_mortality_data/direct/subset_{round(subset_fraction*100)}%_of_sites\"\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                my_dir = here(\n",
    "                    str.lower(f\"data/tmp/nfi/growth_and_mortality_data/direct/\")\n",
    "                )\n",
    "            os.makedirs(my_dir, exist_ok=True)\n",
    "            my_file = str.lower(\n",
    "                f\"species_{my_species}-height_{my_height}_region-{my_region}\"\n",
    "            )\n",
    "            my_dirfile = f\"{my_dir}/{my_file}.feather\"\n",
    "\n",
    "            # Check if file already exists, if so skip current loop\n",
    "            if os.path.isfile(my_dirfile) and not force_rerunning_all_sites:\n",
    "                print(f\" - File already exists: {my_file}, skipping it\")\n",
    "                continue\n",
    "\n",
    "            # Verbose\n",
    "            print(str.lower(f\"\\n - Working on: {my_file}\"))\n",
    "\n",
    "            # ! Add grouping variable\n",
    "            my_region_tmp = my_region\n",
    "\n",
    "            # IDP holds year information, so no need to add there\n",
    "            # But grouping for other regions need this time information\n",
    "            if my_region != \"idp\":\n",
    "                my_region = my_region + \"_year\"\n",
    "                df_loop[my_region] = (\n",
    "                    df_loop[my_region_tmp].astype(str)\n",
    "                    + \"_\"\n",
    "                    + df_loop[\"campagne_1\"].astype(str)\n",
    "                )\n",
    "\n",
    "            # ! Create list and run mp\n",
    "            df_list = [\n",
    "                group for name, group in df_loop.groupby(my_region, as_index=False)\n",
    "            ]\n",
    "\n",
    "            df_mp = run_mp(\n",
    "                calculate_growth_mortality_optimized,\n",
    "                df_list,\n",
    "                combine_func=pd.concat,\n",
    "                progress_bar=True,\n",
    "                num_cores=10,\n",
    "                grouping_variable=my_region,\n",
    "            )\n",
    "\n",
    "            # ! Save df\n",
    "            df_mp.reset_index(drop=True).to_feather(my_dirfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At region-level - aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['species_fraxinus-height_0-10.feather',\n",
       " 'species_acer-height_0-10.feather',\n",
       " 'species_quercus-height_all.feather']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all of the subsets where change was calculated at site-level\n",
    "if run_only_subset:\n",
    "    my_dir = here(\n",
    "        f\"data/tmp/nfi/growth_and_mortality_data/idp/subset_{round(subset_fraction*100)}%_of_sites\"\n",
    "    )\n",
    "else:\n",
    "    my_dir = here(f\"data/tmp/nfi/growth_and_mortality_data/idp/\")\n",
    "\n",
    "my_dir_files = [x for x in os.listdir(my_dir) if x.endswith(\".feather\")]\n",
    "my_dir_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idp_region_dict = nfi_raw[\n",
    "    [\"idp\", \"campagne_1\", \"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# * Preparation ---------------------------------------------------------------\n",
    "# Set all regions\n",
    "all_regions = [\"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "\n",
    "# Get regions dictionary\n",
    "idp_region_dict = nfi_raw[\n",
    "    [\"idp\", \"campagne_1\"] + [\"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "].drop_duplicates()\n",
    "\n",
    "# For every region, attach variable region_year to df\n",
    "for my_region in all_regions:\n",
    "    idp_region_dict[my_region + \"_year\"] = (\n",
    "        idp_region_dict[my_region].astype(str)\n",
    "        + \"_\"\n",
    "        + idp_region_dict[\"campagne_1\"].astype(str)\n",
    "    )\n",
    "\n",
    "# * Loop over all files -------------------------------------------------------\n",
    "\n",
    "# Loop over all files\n",
    "for my_file in my_dir_files:\n",
    "    # Loop over all regions\n",
    "    for my_region in all_regions:\n",
    "        # Get file\n",
    "        df_loop = pd.read_feather(f\"{my_dir}/{my_file}\")\n",
    "\n",
    "        # Attach region_year information and drop idp to avoid confusion\n",
    "        df_loop = df_loop.merge(\n",
    "            idp_region_dict[[\"idp\", f\"{my_region}_year\"]], on=\"idp\"\n",
    "        ).drop(\"idp\", axis=1)\n",
    "\n",
    "        # Group by region_year and take mean and sd of all variables\n",
    "        # Except for number of plots, which should be summed up\n",
    "        my_agg = {\n",
    "            var: [\"mean\", \"std\"]\n",
    "            for var in df_loop.columns\n",
    "            if var not in [f\"{my_region}_year\", \"n_plots\"]\n",
    "        }\n",
    "        my_agg[\"n_plots\"] = \"sum\"\n",
    "\n",
    "        grouped_df = df_loop.groupby(f\"{my_region}_year\").agg(my_agg)\n",
    "        grouped_df.columns = [\"_\".join((var, stat)) for var, stat in grouped_df.columns]\n",
    "        grouped_df = grouped_df.reset_index()\n",
    "        grouped_df\n",
    "\n",
    "        # Save file\n",
    "        if run_only_subset:\n",
    "            new_dir = here(\n",
    "                f\"data/tmp/nfi/growth_and_mortality_data/aggregated/subset_{round(subset_fraction*100)}%_of_sites\"\n",
    "            )\n",
    "        else:\n",
    "            new_dir = here(f\"data/tmp/nfi/growth_and_mortality_data/aggregated/\")\n",
    "\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "        new_file = my_file.replace(\".feather\", f\"_region-{my_region}.feather\")\n",
    "        grouped_df.to_feather(f\"{new_dir}/{new_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_abies-height_all_region-dep.feather',\n",
       " '/Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_abies-height_all_region-gre.feather',\n",
       " '/Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_abies-height_all_region-hex.feather']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get directory\n",
    "if run_only_subset:\n",
    "    my_dir = here(\n",
    "        f\"data/tmp/nfi/growth_and_mortality_data/direct/subset_{round(subset_fraction*100)}%_of_sites\"\n",
    "    )\n",
    "else:\n",
    "    my_dir = here(f\"data/tmp/nfi/growth_and_mortality_data/direct/\")\n",
    "\n",
    "\n",
    "# List files in directory\n",
    "all_files = sorted(glob.glob(my_dir.as_posix() + \"/*.feather\"))\n",
    "\n",
    "# ! For spatial maps, we are not interested in height classes\n",
    "# Keep only files with pattern \"height_all\"\n",
    "all_files = [x for x in all_files if \"height_all\" in x]\n",
    "\n",
    "print(len(all_files))\n",
    "print(\"Al files:\")\n",
    "display(all_files[:3])\n",
    "\n",
    "print(\"All regions: \", all_regions)\n",
    "print(\"All species: \", all_species)\n",
    "print(\"All heights: \", all_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running files:\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-dep.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-gre.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-hex.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-reg.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-ser.feather\n",
      "Splitting df into 5 random groups\n"
     ]
    }
   ],
   "source": [
    "# ! Shortcut to plot the species of interest one-by-one\n",
    "my_species = \"all\"\n",
    "groups_of_files = [x for x in all_files if f\"species_{my_species}\" in x]\n",
    "print(f\"Running files:\")\n",
    "for g in groups_of_files:\n",
    "    print(f\" - {g}\")\n",
    "\n",
    "ngroups = min(10, len(groups_of_files))\n",
    "groups_of_files = split_df_into_list_of_group_or_ns(groups_of_files, ngroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-ser.feather'],\n",
       "      dtype='<U128')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_of_files[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'all_metrics' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test for one group\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmake_plots_per_file_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups_of_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdirect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_only_subset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_only_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/padasch/ifn_analysis/python/00_process_nfi_data/../../src/utilities.py:1157\u001b[0m, in \u001b[0;36mmake_plots_per_file_parallel\u001b[0;34m(file_group, run_only_subset, subset_fraction, method, verbose)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_plots_per_file_parallel\u001b[39m(\n\u001b[1;32m   1150\u001b[0m     file_group,\n\u001b[1;32m   1151\u001b[0m     run_only_subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1155\u001b[0m ):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m my_file \u001b[38;5;129;01min\u001b[39;00m file_group:\n\u001b[0;32m-> 1157\u001b[0m         \u001b[43mmake_plots_per_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmy_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_only_subset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_only_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubset_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/padasch/ifn_analysis/python/00_process_nfi_data/../../src/utilities.py:1244\u001b[0m, in \u001b[0;36mmake_plots_per_file\u001b[0;34m(my_file, method, run_only_subset, subset_fraction, verbose)\u001b[0m\n\u001b[1;32m   1238\u001b[0m idf_region \u001b[38;5;241m=\u001b[39m df_loop[df_loop[my_region] \u001b[38;5;241m==\u001b[39m i_region]\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# display(idf_region.n_plots.isna().sum())\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;66;03m# display(idf_region.shape[0])\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[1;32m   1242\u001b[0m \u001b[38;5;66;03m# Get the data for the year 2010, subset to metrics\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m data_2010 \u001b[38;5;241m=\u001b[39m idf_region[idf_region[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2010\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\n\u001b[0;32m-> 1244\u001b[0m     \u001b[43mall_metrics\u001b[49m\n\u001b[1;32m   1245\u001b[0m ]\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;66;03m# If there is no data for 2010, skip the region-tile\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;66;03m# if data_2010.dropna().shape[0] == 0:\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \n\u001b[1;32m   1251\u001b[0m \u001b[38;5;66;03m# Loop over all years\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_year \u001b[38;5;129;01min\u001b[39;00m df_loop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;66;03m# Skip the year 2010\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'all_metrics' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# # Test for one group\n",
    "# make_plots_per_file_parallel(\n",
    "#     groups_of_files[4],\n",
    "#     method=\"direct\",\n",
    "#     run_only_subset=run_only_subset,\n",
    "#     subset_fraction=subset_fraction,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running files:\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-dep.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-gre.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-hex.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-reg.feather\n",
      " - /Users/pascal/repos/padasch/ifn_analysis/data/tmp/nfi/growth_and_mortality_data/direct/species_all-height_all_region-ser.feather\n",
      "Splitting df into 5 random groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [48:04<00:00, 576.89s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import make_plots_per_file_parallel\n",
    "\n",
    "# ! Shortcut to plot the species of interest one-by-one\n",
    "my_species = \"all\"\n",
    "groups_of_files = [x for x in all_files if f\"species_{my_species}\" in x]\n",
    "print(f\"Running files:\")\n",
    "for g in groups_of_files:\n",
    "    print(f\" - {g}\")\n",
    "\n",
    "ngroups = min(10, len(groups_of_files))\n",
    "groups_of_files = split_df_into_list_of_group_or_ns(groups_of_files, ngroups)\n",
    "\n",
    "\n",
    "# Run mp\n",
    "run_mp(\n",
    "    make_plots_per_file_parallel,\n",
    "    groups_of_files,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    method=\"direct\",\n",
    "    run_only_subset=run_only_subset,\n",
    "    subset_fraction=subset_fraction,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct\n",
    "\n",
    "- Not implemented yet because this requires having directly region-level calculated mortality rates for all height subsets. Takes a long time to compute and has thus not been done yet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚧 Old Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code for Mapping Divergent colors nicely... not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "# Use some nice font\n",
    "plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans\"\n",
    "\n",
    "# Load the data\n",
    "gdf = df_loop.copy()  # .query(\"year != 2016\")\n",
    "# sp_france = get_shp_of_region(\"cty\")  # Shapefile of France for contour # TODO TURN ON AGAIN!\n",
    "\n",
    "# Unique years to create subplots for\n",
    "unique_years = sorted(gdf[\"year\"].unique())\n",
    "\n",
    "# Set up figure and GridSpec\n",
    "n_cols = int(np.ceil(7 / 2))  # Make sure to fit on two rows\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Allocate the last column for the colorbar and use 2x2 grid for the rest\n",
    "gs = gridspec.GridSpec(\n",
    "    2,\n",
    "    n_cols + 1,\n",
    "    height_ratios=[1, 1],\n",
    "    width_ratios=np.repeat(1, n_cols).tolist() + [0.025],\n",
    ")\n",
    "\n",
    "# ! Color normalization and colormap ------------------------------------------\n",
    "if fig_dic[\"default_cbar\"]:\n",
    "    # Default\n",
    "    data_min = 0\n",
    "    data_max = gdf[fig_dic[\"var\"]].max()\n",
    "    norm = colors.Normalize(vmin=data_min, vmax=data_max)\n",
    "    sm = plt.cm.ScalarMappable(cmap=fig_dic[\"cmap\"], norm=norm)\n",
    "\n",
    "else:\n",
    "    # Create a custom divergent colormap\n",
    "    # Calculate the relative lengths of the negative and positive ranges\n",
    "    data_max = gdf[fig_dic[\"var\"]].max()\n",
    "    data_min = gdf[fig_dic[\"var\"]].min()\n",
    "\n",
    "    if data_min > 0:\n",
    "        raise ValueError(\"Minimum value for divergent cmap is above 0!\")\n",
    "    if data_max < 0:\n",
    "        raise ValueError(\"Maximum value for divergent cmap is below 0!\")\n",
    "\n",
    "    # If data_min or data_max are very small, then make them at least 10% of the range\n",
    "    data_min = -max(abs(data_max) * 0.1, abs(data_min))\n",
    "    data_max = max(abs(data_max), abs(data_min) * 0.1)\n",
    "    data_center = 0\n",
    "\n",
    "    total_range = data_max - data_min\n",
    "    neg_range = data_center - data_min\n",
    "    pos_range = data_max - data_center\n",
    "    neg_proportion = neg_range / total_range\n",
    "    pos_proportion = pos_range / total_range\n",
    "\n",
    "    ## Create the color list, which stretches more on the side with the larger range\n",
    "    list_colors = [(0, \"red\"), (neg_proportion, \"white\"), (1, \"blue\")]\n",
    "\n",
    "    # Create a LinearSegmentedColormap object\n",
    "    fig_dic[\"cmap\"] = LinearSegmentedColormap.from_list(\"custom_diverging\", list_colors)\n",
    "\n",
    "    # Normalization object\n",
    "    norm = plt.Normalize(vmin=data_min, vmax=data_max)\n",
    "    norm = colors.TwoSlopeNorm(vmin=data_min, vcenter=data_center, vmax=data_max)\n",
    "\n",
    "    # Create a scalar mappable object with our custom colormap and normalization\n",
    "    sm = plt.cm.ScalarMappable(cmap=fig_dic[\"cmap\"], norm=norm)\n",
    "\n",
    "    # Create a dummy array for the colorbar to latch onto\n",
    "    sm.set_array([])\n",
    "\n",
    "# ! Iterate over the years and create a subplot for each -----------------------\n",
    "for i, year in enumerate(unique_years):\n",
    "    ax = fig.add_subplot(gs[i // n_cols, i % n_cols])\n",
    "\n",
    "    # Filter the data for the year and plot\n",
    "    data_for_year = gdf[gdf[\"year\"] == year]\n",
    "    # Plot it\n",
    "    plot = data_for_year.plot(\n",
    "        column=fig_dic[\"var\"],\n",
    "        edgecolor=\"face\",\n",
    "        linewidth=0.5,\n",
    "        ax=ax,\n",
    "        cmap=fig_dic[\"cmap\"],\n",
    "        norm=norm,\n",
    "        missing_kwds={\"color\": \"lightgrey\", \"edgecolor\": \"lightgrey\", \"linewidth\": 0.5},\n",
    "    )\n",
    "\n",
    "    # Add countour of France\n",
    "    sp_france.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "    # Remove axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Add year as text below the map\n",
    "    ax.text(0.5, 0, str(year), transform=ax.transAxes, ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "# ! Add colorbar --------------------------------------------------------------\n",
    "# Create a colorbar in the space of the last column of the first row\n",
    "# Span both rows in the last column for the colorbar\n",
    "cbar_ax = fig.add_subplot(gs[0:2, n_cols])\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "cbar.set_label(fig_dic[\"legend\"])\n",
    "\n",
    "# ! Finish up -----------------------------------------------------------------\n",
    "# Adjust layout to accommodate the main title and subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "# After creating your subplots and before showing or saving the figure\n",
    "fig.suptitle(fig_dic[\"main\"], fontsize=16, fontweight=\"bold\", position=(0.5, 1.05))\n",
    "\n",
    "# Show/save the figure\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"test.png\", bbox_inches=\"tight\", pad_inches=0.1, dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# Define the data range and the center for the diverging colormap\n",
    "data_min, data_max = -25, 50  # Replace with your actual data range\n",
    "center = 0\n",
    "\n",
    "# Define the colors for the negative and positive sides, and the center\n",
    "negative_color = \"blue\"\n",
    "positive_color = \"red\"\n",
    "center_color = \"white\"\n",
    "\n",
    "# Calculate the proportion of the negative and positive ranges relative to the total range\n",
    "total_range = data_max - data_min\n",
    "prop_neg = abs(center - data_min) / total_range\n",
    "prop_pos = abs(data_max - center) / total_range\n",
    "\n",
    "# Create the color list with the correct proportions\n",
    "color_list = [\n",
    "    (0, negative_color),\n",
    "    (prop_neg, center_color),\n",
    "    (prop_neg + prop_pos, positive_color),\n",
    "]\n",
    "\n",
    "# Create a LinearSegmentedColormap object\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", color_list)\n",
    "\n",
    "# Normalization object centered at zero\n",
    "norm = mcolors.TwoSlopeNorm(vmin=data_min, vcenter=center, vmax=data_max)\n",
    "\n",
    "# Create a ScalarMappable and initialize a data array for the colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Plot the colorbar\n",
    "plt.figure(figsize=(8, 2))\n",
    "cbar = plt.colorbar(sm, orientation=\"horizontal\")\n",
    "cbar.set_label(\"Change of Basal Area [%/yr]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data range for the diverging colormap\n",
    "data_min, data_max = -20, 100  # Replace with the actual range of xxx\n",
    "\n",
    "# Calculate the absolute maximum value\n",
    "abs_max = max(abs(data_min), abs(data_max))\n",
    "\n",
    "# Define the colors for the negative and positive sides\n",
    "negative_color = \"blue\"\n",
    "positive_color = \"red\"\n",
    "\n",
    "# Create the color list with the correct proportions\n",
    "color_list = [\n",
    "    (0, negative_color),\n",
    "    (0.5, \"white\"),\n",
    "    (1, positive_color),\n",
    "]\n",
    "\n",
    "color_list_ = [\n",
    "    (0, negative_color),\n",
    "    (data_max / abs(data_min), \"white\"),\n",
    "    (1, positive_color),\n",
    "]\n",
    "\n",
    "# Create a LinearSegmentedColormap object\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", color_list)\n",
    "custom_cmap_ = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap_\", color_list_)\n",
    "\n",
    "# Normalize the data to range from -1 to 1\n",
    "norm = colors.TwoSlopeNorm(vmin=-data_max, vcenter=data_center, vmax=data_max)\n",
    "norm_ = colors.TwoSlopeNorm(vmin=data_min, vcenter=data_center, vmax=data_max)\n",
    "sm = plt.cm.ScalarMappable(cmap=custom_cmap_, norm=norm_)\n",
    "sm.set_array([])\n",
    "\n",
    "# Generate some sample data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "xxx = np.random.uniform(data_min, data_max, 100)\n",
    "xxx.sort()  # Sort the xxx array in ascending order\n",
    "\n",
    "# Plot the scatter plot with divergent colors\n",
    "plt.scatter(xxx, y, c=xxx, cmap=custom_cmap, norm=norm, edgecolors=\"black\")\n",
    "\n",
    "# Plot the colorbar\n",
    "cbar = plt.colorbar(sm)\n",
    "cbar.set_label(\"xxx\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Patterns\n",
    "\n",
    "- There are two approaches:\n",
    "\n",
    "  - Direct: Aggregate trees to given area and calculate change _directly_ at this level\n",
    "    - To assess the uncertainty per area and year, this approach requires a bootstrapping\n",
    "  - Aggregated: Aggregate trees to site and take the mean over the given area\n",
    "    - To assess the uncertainty per area and year, this approach simply reports the mean and sd across sites\n",
    "\n",
    "- Plus, we are interested in all species and in species subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from utilities import calculate_growth_mortality\n",
    "from run_mp import run_mp\n",
    "\n",
    "# Get factorial setup\n",
    "all_regions = [\"idp\", \"reg\", \"dep\", \"gre\", \"ser\", \"hex\"]\n",
    "all_species = [\"all\"] + nfi_raw[\"genus_lat\"].value_counts().sort_values(ascending=False)\n",
    "all_species = all_species.head(10).index.tolist()\n",
    "all_heights = [\"all\"] + df_merged[\"tree_height_class\"].value_counts().index.tolist()\n",
    "all_heights.remove(\"Missing\")\n",
    "\n",
    "# Make sure poplars are in there\n",
    "if \"Populus\" not in all_species:\n",
    "    all_species.append(\"Populus\")\n",
    "\n",
    "# Get input df\n",
    "df_in = nfi_raw.copy()\n",
    "\n",
    "# Loop over species\n",
    "for my_species in all_species:\n",
    "    # Loop over heights\n",
    "    for my_height in all_heights:\n",
    "        # Get new df\n",
    "        df_loop = df_in.copy()\n",
    "\n",
    "        # Filter for species\n",
    "        if my_species != \"all\":\n",
    "            df_loop = df_loop.query(f\"genus_lat == '{my_species}'\")\n",
    "\n",
    "        # Filter for height\n",
    "        if my_height != \"all\":\n",
    "            df_loop = df_loop.query(f\"tree_height_class == '{my_height}'\")\n",
    "\n",
    "        # Loop over regions\n",
    "        for my_region in all_regions:\n",
    "            # Get filename and print it\n",
    "            my_dir = here(\n",
    "                str.lower(f\"data/tmp/nfi/growth_and_mortality_data/direct_approach\")\n",
    "            )\n",
    "            os.makedirs(my_dir, exist_ok=True)\n",
    "            my_file = str.lower(f\"species_{my_species}-area_{my_region}\")\n",
    "            my_dirfile = f\"{my_dir}/{my_file}.feather\"\n",
    "\n",
    "            # Check if file already exists, if so skip current loop\n",
    "            if os.path.isfile(my_dirfile) and not force_rerunning_all_sites:\n",
    "                print(f\" - File already exists: {my_file}, skipping it\")\n",
    "                continue\n",
    "\n",
    "            # Verbose\n",
    "            print(str.lower(f\"\\n - Working on: {my_file}\"))\n",
    "\n",
    "            my_region_tmp = my_region\n",
    "\n",
    "            # IDP holds year information, so no need to add there\n",
    "            # But grouping for other regions need this time information\n",
    "            if my_region != \"idp\":\n",
    "                my_region = my_region + \"_year\"\n",
    "                df_loop[my_region] = (\n",
    "                    df_loop[my_region_tmp].astype(str)\n",
    "                    + \"_\"\n",
    "                    + df_loop[\"campagne_1\"].astype(str)\n",
    "                )\n",
    "\n",
    "            # Create list and run mp\n",
    "            df_list = [\n",
    "                group for name, group in df_loop.groupby(my_region, as_index=False)\n",
    "            ]\n",
    "            df_mp = run_mp(\n",
    "                calculate_growth_mortality,\n",
    "                df_list,\n",
    "                combine_func=pd.concat,\n",
    "                progress_bar=True,\n",
    "                num_cores=10,\n",
    "                min_trees_per_plot=1,\n",
    "                grouping_variable=my_region,\n",
    "            )\n",
    "\n",
    "            # Save df\n",
    "            df_mp.reset_index(drop=True).to_feather(my_dirfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the idp-level data for each species and calculate the mean and sd over desired region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Patterns\n",
    "\n",
    "- For the temporal patterns, we can again do the holistic or the mean-approach:\n",
    "- For now, to save time, I am only doing the mean approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Approach\n",
    "\n",
    "- For this, I need factorial species-height subsets but only at the idp level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics of change at region-level\n",
    "all_regions = [\"idp\"]\n",
    "all_species = [\"all\"] + df_merged[\"genus_lat\"].value_counts().head(10).index.tolist()\n",
    "all_heights = [\"all\"] + df_merged[\"tree_height_class\"].value_counts().index.tolist()\n",
    "all_heights.remove(\"Missing\")\n",
    "\n",
    "from utilities import calculate_growth_mortality\n",
    "from run_mp import run_mp\n",
    "\n",
    "df_in = df_merged.copy()\n",
    "group_per_height = True\n",
    "\n",
    "for my_species in all_species:\n",
    "    for my_height in all_heights:\n",
    "        # Get new df\n",
    "        df_loop = df_in.copy()\n",
    "        # Filter for species\n",
    "        if my_species != \"all\":\n",
    "            df_loop = df_loop.query(f\"genus_lat == '{my_species}'\")\n",
    "        # Filter for height\n",
    "        if my_height != \"all\":\n",
    "            df_loop = df_loop.query(f\"tree_height_class == '{my_height}'\")\n",
    "\n",
    "        for my_region in all_regions:\n",
    "            my_file = str.lower(\n",
    "                f\"species_{my_species}__tree_heights_{my_height}__area_{my_region}\"\n",
    "            )\n",
    "\n",
    "            print(str.lower(f\"\\n - Working on: {my_file}\"))\n",
    "\n",
    "            my_region_tmp = my_region\n",
    "\n",
    "            # IDP holds year information, so no need to add there\n",
    "            # But grouping for other regions need this information\n",
    "            if my_region != \"idp\":\n",
    "                my_region = my_region + \"_year\"\n",
    "                df_loop[my_region] = (\n",
    "                    df_loop[my_region_tmp].astype(str)\n",
    "                    + \"_\"\n",
    "                    + df_loop[\"campagne_1\"].astype(str)\n",
    "                )\n",
    "\n",
    "            # Create list and run mp\n",
    "            df_list = [\n",
    "                group for name, group in df_loop.groupby(my_region, as_index=False)\n",
    "            ]\n",
    "            df_mp = run_mp(\n",
    "                calculate_growth_mortality,\n",
    "                df_list,\n",
    "                combine_func=pd.concat,\n",
    "                progress_bar=True,\n",
    "                num_cores=10,\n",
    "                min_trees_per_plot=1,\n",
    "                grouping_variable=my_region,\n",
    "            )\n",
    "\n",
    "            # Save df\n",
    "            my_dir = here(str.lower(f\"data/tmp/dfs_metrics_of_change/area-level/\"))\n",
    "            if not os.path.exists(my_dir):\n",
    "                os.makedirs(my_dir)\n",
    "            df_mp.reset_index(drop=True).to_feather(f\"{my_dir}/{my_file}.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_hex10 = gpd.read_file(here(\"qgis/hexmaps/hexmap_10000.geojson\"))\n",
    "shp_hex12 = gpd.read_file(here(\"qgis/hexmaps/hexmap_12500.geojson\"))\n",
    "shp_hex25 = gpd.read_file(here(\"qgis/hexmaps/hexmap_25000.geojson\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFI Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NFI data ready for analysis\n",
    "data = pd.read_feather(\"nfi_ready_for_spatial_temporal_analysis.feather\")\n",
    "\n",
    "# Move ser and gre columns to the start\n",
    "data.insert(0, \"ser\", data.pop(\"ser\"))\n",
    "data.insert(0, \"gre\", data.pop(\"gre\"))\n",
    "data.insert(0, \"lat\", data.pop(\"lat\"))\n",
    "data.insert(0, \"lon\", data.pop(\"lon\"))\n",
    "data.insert(0, \"campagne_1\", data.pop(\"campagne_1\"))\n",
    "data.insert(0, \"idp\", data.pop(\"idp\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of genus-espar\n",
    "dict_species = data[[\"genus_lat\", \"espar_red\"]].drop_duplicates().reset_index(drop=True)\n",
    "dict_species[\"espar_red\"].value_counts(ascending=True).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_species.query(\"espar_red == '68'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_species.query(\"genus_lat == 'Abies'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric of Change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate on site-level for aggregation to larger region later on\n",
    "df_list = data.groupby(\"idp\", as_index=False)\n",
    "df_list = [group for name, group in df_list]\n",
    "df_site = run_mp(\n",
    "    calculate_growth_mortality,\n",
    "    df_list,\n",
    "    combine_func=pd.concat,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    divide_by_nplots=True,\n",
    "    grouping_variable=my_group,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Level\n",
    "df_list = data.groupby(\"reg\", as_index=False)\n",
    "df_list = [group for name, group in df_list]\n",
    "df_reg = run_mp(\n",
    "    calculate_growth_mortality,\n",
    "    df_list,\n",
    "    combine_func=pd.concat,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    grouping_variable=\"reg\",\n",
    "    divide_by_nplots=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department Level\n",
    "df_list = data.groupby(\"dep\", as_index=False)\n",
    "df_list = [group for name, group in df_list]\n",
    "df_dep = run_mp(\n",
    "    calculate_growth_mortality,\n",
    "    df_list,\n",
    "    combine_func=pd.concat,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    grouping_variable=\"dep\",\n",
    "    divide_by_nplots=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sylvoregion Level\n",
    "df_list = data.groupby(\"ser\", as_index=False)\n",
    "df_list = [group for name, group in df_list]\n",
    "df_ser = run_mp(\n",
    "    calculate_growth_mortality,\n",
    "    df_list,\n",
    "    combine_func=pd.concat,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    grouping_variable=\"ser\",\n",
    "    divide_by_nplots=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greco Level\n",
    "df_list = data.groupby(\"gre\", as_index=False)\n",
    "df_list = [group for name, group in df_list]\n",
    "df_gre = run_mp(\n",
    "    calculate_growth_mortality,\n",
    "    df_list,\n",
    "    combine_func=pd.concat,\n",
    "    progress_bar=True,\n",
    "    num_cores=10,\n",
    "    grouping_variable=\"gre\",\n",
    "    divide_by_nplots=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics of Change\n",
    "\n",
    "**Target:** Mean of Metric within Region\n",
    "\n",
    "Routine:\n",
    "\n",
    "- Filter for tree subset\n",
    "- For each site, calculate metrics of change\n",
    "- Group sites by given variable (ser, gre, dep, reg, hex)\n",
    "- Calculate the mean and sd for that group\n",
    "- Plot mean and sd for that group\n",
    "\n",
    "**Alternative:** Calculate total change per region (aggregate all sites to one instead of taking the mean across sites).\n",
    "\n",
    "**Maps:**\n",
    "\n",
    "- Plot The difference relative to 2010 Campagnes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifna-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
