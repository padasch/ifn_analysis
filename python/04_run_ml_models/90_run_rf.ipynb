{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìú Libraries and Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Data visualisation\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import f\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# My functions\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from run_mp import *\n",
    "from utilities import *\n",
    "from random_forest_utils import *\n",
    "\n",
    "# Other\n",
    "from os import error\n",
    "import datetime\n",
    "from io import StringIO\n",
    "import re\n",
    "import warnings\n",
    "import chime\n",
    "from pyprojroot import here\n",
    "\n",
    "chime.theme(\"mario\")\n",
    "\n",
    "# Magic\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üë§ User Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options:\n",
    "\n",
    "# - imputation_method = knn mean median minus_9999\n",
    "# - weight_method = none squared cubic quadratic inverse inverse_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFI file name\n",
    "nfi_file_name = \"20231201-103649_nfi_dataset_for_analysis copy.csv\"\n",
    "\n",
    "# Folder prefix\n",
    "folder_suffix = \"\"  # None for no prefix\n",
    "\n",
    "user_input = {\n",
    "    # Add Datasets\n",
    "    \"add_nfi_original\": True,\n",
    "    \"add_nfi_derivatives\": True,\n",
    "    \"add_gee_data\": True,\n",
    "    \"add_rmqs_data\": False,\n",
    "    \"add_edo_data\": False,\n",
    "    \"add_apt_data\": False,\n",
    "    \"add_dem_data\": True,\n",
    "    # Subsetting NFIx\n",
    "    \"rerun_calculation_growth_mortality\": True,  # ONLY HAVE TO RERUN THIS IF SUBSETTING SPECIES!\n",
    "    \"subset_nfi\": False,\n",
    "    \"subset_min_trees_per_plot\": 10,  # Set to None or 0 for no subsetting\n",
    "    \"subset_species\": \"Quercus\",  # Set to \"all\" for no subsetting\n",
    "    # Feature Selection\n",
    "    \"na_drop_threshold\": 0.1,\n",
    "    # Entry Selection\n",
    "    \"add_target_0s\": False,  # False = Remove all 0 values from target\n",
    "    \"add_target_0s_percentage\": 0.01,\n",
    "    \"add_target_0s_strata\": \"ser\",  # Set to \"none\" if no strata should be used\n",
    "    # Entry imputation\n",
    "    \"imputation_method\": \"mean\",\n",
    "    # üéØ RF Definition\n",
    "    \"target\": \"mort_ba_prc_yr_v1\",\n",
    "    \"test_train_strata\": [\n",
    "        \"gre\",\n",
    "        \"campagne_1\",\n",
    "        \"top1_species_nfi\",\n",
    "    ],\n",
    "    # Regression\n",
    "    \"reduce_to_percentile\": False,  # If True, reduce dataset to percentile\n",
    "    \"percentile_n_group\": 5,  # Data should be split into how many groups\n",
    "    \"percentile_group\": 4,  # Which group should be used (starting indexing at 0)!\n",
    "    # Classification\n",
    "    \"make_classification\": False,\n",
    "    \"classification_groups\": 5,\n",
    "    # ‚öôÔ∏è RF Tuning\n",
    "    \"weight_method\": \"none\",\n",
    "    \"cv_folds\": 5,\n",
    "    \"test_split\": 0.3,\n",
    "    \"do_random_search\": False,\n",
    "    \"do_prescribed_search\": False,\n",
    "    \"do_ref\": False,\n",
    "    \"seed_nr\": 42,\n",
    "}\n",
    "\n",
    "# Data Wrangling\n",
    "run_reports_major = True\n",
    "run_reports_minor = False\n",
    "\n",
    "# --------------------------------------------------\n",
    "# GREY = KEEP\n",
    "# GREEN = REMOVED\n",
    "# If not specified otherwise in google sheet or in routine\n",
    "\n",
    "user_input_variable_removal = [\n",
    "    # ! Variables with temporal information\n",
    "    # \"campagne_1\",\n",
    "    \"campagne_2\",\n",
    "    \"visite_1\",\n",
    "    \"visite_2\",\n",
    "    \"census_interval\",\n",
    "    # ! Variables with spatial information\n",
    "    \"ser\",\n",
    "    \"gre\",\n",
    "    \"dep\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"lat_fr\",\n",
    "    \"lon_fr\",\n",
    "    # ! Variables from NFI derivatives that hold ba information\n",
    "    \"site_ba_prc_cut_at_v2\",\n",
    "    \"site_ba_prc_dead_at_v1\",\n",
    "    \"site_ba_prc_dead_at_v2\",\n",
    "    \"site_ba_prc_rec_at_v2\",\n",
    "    \"site_total_ba_at_v1\",\n",
    "    \"site_total_ba_at_v2\",\n",
    "    \"ntrees_1\",\n",
    "    \"ntrees_2\",\n",
    "    # ! Variables from calculation_growth_mortality:\n",
    "    # * General variables / stand descriptions\n",
    "    \"idp\",\n",
    "    \"n_plots\",\n",
    "    \"n_ini\",\n",
    "    \"n_sur\",\n",
    "    \"n_fin\",\n",
    "    \"n_rec\",\n",
    "    \"n_die\",\n",
    "    \"ba_at_v1_of_alive_trees\",\n",
    "    \"ba_at_v2_of_alive_trees\",\n",
    "    \"ba_at_v1_of_survivors\",\n",
    "    \"ba_at_v2_of_survivors\",\n",
    "    \"ba_at_v1_of_dead\",\n",
    "    \"ba_at_v2_of_dead\",\n",
    "    \"ba_at_v2_of_recruits\",\n",
    "    # * Growth and Mortality variables\n",
    "    \"mort_stems_prc_yr_esq\",  # <--- Target variable ESQ\n",
    "    \"mort_stems_prc_yr_hoshino\",\n",
    "    \"rec_stems_prc_yr_hoshino\",\n",
    "    \"mort_ba_prc_yr_hoshino\",\n",
    "    \"tot_growth_ba_prc_yr_hoshino\",\n",
    "    \"sur_growth_ba_prc_yr_hoshino\",\n",
    "    \"tot_growth_ba_yr\",\n",
    "    \"sur_growth_ba_yr\",\n",
    "    \"mort_ba_yr_v1\",  # <--- Target variable ABS\n",
    "    \"mort_ba_yr_v2\",\n",
    "    \"tot_growth_ba_prc_yr\",\n",
    "    \"sur_growth_ba_prc_yr\",\n",
    "    \"mort_ba_prc_yr_v1\",  # <--- Target variable PRC\n",
    "    \"mort_ba_prc_yr_v2\",\n",
    "]\n",
    "\n",
    "user_input[\"features_to_remove\"] = user_input_variable_removal\n",
    "\n",
    "# --------------------------------------------------\n",
    "# TODO: Needs to be cleaned up\n",
    "add_gee_data = user_input[\"add_gee_data\"]\n",
    "target = user_input[\"target\"]\n",
    "na_drop_threshold = user_input[\"na_drop_threshold\"]\n",
    "seed_nr = user_input[\"seed_nr\"]\n",
    "test_split = user_input[\"test_split\"]\n",
    "test_train_strata = user_input[\"test_train_strata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current directory\n",
    "current_dir = create_new_run_folder(folder_suffix=folder_suffix)\n",
    "\n",
    "# Write to file\n",
    "file_path = f\"{current_dir}/user_input.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    for key, value in user_input.items():\n",
    "        if isinstance(value, list):\n",
    "            file.write(f\"{key}:\")\n",
    "            for v in value:\n",
    "                file.write(f\"\\n - {v}\")\n",
    "            file.write(\"\\n\\n\")\n",
    "        else:\n",
    "            file.write(f\"{key}:\\n - {value}\\n\\n\")\n",
    "\n",
    "\n",
    "# Create txt file with name\n",
    "def write_txt(text):\n",
    "    with open(text, \"w\") as file:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Add a few quick_see_files\n",
    "write_txt(f\"{current_dir}/_{user_input['target']}.txt\")\n",
    "write_txt(f\"{current_dir}/_classification_{user_input['make_classification']}.txt\")\n",
    "write_txt(\n",
    "    f\"{current_dir}/_percentile_{user_input['reduce_to_percentile']}_group_{user_input['percentile_group']+1}of{user_input['percentile_n_group']}.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíΩ Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Stand Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_subset_mortality_group = True\n",
    "subset_variable = \"genus_lat\"\n",
    "subset_level = \"Quercus\"\n",
    "# # Additional user_input filters\n",
    "# shape_org = nfi_subsetted_trees.shape\n",
    "# nfi_user_subset = nfi_subsetted_trees.copy()\n",
    "\n",
    "# # Species Subsetting\n",
    "# if user_input[\"subset_species\"] != \"all\":\n",
    "#     nfi_user_subset = nfi_user_subset.query(\n",
    "#         f\"genus_lat == '{user_input['subset_species']}'\"\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Filter subset_species \\t| Subsetting to species {user_input['subset_species']}:\\t\\t {nfi_user_subset.shape}\"\n",
    "#     )\n",
    "\n",
    "# else:\n",
    "#     # No subsetting\n",
    "#     print(\"No subsetting done.\")\n",
    "\n",
    "# write_txt(f\"{current_dir}/_species-genus_lat-subset_{user_input['subset_species']}.txt\")\n",
    "\n",
    "# print(\n",
    "#     f\"\\nSubsetting based on user input changed df from \\n {shape_org} to \\n {nfi_user_subset.shape}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_subset_mortality = nfi_filter_trees[\n",
    "    [\n",
    "        \"idp\",\n",
    "        \"group_id\",\n",
    "        \"ba_1\",\n",
    "        \"ba_2\",\n",
    "        \"tree_state_change\",\n",
    "        \"tree_state_1\",\n",
    "        \"tree_state_2\",\n",
    "        \"genus_lat\",\n",
    "        \"species_lat\",\n",
    "        \"espar_red\",\n",
    "    ]\n",
    "]\n",
    "# df_for_subset_mortality = df_for_subset_mortality.query(\"idp == 501554\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4987/4987 [00:07<00:00, 680.21it/s] \n"
     ]
    }
   ],
   "source": [
    "if do_subset_mortality_group:\n",
    "    # Subset to mortality group\n",
    "    ss_grouped = df_for_subset_mortality[\n",
    "        nfi_filter_trees[\"genus_lat\"] == subset_level\n",
    "    ].groupby(\"group_id\", as_index=False)\n",
    "    # Get list of dataframes\n",
    "    ss_df_list = [group for name, group in ss_grouped]\n",
    "    ss_df_list = ss_df_list  # For debug, reduce number to 100 sites only\n",
    "    # Do multiprocess\n",
    "    ss_df_mp = run_mp(\n",
    "        calculate_growth_mortality,\n",
    "        ss_df_list,\n",
    "        combine_func=pd.concat,\n",
    "        progress_bar=True,\n",
    "        num_cores=10,\n",
    "    )\n",
    "ss_df_mp.reset_index(drop=True).to_feather(\"tmp_ss_df_mp.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "ss_df_mp[\"sur_growth_ba_prc_yr\"].plot(kind=\"hist\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idp</th>\n",
       "      <th>ss_n_plots</th>\n",
       "      <th>ss_n_ini</th>\n",
       "      <th>ss_n_sur</th>\n",
       "      <th>ss_n_fin</th>\n",
       "      <th>ss_n_rec</th>\n",
       "      <th>ss_n_die</th>\n",
       "      <th>ss_ba_at_v1_of_alive_trees</th>\n",
       "      <th>ss_ba_at_v2_of_alive_trees</th>\n",
       "      <th>ss_ba_at_v1_of_survived</th>\n",
       "      <th>...</th>\n",
       "      <th>ss_tot_growth_ba_prc_yr_hoshino</th>\n",
       "      <th>ss_sur_growth_ba_prc_yr_hoshino</th>\n",
       "      <th>ss_tot_growth_ba_yr</th>\n",
       "      <th>ss_sur_growth_ba_yr</th>\n",
       "      <th>ss_mort_ba_yr_v1</th>\n",
       "      <th>ss_mort_ba_yr_v2</th>\n",
       "      <th>ss_tot_growth_ba_prc_yr</th>\n",
       "      <th>ss_sur_growth_ba_prc_yr</th>\n",
       "      <th>ss_mort_ba_prc_yr_v1</th>\n",
       "      <th>ss_mort_ba_prc_yr_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441355</td>\n",
       "      <td>0.554835</td>\n",
       "      <td>0.441355</td>\n",
       "      <td>...</td>\n",
       "      <td>4.576414</td>\n",
       "      <td>4.576414</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.142332</td>\n",
       "      <td>5.142332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.186905</td>\n",
       "      <td>29.109171</td>\n",
       "      <td>27.186905</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366357</td>\n",
       "      <td>1.366357</td>\n",
       "      <td>0.384453</td>\n",
       "      <td>0.384453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414111</td>\n",
       "      <td>1.414111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895274</td>\n",
       "      <td>1.095890</td>\n",
       "      <td>0.895274</td>\n",
       "      <td>...</td>\n",
       "      <td>4.043845</td>\n",
       "      <td>4.043845</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.481666</td>\n",
       "      <td>4.481666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500331</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.232861</td>\n",
       "      <td>39.199545</td>\n",
       "      <td>36.232861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573974</td>\n",
       "      <td>1.573974</td>\n",
       "      <td>0.593337</td>\n",
       "      <td>0.593337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.637566</td>\n",
       "      <td>1.637566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500653</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.332574</td>\n",
       "      <td>7.718242</td>\n",
       "      <td>6.332574</td>\n",
       "      <td>...</td>\n",
       "      <td>3.957598</td>\n",
       "      <td>3.957598</td>\n",
       "      <td>0.277134</td>\n",
       "      <td>0.277134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.376320</td>\n",
       "      <td>4.376320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idp  ss_n_plots  ss_n_ini  ss_n_sur  ss_n_fin  ss_n_rec  ss_n_die  \\\n",
       "0  500137           1         1         1         1         0         0   \n",
       "0  500214           1         1         1         1         0         0   \n",
       "0  500284           1         1         1         1         0         0   \n",
       "0  500331           1         1         1         1         0         0   \n",
       "0  500653           1         1         1         1         0         0   \n",
       "\n",
       "   ss_ba_at_v1_of_alive_trees  ss_ba_at_v2_of_alive_trees  \\\n",
       "0                    0.441355                    0.554835   \n",
       "0                   27.186905                   29.109171   \n",
       "0                    0.895274                    1.095890   \n",
       "0                   36.232861                   39.199545   \n",
       "0                    6.332574                    7.718242   \n",
       "\n",
       "   ss_ba_at_v1_of_survived  ...  ss_tot_growth_ba_prc_yr_hoshino  \\\n",
       "0                 0.441355  ...                         4.576414   \n",
       "0                27.186905  ...                         1.366357   \n",
       "0                 0.895274  ...                         4.043845   \n",
       "0                36.232861  ...                         1.573974   \n",
       "0                 6.332574  ...                         3.957598   \n",
       "\n",
       "   ss_sur_growth_ba_prc_yr_hoshino  ss_tot_growth_ba_yr  ss_sur_growth_ba_yr  \\\n",
       "0                         4.576414             0.022696             0.022696   \n",
       "0                         1.366357             0.384453             0.384453   \n",
       "0                         4.043845             0.040123             0.040123   \n",
       "0                         1.573974             0.593337             0.593337   \n",
       "0                         3.957598             0.277134             0.277134   \n",
       "\n",
       "   ss_mort_ba_yr_v1  ss_mort_ba_yr_v2  ss_tot_growth_ba_prc_yr  \\\n",
       "0               0.0               0.0                 5.142332   \n",
       "0               0.0               0.0                 1.414111   \n",
       "0               0.0               0.0                 4.481666   \n",
       "0               0.0               0.0                 1.637566   \n",
       "0               0.0               0.0                 4.376320   \n",
       "\n",
       "   ss_sur_growth_ba_prc_yr  ss_mort_ba_prc_yr_v1  ss_mort_ba_prc_yr_v2  \n",
       "0                 5.142332                   0.0                   0.0  \n",
       "0                 1.414111                   0.0                   0.0  \n",
       "0                 4.481666                   0.0                   0.0  \n",
       "0                 1.637566                   0.0                   0.0  \n",
       "0                 4.376320                   0.0                   0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach prefix\n",
    "xxx = ss_df_mp.add_prefix(\"ss_\").rename(\n",
    "    columns={\"ss_group_id\": \"group_id\", \"ss_idp\": \"idp\"}\n",
    ")\n",
    "xxx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idp</th>\n",
       "      <th>ss_n_plots</th>\n",
       "      <th>ss_n_ini</th>\n",
       "      <th>ss_n_sur</th>\n",
       "      <th>ss_n_fin</th>\n",
       "      <th>ss_n_rec</th>\n",
       "      <th>ss_n_die</th>\n",
       "      <th>ss_ba_at_v1_of_alive_trees</th>\n",
       "      <th>ss_ba_at_v2_of_alive_trees</th>\n",
       "      <th>ss_ba_at_v1_of_survived</th>\n",
       "      <th>...</th>\n",
       "      <th>ss_tot_growth_ba_prc_yr_hoshino</th>\n",
       "      <th>ss_sur_growth_ba_prc_yr_hoshino</th>\n",
       "      <th>ss_tot_growth_ba_yr</th>\n",
       "      <th>ss_sur_growth_ba_yr</th>\n",
       "      <th>ss_mort_ba_yr_v1</th>\n",
       "      <th>ss_mort_ba_yr_v2</th>\n",
       "      <th>ss_tot_growth_ba_prc_yr</th>\n",
       "      <th>ss_sur_growth_ba_prc_yr</th>\n",
       "      <th>ss_mort_ba_prc_yr_v1</th>\n",
       "      <th>ss_mort_ba_prc_yr_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501554</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.418238</td>\n",
       "      <td>38.295760</td>\n",
       "      <td>34.703316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.970079</td>\n",
       "      <td>1.970079</td>\n",
       "      <td>0.718489</td>\n",
       "      <td>0.718489</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>2.070375</td>\n",
       "      <td>2.070375</td>\n",
       "      <td>0.403703</td>\n",
       "      <td>0.366526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502343</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.135755</td>\n",
       "      <td>23.857086</td>\n",
       "      <td>21.958732</td>\n",
       "      <td>...</td>\n",
       "      <td>1.658328</td>\n",
       "      <td>1.658328</td>\n",
       "      <td>0.379671</td>\n",
       "      <td>0.379671</td>\n",
       "      <td>1.328037</td>\n",
       "      <td>1.369862</td>\n",
       "      <td>1.729019</td>\n",
       "      <td>1.729019</td>\n",
       "      <td>3.779731</td>\n",
       "      <td>4.461163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502856</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.190134</td>\n",
       "      <td>55.447005</td>\n",
       "      <td>51.230422</td>\n",
       "      <td>...</td>\n",
       "      <td>1.581883</td>\n",
       "      <td>1.581883</td>\n",
       "      <td>0.843316</td>\n",
       "      <td>0.843316</td>\n",
       "      <td>1.191942</td>\n",
       "      <td>1.191942</td>\n",
       "      <td>1.646124</td>\n",
       "      <td>1.646124</td>\n",
       "      <td>2.084175</td>\n",
       "      <td>1.941062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502874</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.314879</td>\n",
       "      <td>43.101221</td>\n",
       "      <td>40.160475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.413360</td>\n",
       "      <td>1.413360</td>\n",
       "      <td>0.588149</td>\n",
       "      <td>0.588149</td>\n",
       "      <td>4.030881</td>\n",
       "      <td>4.103508</td>\n",
       "      <td>1.464498</td>\n",
       "      <td>1.464498</td>\n",
       "      <td>6.683062</td>\n",
       "      <td>6.450154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>503379</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.165269</td>\n",
       "      <td>15.003641</td>\n",
       "      <td>12.334436</td>\n",
       "      <td>...</td>\n",
       "      <td>3.917958</td>\n",
       "      <td>3.917958</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>0.088271</td>\n",
       "      <td>0.088271</td>\n",
       "      <td>4.328054</td>\n",
       "      <td>4.328054</td>\n",
       "      <td>0.670484</td>\n",
       "      <td>0.571519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1130924</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.800112</td>\n",
       "      <td>2.841857</td>\n",
       "      <td>2.459268</td>\n",
       "      <td>...</td>\n",
       "      <td>2.891878</td>\n",
       "      <td>2.891878</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.076518</td>\n",
       "      <td>0.068169</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>3.111404</td>\n",
       "      <td>3.111404</td>\n",
       "      <td>2.434506</td>\n",
       "      <td>1.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131093</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.639862</td>\n",
       "      <td>1.543961</td>\n",
       "      <td>1.420523</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666516</td>\n",
       "      <td>1.666516</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.443868</td>\n",
       "      <td>0.443868</td>\n",
       "      <td>1.737917</td>\n",
       "      <td>1.737917</td>\n",
       "      <td>12.194633</td>\n",
       "      <td>11.794645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131233</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.391338</td>\n",
       "      <td>11.855575</td>\n",
       "      <td>10.949983</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589207</td>\n",
       "      <td>1.589207</td>\n",
       "      <td>0.181119</td>\n",
       "      <td>0.181119</td>\n",
       "      <td>0.088271</td>\n",
       "      <td>0.077896</td>\n",
       "      <td>1.654053</td>\n",
       "      <td>1.654053</td>\n",
       "      <td>0.774896</td>\n",
       "      <td>0.636140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131278</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.570699</td>\n",
       "      <td>56.237545</td>\n",
       "      <td>52.296726</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453016</td>\n",
       "      <td>1.453016</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>0.054794</td>\n",
       "      <td>1.507100</td>\n",
       "      <td>1.507100</td>\n",
       "      <td>0.104230</td>\n",
       "      <td>0.096962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131410</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.712729</td>\n",
       "      <td>2.261525</td>\n",
       "      <td>2.100996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.472559</td>\n",
       "      <td>1.472559</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>1.922347</td>\n",
       "      <td>1.932346</td>\n",
       "      <td>1.528125</td>\n",
       "      <td>1.528125</td>\n",
       "      <td>16.412457</td>\n",
       "      <td>16.206530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1654 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        idp  ss_n_plots  ss_n_ini  ss_n_sur  ss_n_fin  ss_n_rec  ss_n_die  \\\n",
       "0    501554           1        13        12        12         0         1   \n",
       "0    502343           1         4         2         2         0         1   \n",
       "0    502856           1        10         8         8         0         2   \n",
       "0    502874           1         7         6         6         0         1   \n",
       "0    503379           1        10         8         8         0         1   \n",
       "..      ...         ...       ...       ...       ...       ...       ...   \n",
       "0   1130924           1         3         2         2         0         1   \n",
       "0   1131093           1         3         2         2         0         1   \n",
       "0   1131233           1         4         3         3         0         1   \n",
       "0   1131278           1         5         4         4         0         1   \n",
       "0   1131410           1         2         1         1         0         1   \n",
       "\n",
       "    ss_ba_at_v1_of_alive_trees  ss_ba_at_v2_of_alive_trees  \\\n",
       "0                    35.418238                   38.295760   \n",
       "0                    35.135755                   23.857086   \n",
       "0                    57.190134                   55.447005   \n",
       "0                    60.314879                   43.101221   \n",
       "0                    13.165269                   15.003641   \n",
       "..                         ...                         ...   \n",
       "0                     2.800112                    2.841857   \n",
       "0                     3.639862                    1.543961   \n",
       "0                    11.391338                   11.855575   \n",
       "0                    52.570699                   56.237545   \n",
       "0                    11.712729                    2.261525   \n",
       "\n",
       "    ss_ba_at_v1_of_survived  ...  ss_tot_growth_ba_prc_yr_hoshino  \\\n",
       "0                 34.703316  ...                         1.970079   \n",
       "0                 21.958732  ...                         1.658328   \n",
       "0                 51.230422  ...                         1.581883   \n",
       "0                 40.160475  ...                         1.413360   \n",
       "0                 12.334436  ...                         3.917958   \n",
       "..                      ...  ...                              ...   \n",
       "0                  2.459268  ...                         2.891878   \n",
       "0                  1.420523  ...                         1.666516   \n",
       "0                 10.949983  ...                         1.589207   \n",
       "0                 52.296726  ...                         1.453016   \n",
       "0                  2.100996  ...                         1.472559   \n",
       "\n",
       "    ss_sur_growth_ba_prc_yr_hoshino  ss_tot_growth_ba_yr  ss_sur_growth_ba_yr  \\\n",
       "0                          1.970079             0.718489             0.718489   \n",
       "0                          1.658328             0.379671             0.379671   \n",
       "0                          1.581883             0.843316             0.843316   \n",
       "0                          1.413360             0.588149             0.588149   \n",
       "0                          3.917958             0.533841             0.533841   \n",
       "..                              ...                  ...                  ...   \n",
       "0                          2.891878             0.076518             0.076518   \n",
       "0                          1.666516             0.024688             0.024688   \n",
       "0                          1.589207             0.181119             0.181119   \n",
       "0                          1.453016             0.788164             0.788164   \n",
       "0                          1.472559             0.032106             0.032106   \n",
       "\n",
       "    ss_mort_ba_yr_v1  ss_mort_ba_yr_v2  ss_tot_growth_ba_prc_yr  \\\n",
       "0           0.142984          0.142984                 2.070375   \n",
       "0           1.328037          1.369862                 1.729019   \n",
       "0           1.191942          1.191942                 1.646124   \n",
       "0           4.030881          4.103508                 1.464498   \n",
       "0           0.088271          0.088271                 4.328054   \n",
       "..               ...               ...                      ...   \n",
       "0           0.068169          0.062644                 3.111404   \n",
       "0           0.443868          0.443868                 1.737917   \n",
       "0           0.088271          0.077896                 1.654053   \n",
       "0           0.054794          0.054794                 1.507100   \n",
       "0           1.922347          1.932346                 1.528125   \n",
       "\n",
       "    ss_sur_growth_ba_prc_yr  ss_mort_ba_prc_yr_v1  ss_mort_ba_prc_yr_v2  \n",
       "0                  2.070375              0.403703              0.366526  \n",
       "0                  1.729019              3.779731              4.461163  \n",
       "0                  1.646124              2.084175              1.941062  \n",
       "0                  1.464498              6.683062              6.450154  \n",
       "0                  4.328054              0.670484              0.571519  \n",
       "..                      ...                   ...                   ...  \n",
       "0                  3.111404              2.434506              1.985500  \n",
       "0                  1.737917             12.194633             11.794645  \n",
       "0                  1.654053              0.774896              0.636140  \n",
       "0                  1.507100              0.104230              0.096962  \n",
       "0                  1.528125             16.412457             16.206530  \n",
       "\n",
       "[1654 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ss_mort_ba_prc_yr_v1\n",
       "0.057283     1\n",
       "0.071199     1\n",
       "0.076223     1\n",
       "0.080427     1\n",
       "0.088291     1\n",
       "            ..\n",
       "18.046798    1\n",
       "18.061745    1\n",
       "19.388243    1\n",
       "19.479319    1\n",
       "19.890448    1\n",
       "Name: count, Length: 1651, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx_nonas = xxx.dropna(subset=[\"ss_mort_ba_prc_yr_v1\"])\n",
    "xxx_nonas\n",
    "xxx_nonas_nozeros = xxx_nonas[xxx_nonas[\"ss_mort_ba_prc_yr_v1\"] != 0]\n",
    "xxx_nonas_nozeros\n",
    "xxx_nonas_nozeros_no20s = xxx_nonas_nozeros[\n",
    "    xxx_nonas_nozeros[\"ss_mort_ba_prc_yr_v1\"] != 20\n",
    "]\n",
    "display(xxx_nonas_nozeros_no20s)\n",
    "xxx_nonas_nozeros_no20s[\"ss_mort_ba_prc_yr_v1\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp = df_mp.rename(columns={\"group_id\": \"idp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idp\n",
      "ss_n_plots\n",
      "ss_n_ini\n",
      "ss_n_sur\n",
      "ss_n_fin\n",
      "ss_n_rec\n",
      "ss_n_die\n",
      "ss_ba_at_v1_of_alive_trees\n",
      "ss_ba_at_v2_of_alive_trees\n",
      "ss_ba_at_v1_of_survived\n",
      "ss_ba_at_v2_of_survived\n",
      "ss_ba_at_v1_of_died\n",
      "ss_ba_at_v2_of_died\n",
      "ss_ba_at_v2_of_recruited\n",
      "ss_mort_stems_prc_yr_esq\n",
      "ss_mort_stems_prc_yr_hoshino\n",
      "ss_rec_stems_prc_yr_hoshino\n",
      "ss_mort_ba_prc_yr_hoshino\n",
      "ss_tot_growth_ba_prc_yr_hoshino\n",
      "ss_sur_growth_ba_prc_yr_hoshino\n",
      "ss_tot_growth_ba_yr\n",
      "ss_sur_growth_ba_yr\n",
      "ss_mort_ba_yr_v1\n",
      "ss_mort_ba_yr_v2\n",
      "ss_tot_growth_ba_prc_yr\n",
      "ss_sur_growth_ba_prc_yr\n",
      "ss_mort_ba_prc_yr_v1\n",
      "ss_mort_ba_prc_yr_v2\n",
      "n_species_espar_red\n",
      "n_species_species_lat\n",
      "n_species_genus_lat\n",
      "allspecies_htot_mean\n",
      "allspecies_age13_mean\n",
      "allspecies_ir5_mean\n",
      "allspecies_v_mean\n",
      "allspecies_ba_1_mean\n",
      "allspecies_ba_2_mean\n",
      "allspecies_ba_change_perc_yr_mean\n",
      "allspecies_htot_std\n",
      "allspecies_age13_std\n",
      "allspecies_ir5_std\n",
      "allspecies_v_std\n",
      "allspecies_ba_1_std\n",
      "allspecies_ba_2_std\n",
      "allspecies_ba_change_perc_yr_std\n",
      "allspecies_htot_range\n",
      "allspecies_age13_range\n",
      "allspecies_ir5_range\n",
      "allspecies_v_range\n",
      "allspecies_ba_1_range\n",
      "allspecies_ba_2_range\n",
      "allspecies_ba_change_perc_yr_range\n",
      "top1_htot_mean\n",
      "top1_age13_mean\n",
      "top1_ir5_mean\n",
      "top1_v_mean\n",
      "top1_ba_1_mean\n",
      "top1_ba_2_mean\n",
      "top1_ba_change_perc_yr_mean\n",
      "top1_htot_std\n",
      "top1_age13_std\n",
      "top1_ir5_std\n",
      "top1_v_std\n",
      "top1_ba_1_std\n",
      "top1_ba_2_std\n",
      "top1_ba_change_perc_yr_std\n",
      "top1_htot_range\n",
      "top1_age13_range\n",
      "top1_ir5_range\n",
      "top1_v_range\n",
      "top1_ba_1_range\n",
      "top1_ba_2_range\n",
      "top1_ba_change_perc_yr_range\n",
      "top1_espar_red\n",
      "top2_htot_mean\n",
      "top2_age13_mean\n",
      "top2_ir5_mean\n",
      "top2_v_mean\n",
      "top2_ba_1_mean\n",
      "top2_ba_2_mean\n",
      "top2_ba_change_perc_yr_mean\n",
      "top2_htot_std\n",
      "top2_age13_std\n",
      "top2_ir5_std\n",
      "top2_v_std\n",
      "top2_ba_1_std\n",
      "top2_ba_2_std\n",
      "top2_ba_change_perc_yr_std\n",
      "top2_htot_range\n",
      "top2_age13_range\n",
      "top2_ir5_range\n",
      "top2_v_range\n",
      "top2_ba_1_range\n",
      "top2_ba_2_range\n",
      "top2_ba_change_perc_yr_range\n",
      "top2_espar_red\n",
      "top3_htot_mean\n",
      "top3_age13_mean\n",
      "top3_ir5_mean\n",
      "top3_v_mean\n",
      "top3_ba_1_mean\n",
      "top3_ba_2_mean\n",
      "top3_ba_change_perc_yr_mean\n",
      "top3_htot_std\n",
      "top3_age13_std\n",
      "top3_ir5_std\n",
      "top3_v_std\n",
      "top3_ba_1_std\n",
      "top3_ba_2_std\n",
      "top3_ba_change_perc_yr_std\n",
      "top3_htot_range\n",
      "top3_age13_range\n",
      "top3_ir5_range\n",
      "top3_v_range\n",
      "top3_ba_1_range\n",
      "top3_ba_2_range\n",
      "top3_ba_change_perc_yr_range\n",
      "top3_espar_red\n",
      "static_full_stand_ba_at_v1\n",
      "static_full_stand_nt_at_v1\n",
      "static_alive_ba_at_v1\n",
      "static_alive_nt_at_v1\n",
      "static_alive_ba_at_v1_perc\n",
      "static_alive_nt_at_v1_perc\n",
      "static_dead_ba_at_v1\n",
      "static_dead_nt_at_v1\n",
      "static_dead_ba_at_v1_perc\n",
      "static_dead_nt_at_v1_perc\n",
      "static_full_stand_ba_at_v2\n",
      "static_full_stand_nt_at_v2\n",
      "static_alive_ba_at_v2\n",
      "static_alive_nt_at_v2\n",
      "static_alive_ba_at_v2_perc\n",
      "static_alive_nt_at_v2_perc\n",
      "static_cut_ba_at_v2\n",
      "static_cut_nt_at_v2\n",
      "static_cut_ba_at_v2_perc\n",
      "static_cut_nt_at_v2_perc\n",
      "static_dead_ba_at_v2\n",
      "static_dead_nt_at_v2\n",
      "static_dead_ba_at_v2_perc\n",
      "static_dead_nt_at_v2_perc\n",
      "trees_alive_with_structdmg_at_v1_in_perc\n",
      "trees_alive_with_burn_at_v1_in_perc\n",
      "trees_alive_with_game_at_v1_in_perc\n",
      "trees_alive_with_foot_at_v1_in_perc\n",
      "trees_alive_with_rot_at_v1_in_perc\n",
      "trees_alive_with_mistl_at_v1_in_perc\n",
      "trees_alive_with_frost_at_v1_in_perc\n",
      "trees_alive_with_firrust_at_v1_in_perc\n",
      "trees_alive_with_branchdmg_at_v1_in_perc\n",
      "trees_alive_with_anydmg_at_v1_in_perc\n",
      "trees_alive_with_frost_at_v2_in_perc\n",
      "trees_alive_with_mistl_at_v2_in_perc\n",
      "trees_alive_with_firrust_at_v2_in_perc\n",
      "trees_alive_with_branchdmg_at_v2_in_perc\n",
      "trees_alive_with_anydmg_at_v2_in_perc\n",
      "trees_died_with_structdmg_at_v1_in_perc\n",
      "trees_died_with_burn_at_v1_in_perc\n",
      "trees_died_with_game_at_v1_in_perc\n",
      "trees_died_with_foot_at_v1_in_perc\n",
      "trees_died_with_rot_at_v1_in_perc\n",
      "trees_died_with_mistl_at_v1_in_perc\n",
      "trees_died_with_frost_at_v1_in_perc\n",
      "trees_died_with_firrust_at_v1_in_perc\n",
      "trees_died_with_branchdmg_at_v1_in_perc\n",
      "trees_died_with_anydmg_at_v1_in_perc\n",
      "trees_died_with_frost_at_v2_in_perc\n",
      "trees_died_with_mistl_at_v2_in_perc\n",
      "trees_died_with_firrust_at_v2_in_perc\n",
      "trees_died_with_branchdmg_at_v2_in_perc\n",
      "trees_died_with_anydmg_at_v2_in_perc\n",
      "trees_survived_with_structdmg_at_v1_in_perc\n",
      "trees_survived_with_burn_at_v1_in_perc\n",
      "trees_survived_with_game_at_v1_in_perc\n",
      "trees_survived_with_foot_at_v1_in_perc\n",
      "trees_survived_with_rot_at_v1_in_perc\n",
      "trees_survived_with_mistl_at_v1_in_perc\n",
      "trees_survived_with_frost_at_v1_in_perc\n",
      "trees_survived_with_firrust_at_v1_in_perc\n",
      "trees_survived_with_branchdmg_at_v1_in_perc\n",
      "trees_survived_with_anydmg_at_v1_in_perc\n",
      "trees_survived_with_frost_at_v2_in_perc\n",
      "trees_survived_with_mistl_at_v2_in_perc\n",
      "trees_survived_with_firrust_at_v2_in_perc\n",
      "trees_survived_with_branchdmg_at_v2_in_perc\n",
      "trees_survived_with_anydmg_at_v2_in_perc\n",
      "n_plots\n",
      "n_ini\n",
      "n_sur\n",
      "n_fin\n",
      "n_rec\n",
      "n_die\n",
      "ba_at_v1_of_alive_trees\n",
      "ba_at_v2_of_alive_trees\n",
      "ba_at_v1_of_survived\n",
      "ba_at_v2_of_survived\n",
      "ba_at_v1_of_died\n",
      "ba_at_v2_of_died\n",
      "ba_at_v2_of_recruited\n",
      "mort_stems_prc_yr_esq\n",
      "mort_stems_prc_yr_hoshino\n",
      "rec_stems_prc_yr_hoshino\n",
      "mort_ba_prc_yr_hoshino\n",
      "tot_growth_ba_prc_yr_hoshino\n",
      "sur_growth_ba_prc_yr_hoshino\n",
      "tot_growth_ba_yr\n",
      "sur_growth_ba_yr\n",
      "mort_ba_yr_v1\n",
      "mort_ba_yr_v2\n",
      "tot_growth_ba_prc_yr\n",
      "sur_growth_ba_prc_yr\n",
      "mort_ba_prc_yr_v1\n",
      "mort_ba_prc_yr_v2\n"
     ]
    }
   ],
   "source": [
    "merged = xxx_nonas_nozeros_no20s.merge(df_mp, how=\"left\", on=\"idp\")\n",
    "for col in merged.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5149061330315192"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statistics import correlation\n",
    "from numpy import corrcoef\n",
    "\n",
    "\n",
    "y = \"ss_mort_ba_prc_yr_v1\"\n",
    "x = \"ss_ba_at_v1_of_died\"\n",
    "\n",
    "ttt = merged.copy()\n",
    "ttt[x].replace(0, np.nan, inplace=True)\n",
    "ttt[y].replace(0, np.nan, inplace=True)\n",
    "ttt = ttt.dropna(subset=x)\n",
    "ttt = ttt.dropna(subset=y)\n",
    "\n",
    "\n",
    "sns.regplot(\n",
    "    data=ttt,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    scatter_kws={\"color\": \"royalblue\", \"alpha\": 0.75, \"s\": 5},\n",
    "    line_kws={\"color\": \"tomato\"},\n",
    "    # lowess=True,\n",
    ")\n",
    "\n",
    "correlation(ttt[x], ttt[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of Growth / Mortality at plot-level\n",
    "\n",
    "if \"nfi_agg\" not in globals() or user_input[\"rerun_calculation_growth_mortality\"]:\n",
    "    # Load pre-calculated dataframe\n",
    "    nfi_agg = pd.read_parquet(\"nfi-idp_level_aggregated_growth_mortality.parquet\")\n",
    "\n",
    "    if (\n",
    "        nfi_agg.shape[0] != nfi_final_data[\"idp\"].nunique()\n",
    "        or user_input[\"rerun_calculation_growth_mortality\"]\n",
    "    ):\n",
    "        # ‚ö†Ô∏è  This takes abnfi_agg 30 minutes to run, so loading the data from the feather file instead\n",
    "        #     Plus, for some reason, after running this cell, the notebook slows down massively.\n",
    "\n",
    "        if nfi_agg.shape[0] != nfi_final_data[\"idp\"].nunique():\n",
    "            print(\n",
    "                \"Number of rows in nfi_agg is not equal to number of rows in nfi_final_data, so re-running the calculation.\"\n",
    "            )\n",
    "            print(\"Shape of old nfi_agg:\", nfi_agg.shape)\n",
    "\n",
    "        grouped = nfi_final_data.groupby(\"idp\", as_index=False)\n",
    "        df_list = [group for name, group in grouped]\n",
    "\n",
    "        # df_list = df_list[:100] # For debug, reduce number to 100 sites only\n",
    "\n",
    "        nfi_agg = run_mp(\n",
    "            calculate_growth_mortality,\n",
    "            df_list,\n",
    "            combine_func=pd.concat,\n",
    "            progress_bar=True,\n",
    "            num_cores=10,\n",
    "        )\n",
    "\n",
    "        # Save data\n",
    "        nfi_agg.to_parquet(\"nfi-idp_level_aggregated_growth_mortality.parquet\")\n",
    "\n",
    "        # Create Report\n",
    "        if run_reports_minor:\n",
    "            profile = ProfileReport(\n",
    "                nfi_agg.sort_index(axis=1),\n",
    "                minimal=True,\n",
    "                dark_mode=True,\n",
    "                title=\"Overview of Growth and Mortality Calculations\",\n",
    "            )\n",
    "\n",
    "            profile.to_file(f\"report-growth_mortality_calculations.html\")\n",
    "\n",
    "print(\"Shape of final nfi_agg:\", nfi_agg.shape)\n",
    "print(\"Number of individual sites:\", nfi_agg[\"idp\"].nunique())\n",
    "\n",
    "# for col in nfi_agg.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sites post-aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sites with too few trees\n",
    "print(f\"Number of sites before subsetting: {rf_data_raw['idp'].nunique()}\")\n",
    "\n",
    "if user_input[\"subset_nfi\"]:\n",
    "    # Mintrees\n",
    "    # nfi_at_location_level = nfi_at_location_level.query(\n",
    "    #     \"n_ini >= @user_input['subset_min_trees_per_plot']\"\n",
    "    # )\n",
    "\n",
    "    # # Write information to file\n",
    "    # write_txt(\n",
    "    #     f\"{current_dir}/_subsetted_to_min_trees_per_plot>{user_input['subset_min_trees_per_plot']}.txt\"\n",
    "    # )\n",
    "\n",
    "    # Height\n",
    "    # above_or_below = \"below\"\n",
    "    # mymedian = nfi_at_location_level[\"top1_species_htot_mean\"].median()\n",
    "\n",
    "    # if above_or_below == \"above\":\n",
    "    #     nfi_at_location_level = nfi_at_location_level.query(\n",
    "    #         \"top1_species_htot_mean >= @mymedian\"\n",
    "    #     )\n",
    "    #     write_txt(f\"{current_dir}/_subsetted_to_above_median_height.txt\")\n",
    "    # else:\n",
    "    #     nfi_at_location_level = nfi_at_location_level.query(\n",
    "    #         \"top1_species_htot_mean <= @mymedian\"\n",
    "    #     )\n",
    "    #     write_txt(f\"{current_dir}/_subsetted_to_below_median_height.txt\")\n",
    "    df_subsetted_sites = nfi_agg.copy()\n",
    "else:\n",
    "    print(\"Not subsetting nfi data.\")\n",
    "    df_subsetted_sites = nfi_agg.copy()\n",
    "\n",
    "\n",
    "print(f\"Number of sites after subsetting: {nfi_agg['idp'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge NFI and Mortality Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach growth/mortality data to nfi_final_data\n",
    "nfi_merged = nfi_final_data.merge(nfi_agg, how=\"left\", left_on=\"idp\", right_on=\"idp\")\n",
    "print(\"Shape of nfi_merged:\", nfi_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check against Excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which variables are part documented in the google sheets:\n",
    "\n",
    "# Load original NFI Variables\n",
    "nfi_org = pd.read_excel(\n",
    "    here(\"docs/ifna_predictor_database.xlsx\"),\n",
    "    sheet_name=\"NFI Original Variables\",\n",
    ")[[\"var\", \"type\", \"level\", \"remove\"]]\n",
    "\n",
    "# Load my NFI derivatives\n",
    "nfi_derivatives = (\n",
    "    pd.read_excel(\n",
    "        here(\"docs/ifna_predictor_database.xlsx\"),\n",
    "        sheet_name=\"NFI Derivatives\",\n",
    "    )\n",
    "    .reset_index()[[\"var\", \"type\", \"level\", \"remove\"]]\n",
    "    .dropna(subset=[\"type\"])\n",
    ")\n",
    "\n",
    "# Add suffixes _1 and _2 to the original variables to distinguish them if sampled from different years\n",
    "suffix_1 = nfi_org.copy()\n",
    "suffix_2 = nfi_org.copy()\n",
    "\n",
    "suffix_1[\"var\"] = suffix_1[\"var\"].apply(lambda x: x + \"_1\")\n",
    "suffix_2[\"var\"] = suffix_2[\"var\"].apply(lambda x: x + \"_2\")\n",
    "\n",
    "# Get list with suffixes for later use\n",
    "nfi_org_with_suffixes = pd.concat([nfi_org, suffix_1, suffix_2])\n",
    "\n",
    "# Concatenate original variables with suffixes and derivatives\n",
    "vars_described_in_sheet = pd.concat([nfi_org, suffix_1, suffix_2, nfi_derivatives])\n",
    "# vars_described_in_sheet\n",
    "\n",
    "# Extract variables that are in the final wrangled nfi dataset\n",
    "final_vars = nfi_merged.columns.to_frame(index=False, name=\"var\").sort_values(\"var\")\n",
    "\n",
    "# Remove all variables that can be found in the excel file:\n",
    "mask = final_vars[\"var\"].isin(vars_described_in_sheet[\"var\"])\n",
    "not_described_vars = final_vars[~mask]\n",
    "\n",
    "# Print output\n",
    "print(\"Variables that are not documented in the excel (should show empty dataframe):\")\n",
    "display(not_described_vars)\n",
    "\n",
    "# Check if variables are described in the excel file that are not in the final wrangled nfi dataset\n",
    "# Extract all derivatives\n",
    "all_ders = nfi_derivatives[\"var\"]\n",
    "\n",
    "# Find entries in var that are in all_ders but not in final_vars\n",
    "mask = nfi_derivatives[\"var\"].isin(final_vars[\"var\"])\n",
    "documented_but_not_in_final_df = nfi_derivatives[~mask]\n",
    "\n",
    "# Print the output\n",
    "print(\"Variables that are documented in the excel but not in the merged nfi dataframe:\")\n",
    "display(documented_but_not_in_final_df.reset_index(drop=True))\n",
    "\n",
    "# vars_described_in_sheet holds all possible suffix combinations but those are not needed.\n",
    "# So, reduce vars_described_in_sheet to match variables in df_tmp\n",
    "vars_described_in_sheet_and_in_df = vars_described_in_sheet[\n",
    "    vars_described_in_sheet[\"var\"].isin(df_tmp.columns)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NFI Variable Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATETIME VARIABLES\n",
    "# TODO: dropping datetime variable for now because it is of little importance and\n",
    "# TODO: encoding takes significant extra work for now...\n",
    "# TODO: To keep circular nature of data structure, encode using trigonometric functions\n",
    "# TODO: https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html\n",
    "\n",
    "# Rerun this to avoid errors:\n",
    "vars_described_in_sheet_and_in_df = vars_described_in_sheet[\n",
    "    vars_described_in_sheet[\"var\"].isin(df_tmp.columns)\n",
    "]\n",
    "\n",
    "date_cols = vars_described_in_sheet_and_in_df.query(\"type == 'date'\")[\"var\"].tolist()\n",
    "\n",
    "for var in date_cols:\n",
    "    df_tmp[var] = df_tmp[var].fillna(df_tmp[\"campagne_1\"].astype(str) + \"-07-01\")\n",
    "\n",
    "df_tmp = df_tmp.drop(columns=date_cols)\n",
    "print(f\"Shape of df_tmp: {df_tmp.shape} after dropping date columns: {date_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE CATEGORICAL VARIABLES\n",
    "\n",
    "# vars_described_in_sheet holds all possible suffix combinations but those are not needed.\n",
    "# So, reduce vars_described_in_sheet to match variables in df_tmp\n",
    "vars_described_in_sheet_and_in_df = vars_described_in_sheet[\n",
    "    vars_described_in_sheet[\"var\"].isin(df_tmp.columns)\n",
    "]\n",
    "\n",
    "# Get list of variables to encode, based on excel file\n",
    "vars_to_ohe = vars_described_in_sheet_and_in_df.query(\"type == 'cat'\")[\"var\"]\n",
    "\n",
    "# Reduce to have only variables in df_tmp\n",
    "vars_to_ohe = [var for var in vars_to_ohe if var in df_tmp.columns]\n",
    "\n",
    "df_encoded = df_tmp.copy()\n",
    "print(f\"Shape of df_encoded: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce data to location-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temporary df\n",
    "df_tmp = df_encoded.copy()\n",
    "print(f\"Shape of df_encoded: {df_encoded.shape}\")\n",
    "print(\"Number of individual sites:\", df_tmp[\"idp\"].nunique())\n",
    "\n",
    "# Get all variables on location-level\n",
    "location_vars = vars_described_in_sheet_and_in_df.query(\n",
    "    \"level == 'location' or level == 'grouping'\"\n",
    ")\n",
    "tree_vars = vars_described_in_sheet_and_in_df.query(\"level == 'tree'\")\n",
    "\n",
    "print(\"Number of tree-level variables that are removed:\", tree_vars.shape[0])\n",
    "print(\"Number of location-level variables that are kept:\", location_vars.shape[0])\n",
    "\n",
    "# Get all columns in nfi_final_data that are also in location_vars\n",
    "matching_columns = [var for var in location_vars[\"var\"] if var in df_tmp.columns]\n",
    "# matching_columns = [var for var in location_vars[\"var\"]]\n",
    "\n",
    "# Fixes by hand because some integers are saved as floats\n",
    "# sver\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"0.0\", \"0\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"1.0\", \"1\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"2.0\", \"2\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"3.0\", \"3\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"4.0\", \"4\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"5.0\", \"5\")\n",
    "df_tmp[\"sver\"] = df_tmp[\"sver\"].replace(\"6.0\", \"6\")\n",
    "df_tmp[\"instp5\"] = df_tmp[\"instp5\"].replace(\"0.0\", \"0\")\n",
    "df_tmp[\"uta1\"] = df_tmp[\"sver\"].replace(\"6.0\", \"6\")\n",
    "\n",
    "# Reduce nfi_final_data to only contain location-level variables\n",
    "nfi_at_location_level = df_tmp[matching_columns].drop_duplicates()\n",
    "\n",
    "# Print all variables that were removed\n",
    "print(\"\\n\")\n",
    "print(\"Variables that were removed because they are undocumented:\")\n",
    "counter = 0\n",
    "for var in df_encoded.columns:\n",
    "    if var not in nfi_at_location_level.columns:\n",
    "        if var not in tree_vars[\"var\"].to_list():\n",
    "            counter = counter + 1\n",
    "            print(f\" {counter}. {var}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Variables that were removed because they are on tree-level:\")\n",
    "counter = 0\n",
    "for var in df_encoded.columns:\n",
    "    if var not in nfi_at_location_level.columns:\n",
    "        if var in tree_vars[\"var\"].to_list():\n",
    "            counter = counter + 1\n",
    "            print(f\" {counter}. {var}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\n",
    "    f\"‚ùå not working ‚ùå Final dataframe should have {df_encoded.shape[1] - len(tree_vars) - counter} columns:\"\n",
    ")\n",
    "print(\"Shape of nfi_at_location_level:\", nfi_at_location_level.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to search for idp duplicates in the dataset\n",
    "if nfi_at_location_level.shape[0] != df_encoded[\"idp\"].nunique():\n",
    "    print(\n",
    "        f\"Number of rows in df_tmp ({nfi_at_location_level.shape[0]}) is not equal to number of rows in df_encoded ({df_encoded['idp'].nunique()}), so running search for duplicated idp to find issue:.\"\n",
    "    )\n",
    "\n",
    "    all_idps = nfi_at_location_level[\"idp\"].to_list()\n",
    "    counter = 0\n",
    "    double_idps = []\n",
    "\n",
    "    for i in range(0, len(all_idps)):\n",
    "        for j in range(i + 1, len(all_idps)):\n",
    "            if all_idps[i] == all_idps[j]:\n",
    "                print(all_idps[j])\n",
    "                counter = counter + 1\n",
    "                double_idps.append(all_idps[j])\n",
    "\n",
    "    print(f\"counter of duplicated idps: {counter}\")\n",
    "\n",
    "    idp_x = double_idps[1]\n",
    "    # idp_x = \"722345\"\n",
    "    xxx = df_tmp.query(\"idp == @idp_x\")\n",
    "\n",
    "    print(idp_x)\n",
    "\n",
    "    for col in xxx.columns:\n",
    "        if xxx[col].nunique() > 1:\n",
    "            # xxx[col] = xxx[col].astype(int)\n",
    "            print(xxx[col])\n",
    "            # print(xxx[col].iloc[0] == xxx[col].iloc[1])\n",
    "else:\n",
    "    print(\"No duplicates found when reducing to location-level variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data to Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target only dataframe and save it separately\n",
    "df_target = nfi_at_location_level.copy()[[\"idp\", user_input[\"target\"]]]\n",
    "# Get df to which data is added sequentially\n",
    "df_target_and_data = df_target.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFI Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note opposite logic: If data is to be added, the cell is NOT executed\n",
    "df_org = df_target_and_data\n",
    "if user_input[\"add_nfi_original\"]:\n",
    "    # Keep only variables not pre-set to be removed\n",
    "    add_these = nfi_org_with_suffixes.query(\"remove != 'x'\")[\"var\"].to_list()\n",
    "    # Make sure \"idp\" is kept\n",
    "    add_these = (\n",
    "        add_these\n",
    "        + [\"idp\"]\n",
    "        + user_input[\"test_train_strata\"]\n",
    "        + [user_input[\"add_target_0s_strata\"]]\n",
    "    )\n",
    "    add_these = [var for var in add_these if var in nfi_at_location_level.columns]\n",
    "    add_these = set(add_these)\n",
    "    add_these = sorted(add_these)\n",
    "\n",
    "    # Merge data\n",
    "    df_target_and_data = df_target_and_data.merge(\n",
    "        nfi_at_location_level[add_these],\n",
    "        how=\"left\",\n",
    "        left_on=\"idp\",\n",
    "        right_on=\"idp\",\n",
    "    )\n",
    "\n",
    "    # display(df_target_and_data)\n",
    "\n",
    "    # Print merge information\n",
    "    print(\n",
    "        f\"Information on adding original NFI variables:\",\n",
    "        f\"\\n - Dataset before merging had shape: {df_org.shape}\",\n",
    "        f\"\\n - Dataset after merging has shape:  {df_target_and_data.shape}\",\n",
    "        f\"\\n - The following {df_target_and_data.shape[1] - df_org.shape[1]} features were added: {' | '.join(add_these)}\",\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"No original NFI variables added.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derived Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df_target_and_data\n",
    "if user_input[\"add_nfi_derivatives\"]:\n",
    "    # Keep only variables not pre-set to be removed\n",
    "    add_these = nfi_derivatives.query(\"remove != 'x'\")[\"var\"].to_list()\n",
    "    # Make sure \"idp\" is kept\n",
    "    add_these = (\n",
    "        add_these\n",
    "        + [\"idp\"]\n",
    "        + user_input[\"test_train_strata\"]\n",
    "        + [user_input[\"add_target_0s_strata\"]]\n",
    "    )\n",
    "    add_these = [var for var in add_these if var in nfi_at_location_level.columns]\n",
    "    add_these = sorted(add_these)\n",
    "    add_these = sorted(add_these)\n",
    "\n",
    "    # Do not add variables that are already in the dataset\n",
    "    add_these = [var for var in add_these if var not in df_target_and_data.columns]\n",
    "    # ... except for idp\n",
    "    if \"idp\" not in add_these:\n",
    "        add_these = add_these + [\"idp\"]\n",
    "\n",
    "    # Merge data\n",
    "    df_target_and_data = df_target_and_data.merge(\n",
    "        nfi_at_location_level[add_these],\n",
    "        how=\"left\",\n",
    "        left_on=\"idp\",\n",
    "        right_on=\"idp\",\n",
    "    )\n",
    "\n",
    "    # display(df_target_and_data)\n",
    "\n",
    "    # Print merge information\n",
    "    print(\n",
    "        f\"Information on adding derived NFI variables:\",\n",
    "        f\"\\n - Dataset before merging had shape: {df_org.shape}\",\n",
    "        f\"\\n - Dataset after merging has shape:  {df_target_and_data.shape}\",\n",
    "        f\"\\n - The following {df_target_and_data.shape[1] - df_org.shape[1]} features were added: {' | '.join(add_these)}\",\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"No derived NFI variables added.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics of Change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvarsnfi = df_target_and_data.shape\n",
    "gee_vars = []\n",
    "\n",
    "if user_input[\"add_gee_data\"]:\n",
    "    if \"gee_data\" not in globals():\n",
    "        gee_data = pd.read_feather(\n",
    "            \"../02_process_gee_data/final_gee_predictor_dataset.feather\"\n",
    "        )\n",
    "\n",
    "    missing_idp_in_gee = list(\n",
    "        set(df_target_and_data[\"idp\"].unique()) - set(gee_data[\"idp\"].unique())\n",
    "    )\n",
    "\n",
    "    if len(missing_idp_in_gee) > 0:\n",
    "        print(\n",
    "            f\"‚ùå {len(missing_idp_in_gee)} idp's are in df_target_and_data but not in gee_data\\n\\t{missing_idp_in_gee}:\\n\",\n",
    "        )\n",
    "\n",
    "    nvarsgee = gee_data.shape[1] - 1  # minus one for idp\n",
    "\n",
    "    df_target_and_data_with_gee = df_target_and_data.merge(\n",
    "        gee_data, how=\"left\", left_on=\"idp\", right_on=\"idp\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\" - Shape of gee_data: {gee_data.shape}\",\n",
    "        f\"\\n - Adding {nvarsgee} columns = {nvarsgee + nvarsnfi[1]} columns in total.\",\n",
    "    )\n",
    "\n",
    "    # Get all new columns:\n",
    "    new_cols = df_target_and_data_with_gee.columns.to_list()\n",
    "    new_cols = [\n",
    "        col for col in new_cols if col not in df_target_and_data.columns.to_list()\n",
    "    ]\n",
    "    print(f\" - New columns: {new_cols}\")\n",
    "\n",
    "    df_target_and_data = df_target_and_data_with_gee.copy()\n",
    "\n",
    "    gee_vars = [var for var in gee_data.columns if var in df_target_and_data.columns]\n",
    "    print(f\" - These gee variables were added: {gee_vars}\")\n",
    "\n",
    "else:\n",
    "    print(\"Not adding gee data.\")\n",
    "    gee_vars = []\n",
    "    df_target_and_data_with_gee = df_target_and_data.copy()\n",
    "\n",
    "print(\n",
    "    f\"\\nShape of before adding gee:\\t {nvarsnfi}\",\n",
    "    f\"\\nShape of after adding gee:\\t {df_target_and_data_with_gee.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soil (RMQS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvarsnfi = df_target_and_data.shape\n",
    "\n",
    "if user_input[\"add_rmqs_data\"]:\n",
    "    if \"rmqs_data\" not in globals():\n",
    "        rmqs_data = pd.read_feather(\"../03_process_france_data/data_rmqs.feather\").drop(\n",
    "            columns=[\"id_site\", \"date_compl\", \"code_dept\"], errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "    missing_idp_in_rmqs = list(\n",
    "        set(df_target_and_data[\"idp\"].unique()) - set(rmqs_data[\"idp\"].unique())\n",
    "    )\n",
    "    print(\n",
    "        f\"Site idp that are in df_target_and_data but not in rmqs_data {len(missing_idp_in_rmqs)}: {missing_idp_in_rmqs}\\n\",\n",
    "    )\n",
    "\n",
    "    nvarsrmqs = rmqs_data.shape[1] - 1  # minus one for idp\n",
    "\n",
    "    df_target_and_data_with_rmqs = df_target_and_data.merge(\n",
    "        rmqs_data, how=\"left\", left_on=\"idp\", right_on=\"idp\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Shape of rmqs_data: {rmqs_data.shape}\",\n",
    "        f\"\\nAdding {nvarsrmqs} columns = {nvarsrmqs + nvarsnfi[1]} columns in total.\",\n",
    "    )\n",
    "\n",
    "    # Get all new columns:\n",
    "    new_cols = df_target_and_data_with_rmqs.columns.to_list()\n",
    "    new_cols = [\n",
    "        col for col in new_cols if col not in df_target_and_data.columns.to_list()\n",
    "    ]\n",
    "    print(f\"New columns: {new_cols}\")\n",
    "\n",
    "    df_target_and_data = df_target_and_data_with_rmqs.copy()\n",
    "else:\n",
    "    print(\"Not adding rmqs data.\")\n",
    "    df_target_and_data_with_rmqs = df_target_and_data.copy()\n",
    "\n",
    "print(\n",
    "    f\"\\nShape of before adding rmqs:\\t {nvarsnfi}\",\n",
    "    f\"\\nShape of after adding rmqs:\\t {df_target_and_data_with_rmqs.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvarsnfi = df_target_and_data.shape\n",
    "\n",
    "if user_input[\"add_edo_data\"]:\n",
    "    if \"edo_data\" not in globals():\n",
    "        edo_data = pd.read_feather(\"../03_process_france_data/data_edo_all.feather\")\n",
    "\n",
    "    missing_idp_in_edo = list(\n",
    "        set(df_target_and_data[\"idp\"].unique()) - set(edo_data[\"idp\"].unique())\n",
    "    )\n",
    "    print(\n",
    "        f\"Site idp that are in df_target_and_data but not in edo_data {len(missing_idp_in_edo)}: {missing_idp_in_edo}\\n\",\n",
    "    )\n",
    "\n",
    "    nvarsedo = edo_data.shape[1] - 1  # minus one for idp\n",
    "\n",
    "    df_target_and_data_with_edo = df_target_and_data.merge(\n",
    "        edo_data, how=\"left\", left_on=\"idp\", right_on=\"idp\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Shape of edo_data: {edo_data.shape}\",\n",
    "        f\"\\nAdding {nvarsedo} columns = {nvarsedo + nvarsnfi[1]} columns in total.\",\n",
    "    )\n",
    "\n",
    "    # Get all new columns:\n",
    "    new_cols = df_target_and_data_with_edo.columns.to_list()\n",
    "    new_cols = [\n",
    "        col for col in new_cols if col not in df_target_and_data.columns.to_list()\n",
    "    ]\n",
    "    print(f\"New columns: {new_cols}\")\n",
    "\n",
    "    df_target_and_data = df_target_and_data_with_edo.copy()\n",
    "else:\n",
    "    print(\"Not adding edo data.\")\n",
    "    df_target_and_data_with_edo = df_target_and_data.copy()\n",
    "\n",
    "print(\n",
    "    f\"\\nShape of before adding edo:\\t {nvarsnfi}\",\n",
    "    f\"\\nShape of after adding edo:\\t {df_target_and_data_with_edo.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agroparistech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvarsnfi = df_target_and_data.shape\n",
    "\n",
    "if user_input[\"add_apt_data\"]:\n",
    "    if \"apt_data\" not in globals():\n",
    "        apt_data = pd.read_feather(\n",
    "            \"../03_process_france_data/data_agroparistech_all.feather\"\n",
    "        )\n",
    "\n",
    "    missing_idp_in_apt = list(\n",
    "        set(df_target_and_data[\"idp\"].unique()) - set(apt_data[\"idp\"].unique())\n",
    "    )\n",
    "    print(\n",
    "        f\"Site idp that are in df_target_and_data but not in apt_data {len(missing_idp_in_apt)}: {missing_idp_in_apt}\\n\",\n",
    "    )\n",
    "\n",
    "    nvarsapt = apt_data.shape[1] - 1  # minus one for idp\n",
    "\n",
    "    df_target_and_data_with_apt = df_target_and_data.merge(\n",
    "        apt_data, how=\"left\", left_on=\"idp\", right_on=\"idp\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Shape of apt_data: {apt_data.shape}\",\n",
    "        f\"\\nAdding {nvarsapt} columns = {nvarsapt + nvarsnfi[1]} columns in total.\",\n",
    "    )\n",
    "\n",
    "    # Get all new columns:\n",
    "    new_cols = df_target_and_data_with_apt.columns.to_list()\n",
    "    new_cols = [\n",
    "        col for col in new_cols if col not in df_target_and_data.columns.to_list()\n",
    "    ]\n",
    "    print(f\"New columns: {new_cols}\")\n",
    "\n",
    "    df_target_and_data = df_target_and_data_with_apt.copy()\n",
    "else:\n",
    "    print(\"Not adding apt data.\")\n",
    "    df_target_and_data_with_apt = df_target_and_data.copy()\n",
    "\n",
    "print(\n",
    "    f\"\\nShape of before adding apt:\\t {nvarsnfi}\",\n",
    "    f\"\\nShape of after adding apt:\\t {df_target_and_data_with_apt.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altimetry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvarsnfi = df_target_and_data.shape\n",
    "\n",
    "if user_input[\"add_dem_data\"]:\n",
    "    if \"dem_data\" not in globals():\n",
    "        dem_data = pd.read_feather(\n",
    "            \"../03_process_france_data/data_altimetry_all.feather\"\n",
    "        )\n",
    "\n",
    "    missing_idp_in_apt = list(\n",
    "        set(df_target_and_data[\"idp\"].unique()) - set(dem_data[\"idp\"].unique())\n",
    "    )\n",
    "    print(\n",
    "        f\"Site idp that are in df_target_and_data but not in dem_data {len(missing_idp_in_apt)}: {missing_idp_in_apt}\\n\",\n",
    "    )\n",
    "\n",
    "    nvarsapt = dem_data.shape[1] - 1  # minus one for idp\n",
    "\n",
    "    df_target_and_data_with_dem = df_target_and_data.merge(\n",
    "        dem_data, how=\"left\", left_on=\"idp\", right_on=\"idp\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Shape of dem_data: {dem_data.shape}\",\n",
    "        f\"\\nAdding {nvarsapt} columns = {nvarsapt + nvarsnfi[1]} columns in total.\",\n",
    "    )\n",
    "\n",
    "    # Get all new columns:\n",
    "    new_cols = df_target_and_data_with_dem.columns.to_list()\n",
    "    new_cols = [\n",
    "        col for col in new_cols if col not in df_target_and_data.columns.to_list()\n",
    "    ]\n",
    "    print(f\"New columns: {new_cols}\")\n",
    "\n",
    "    new_cols = df_target_and_data_with_dem.columns.to_list()\n",
    "\n",
    "    df_target_and_data = df_target_and_data_with_dem.copy()\n",
    "else:\n",
    "    print(\"Not adding apt data.\")\n",
    "    df_target_and_data_with_dem = df_target_and_data.copy()\n",
    "\n",
    "print(\n",
    "    f\"\\nShape of before adding apt:\\t {nvarsnfi}\",\n",
    "    f\"\\nShape of after adding apt:\\t {df_target_and_data_with_dem.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_qc = df_target_and_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if stratification variables need to be added\n",
    "add_strata = False\n",
    "for strata in user_input[\"test_train_strata\"]:\n",
    "    if strata not in df_pre_qc.columns:\n",
    "        print(f\"‚ùó {strata} was not in df_target_and_data. Attaching them now...\")\n",
    "        add_strata = True\n",
    "if add_strata:\n",
    "    df_post_qc = df_pre_qc.merge(\n",
    "        nfi_at_location_level[[\"idp\"] + user_input[\"test_train_strata\"]],\n",
    "        how=\"left\",\n",
    "        left_on=\"idp\",\n",
    "        right_on=\"idp\",\n",
    "    )\n",
    "\n",
    "else:\n",
    "    df_post_qc = df_pre_qc.copy()\n",
    "\n",
    "print(f\"\\nShape of df_pre_qc:  {df_pre_qc.shape}\")\n",
    "print(f\"Shape of df_post_qc: {df_post_qc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no idp is duplicated\n",
    "if sum(df_post_qc[\"idp\"].value_counts() > 1) > 0:\n",
    "    raise SystemError(\"There are duplicated idp's in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on shapes of nfi without data and with data\n",
    "print(\n",
    "    f\"\\nShape of nfi_at_location_level: {df_target.shape}\",\n",
    "    f\"\\nShape of df_post_qc: {df_post_qc.shape}\",\n",
    "    f\"\\nA total of {df_post_qc.shape[1] - df_target.shape[1]} columns were added.\",\n",
    ")\n",
    "\n",
    "print(\"All columns in df_post_qc and their type:\")\n",
    "for i, col in enumerate(df_post_qc.columns):\n",
    "    print(f\" {i:<5} {df_post_qc[col].dtype:}\\t {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_r_squared(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "\n",
    "def create_scatterplots(target, dataframe, subfolder, verbose=False):\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    if verbose:\n",
    "        print(f\"Creating subfolder {subfolder} if it doesn't exist...\")\n",
    "    subfolder = f\"{subfolder}\"\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "\n",
    "    # Get the list of variables in the dataframe\n",
    "    variables = dataframe.columns\n",
    "\n",
    "    # Initialize an empty dataframe to store correlation values\n",
    "    correlation_table = pd.DataFrame(\n",
    "        columns=[\"Target_Variable\", \"Predictor_Variable\", \"Pearson_Correlation\"]\n",
    "    )\n",
    "\n",
    "    # Ignore the specific warning when smoother fails\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", category=RuntimeWarning, message=\"invalid value encountered in divide\"\n",
    "    )\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        category=RuntimeWarning,\n",
    "        message=\"divide by zero encountered in divide\",\n",
    "    )\n",
    "\n",
    "    # Loop through each variable\n",
    "    for variable in variables:\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\n - {variables.get_loc(variable)+1}/{len(variables)}: \\t {variable}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        # Check if variable has only NA values\n",
    "        if dataframe[variable].isna().sum() > (0.8 * len(dataframe[variable])):\n",
    "            if verbose:\n",
    "                print(f\"\\t | {variable} has > 80% NA values. Skipping...\", end=\"\")\n",
    "            # Write information to file\n",
    "            with open(f\"{subfolder}/_skipped_variables.txt\", \"a\") as file:\n",
    "                file.write(f\"{variable}\\t has only NA values. Skipping...\\n\")\n",
    "            continue\n",
    "\n",
    "        if variable != target:\n",
    "            # Density plot for numerical variables\n",
    "            if pd.api.types.is_numeric_dtype(dataframe[variable]):\n",
    "                try:\n",
    "                    # Start figure\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    # Add density plot\n",
    "                    sns.kdeplot(\n",
    "                        data=dataframe,\n",
    "                        x=variable,\n",
    "                        y=target,\n",
    "                        fill=True,\n",
    "                        cmap=\"mako\",\n",
    "                        levels=100,\n",
    "                        warn_singular=False,\n",
    "                    )\n",
    "                    # Add smoother\n",
    "                    sns.regplot(\n",
    "                        x=variable,\n",
    "                        y=target,\n",
    "                        data=dataframe,\n",
    "                        lowess=True,\n",
    "                        color=\"tomato\",\n",
    "                        scatter_kws={\"color\": \"royalblue\", \"alpha\": 0.75, \"s\": 5},\n",
    "                        line_kws={\"color\": \"tomato\"},\n",
    "                    )\n",
    "                    # Add title\n",
    "                    plt.title(f\"{target} ~ {variable}\")\n",
    "                    # Calculate Pearson correlation coefficient\n",
    "                    r = round(\n",
    "                        np.corrcoef(dataframe[target], dataframe[variable])[0, 1], 2\n",
    "                    )\n",
    "                    # Add values to the correlation table dataframe\n",
    "                    correlation_table = pd.concat(\n",
    "                        [\n",
    "                            correlation_table,\n",
    "                            pd.DataFrame(\n",
    "                                {\n",
    "                                    \"Target_Variable\": [target],\n",
    "                                    \"Predictor_Variable\": [variable],\n",
    "                                    \"Pearson_Correlation\": [r],\n",
    "                                }\n",
    "                            ),\n",
    "                        ],\n",
    "                    ).reset_index(drop=True)\n",
    "                    plt.text(\n",
    "                        0.5,\n",
    "                        0.95,\n",
    "                        f\"pearson-r: {r:.2f}\",\n",
    "                        transform=plt.gca().transAxes,\n",
    "                        fontsize=10,\n",
    "                        verticalalignment=\"top\",\n",
    "                    )\n",
    "                    # Save the figure\n",
    "                    plt.savefig(os.path.join(f\"{subfolder}/{variable}.png\"))\n",
    "                    plt.close()\n",
    "\n",
    "                # If density plot caused error, then plot scatterplot\n",
    "                except ValueError as e:\n",
    "                    if verbose:\n",
    "                        print(\n",
    "                            f\"Making only scatterplot because of error plotting {target} ~ {variable}: {e}\"\n",
    "                        )\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    sns.scatterplot(x=variable, y=target, data=dataframe, s=5)\n",
    "                    plt.title(f\"{target} ~ {variable}\")\n",
    "                    plt.savefig(os.path.join(f\"{subfolder}/{variable}.png\"))\n",
    "                    plt.close()\n",
    "\n",
    "            # If not numerical, then plot violin plot\n",
    "            elif pd.api.types.is_object_dtype(dataframe[variable]):\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                sns.violinplot(x=variable, y=target, data=dataframe)\n",
    "                plt.title(f\"{target} ~ {variable}\")\n",
    "                plt.savefig(os.path.join(f\"{subfolder}/{variable}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "    # Save the correlation table dataframe as a CSV file\n",
    "    correlation_table = correlation_table.sort_values(\"Pearson_Correlation\")\n",
    "    correlation_table.to_csv(\n",
    "        os.path.join(subfolder, f\"_correlation_table.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # Reset warnings to default behavior\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    # return correlation_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üå≤ Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data_raw = df_post_qc.copy()\n",
    "print(\"Shape of rf_data_raw:\", rf_data_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõë Add Custom Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROWS FILTER\n",
    "if user_input[\"target\"] == \"mort_stems_prc_yr_esq\":\n",
    "    rf_data_raw = rf_data_raw[rf_data_raw[target] != 100]\n",
    "\n",
    "\n",
    "if user_input[\"target\"] == \"mort_ba_prc_yr_v1\":\n",
    "    rf_data_raw = rf_data_raw[rf_data_raw[target] != 20]\n",
    "\n",
    "print(\"New shape of rf_data_raw:\", rf_data_raw.shape)\n",
    "print(\n",
    "    \"Number of rows dropped:\",\n",
    "    nfi_at_location_level.shape[0] - rf_data_raw.shape[0],\n",
    "    \" (\",\n",
    "    round(\n",
    "        (nfi_at_location_level.shape[0] - rf_data_raw.shape[0])\n",
    "        / nfi_at_location_level.shape[0]\n",
    "        * 100,\n",
    "        2,\n",
    "    ),\n",
    "    \"% )\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS FILTER\n",
    "col_filter = \"none\"\n",
    "\n",
    "if col_filter != \"none\":\n",
    "    # Subset code:\n",
    "    to_keep = [\n",
    "        \"idp\",\n",
    "        target,\n",
    "        # Selection of vars from a good model:\n",
    "        \"top1_species\",\n",
    "        \"top2_species\",\n",
    "        \"nincid_2\",\n",
    "        \"top3_species\",\n",
    "        \"ntrees_1\",\n",
    "        \"dom_nr1_tree_class_ba_abs\",\n",
    "        \"ntrees_2\",\n",
    "        \"gre\",\n",
    "        \"site_ba_prc_dead_at_v1\",\n",
    "    ] + test_train_strata\n",
    "\n",
    "    # Remove duplicates from the list\n",
    "    to_keep = list(dict.fromkeys(to_keep))\n",
    "\n",
    "    # Keep only selected variables\n",
    "    rf_data_raw = rf_data_raw[to_keep]\n",
    "\n",
    "    # Output\n",
    "    # print(f\"Number of columns removed: {nfi_at_location_level.shape[1] - len(to_keep)}\")\n",
    "    # print(rf_data_raw.shape)\n",
    "    # print(rf_data_raw.columns)\n",
    "\n",
    "    # Write information:\n",
    "    file_path = f\"{current_dir}/‚ö†Ô∏è_COL_FILTER_{col_filter}.txt\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(f\"{col_filter}\")\n",
    "\n",
    "    print(\"New shape of rf_data_raw:\", rf_data_raw.shape)\n",
    "    print(\n",
    "        \"Number of rows dropped:\",\n",
    "        nfi_at_location_level.shape[1] - rf_data_raw.shape[1],\n",
    "        \" (\",\n",
    "        round(\n",
    "            (nfi_at_location_level.shape[1] - rf_data_raw.shape[1])\n",
    "            / nfi_at_location_level.shape[1]\n",
    "            * 100,\n",
    "            2,\n",
    "        ),\n",
    "        \"% )\",\n",
    "    )\n",
    "\n",
    "print(f\"Shape of rf_data_raw: {rf_data_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove NAs in Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original shape\n",
    "shape_org = df_subsetted_sites.shape\n",
    "# Drop rows where target is NA\n",
    "df_without_nas = df_subsetted_sites.dropna(subset=[target])\n",
    "# Print information\n",
    "print(\n",
    "    f\"Dropping NA values in target variable `{target}` reduced the dataset by:\",\n",
    "    f\"\\n - {shape_org[0] - df_without_nas.shape[0]} rows ({round((shape_org[0] - df_without_nas.shape[0])/shape_org[0]*100, 2)}%)\",\n",
    "    f\"\\n - Shape changed from {shape_org} to {df_without_nas.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove 0s in Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original shape\n",
    "shape_org = df_without_nas.shape\n",
    "# Get copy of data\n",
    "df_all0s = df_without_nas.copy()\n",
    "df_no0s = df_without_nas.copy()\n",
    "# Reduce to have only target 0s\n",
    "df_all0s = df_all0s[df_all0s[user_input[\"target\"]] == 0]\n",
    "df_no0s = df_no0s[df_no0s[user_input[\"target\"]] != 0]\n",
    "# Get fraction of zeros or no zeros\n",
    "perc_0s = round(df_all0s.shape[0] / shape_org[0] * 100, 2)\n",
    "perc_no0s = round(df_no0s.shape[0] / shape_org[0] * 100, 2)\n",
    "# Get fraction of 0-entries that should be kept.\n",
    "# Percentage is relative to the dataframe without any 0s and NAs\n",
    "perc_to_add = user_input[\"add_target_0s_percentage\"]\n",
    "n_rows_to_add = round(perc_to_add * df_no0s.shape[0], 0)\n",
    "\n",
    "# Print information\n",
    "print(\n",
    "    f\"üëâ Note that this information is AFTER dropping NAs in the target variable `{target}`:\\n\",\n",
    "    f\" - Dataset with 0 values has shape \\t {df_without_nas.shape} (=100%)\",\n",
    "    f\"\\n  - From this keeping only 0s in target gives shape {df_all0s.shape[0]} ({perc_0s}%)\",\n",
    "    f\"\\n  - From this removing all 0s in target gives shape {df_no0s.shape[0]} ({perc_no0s}%)\",\n",
    "    f\"\\n  - Adding {round(perc_to_add*100)}% of NA values equals adding {n_rows_to_add} rows.\",\n",
    "    f\"\\n  - ‚ùóSo the outgoing dataframe should have ~{df_no0s.shape[0] + n_rows_to_add} rows.\",\n",
    ")\n",
    "\n",
    "if user_input[\"add_target_0s\"]:\n",
    "    # SAMPLING OF TARGET 0s\n",
    "    # Do random sampling of 0s\n",
    "    if user_input[\"add_target_0s_strata\"] == \"none\":\n",
    "        print(\"\\n - Adding randomly sampled 0s to the dataset...\")\n",
    "        sample_perc_from_all0s = n_rows_to_add / df_all0s.shape[0]\n",
    "        df_subset0s = df_all0s.sample(\n",
    "            frac=sample_perc_from_all0s, random_state=seed_nr, replace=False\n",
    "        )\n",
    "\n",
    "    # Do a stratified sampling based on the 'add_target_0s_strata' variable\n",
    "    if user_input[\"add_target_0s_strata\"] != \"none\":\n",
    "        print(\n",
    "            f\"\\n - Adding randomly sampled 0s to the dataset based on stratification variable {user_input['add_target_0s_strata']}...\"\n",
    "        )\n",
    "        # Check if strata variable is in the data\n",
    "        if user_input[\"add_target_0s_strata\"] not in df_all0s.columns:\n",
    "            # If strata is not in the nfi data, throw error\n",
    "            if user_input[\"add_target_0s_strata\"] not in nfi_at_location_level.columns:\n",
    "                raise SystemExit(\n",
    "                    f\"‚ùå The requested strata variable `{user_input['add_target_0s_strata']}` is not in the NFI data!\"\n",
    "                )\n",
    "            # Else, attach strata from nfi data temporarily\n",
    "            # Print information on behaviour\n",
    "            print(\n",
    "                f\"   - ‚ùóThe strata variable for adding 0s `{user_input['add_target_0s_strata']}` was not in the data but added temporarily for the split.\"\n",
    "            )\n",
    "\n",
    "            # Get tmp df from nfi data with strata\n",
    "            df_tmp = nfi_at_location_level[\n",
    "                [\"idp\", user_input[\"add_target_0s_strata\"]]\n",
    "            ].rename(columns={user_input[\"add_target_0s_strata\"]: \"nfi_strata\"})\n",
    "\n",
    "            if (df_tmp.shape[1]) > 2:\n",
    "                raise SystemExit(\n",
    "                    f\"‚ùå Trying to add to many columns! df_tmp has {df_tmp.shape[1]} columns but should only have 2 columns, idp and strata.\"\n",
    "                )\n",
    "\n",
    "            # Get number of rows before merging\n",
    "            nrows_before = df_all0s.shape[0]\n",
    "            # Attach strata to df_all0s (which is a subset of df_without_nas!)\n",
    "            df_all0s = df_all0s.merge(df_tmp, how=\"left\", left_on=\"idp\", right_on=\"idp\")\n",
    "            # Check if number of rows changed\n",
    "            nrows_after = df_all0s.shape[0]\n",
    "            if nrows_before != nrows_after:\n",
    "                raise SystemExit(\n",
    "                    f\"‚ùå Number of rows in df_all0s ({nrows_before}) is not equal to number of rows in df_all0s ({nrows_after}) after attaching strata variable from NFI!\"\n",
    "                )\n",
    "        else:\n",
    "            # Else, just use the strata variable directly\n",
    "            df_all0s[\"nfi_strata\"] = df_all0s[user_input[\"add_target_0s_strata\"]]\n",
    "\n",
    "        # Group by strata\n",
    "        df_subset0s = df_all0s.groupby(\"nfi_strata\")\n",
    "        # CHECKS -------------------------------------------------------------------\n",
    "        # Check if groups hold too little rows to sample evenly across all strata\n",
    "        n_groups = df_subset0s.ngroups\n",
    "        n_rows_to_add_per_group = int(round(n_rows_to_add / n_groups, 0))\n",
    "        # Percentage of groups with less than requested number of rows per group\n",
    "        perc_undersampled = round(\n",
    "            (df_subset0s.size() < n_rows_to_add_per_group).sum()\n",
    "            / df_subset0s.size().shape[0]\n",
    "            * 100\n",
    "        )\n",
    "\n",
    "        if perc_undersampled > 50:\n",
    "            raise SystemExit(\n",
    "                f\"‚ùå {perc_undersampled}% of the groups have less than the requested sampling size per group! This is too much, based on a 50% threshold.\"\n",
    "            )\n",
    "        print(\n",
    "            f\"   - ‚úÖ {perc_undersampled}% of the groups have less than the requested sampling size per group.\"\n",
    "        )\n",
    "        # CHECKS -------------------------------------------------------------------\n",
    "        # Do the sampling:\n",
    "        df_subset0s = df_subset0s.apply(\n",
    "            lambda x: x.sample(\n",
    "                min(n_rows_to_add_per_group, len(x)), random_state=seed_nr\n",
    "            )\n",
    "        )\n",
    "        # Ungroup again\n",
    "        df_subset0s = df_subset0s.reset_index(drop=True)\n",
    "\n",
    "        # Remove strata\n",
    "        df_subset0s = df_subset0s.drop(\"nfi_strata\", axis=1)\n",
    "        print(\"   - ‚úÖ Removed strata variable again.\")\n",
    "\n",
    "    # Attach subset to df without 0s\n",
    "    df_subset0s = pd.concat([df_no0s, df_subset0s], axis=0)\n",
    "\n",
    "    # Check that there are no idp duplicates created\n",
    "    if df_subset0s[\"idp\"].nunique() != df_subset0s.shape[0]:\n",
    "        raise SystemExit(\n",
    "            f\"‚ùå Number of rows in df_subset0s ({df_subset0s.shape[0]}) is not equal to number of unique idp ({df_subset0s['idp'].nunique()})!\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"   - ‚úÖ Number of rows in df_subset0s ({df_subset0s.shape[0]}) is equal to number of unique idp ({df_subset0s['idp'].nunique()})!\"\n",
    "        )\n",
    "\n",
    "    # Falling back to first if statement level\n",
    "    # Print information\n",
    "    print(\n",
    "        f\"\\nThe original ingoing dataset (no NAs) had the shape\\t\\t {shape_org}\",\n",
    "        f\"\\nAfter adding a {round(perc_to_add*100)}% subset of 0s, the dataset has the shape\\t {df_subset0s.shape}\",\n",
    "    )\n",
    "\n",
    "    df_after_row_filter = df_subset0s.copy()\n",
    "\n",
    "else:\n",
    "    df_after_row_filter = df_without_nas.copy()[\n",
    "        df_without_nas[user_input[\"target\"]] != 0\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"\\nAll entries where {user_input['target']} == 0 were removed!\",\n",
    "        f\"\\n - Shape before:\\t{df_without_nas.shape}\",\n",
    "        f\"\\n - Shape after: \\t{df_after_row_filter.shape}\",\n",
    "        f\"\\n - This is a removal of {df_without_nas.shape[0] - df_no0s.shape[0]} rows ({round((df_without_nas.shape[0] - df_no0s.shape[0])/df_without_nas.shape[0]*100, 2)}%)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_to_quantile = df_after_row_filter.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"reduce_to_percentile\"]:\n",
    "    df_reduced_to_quantile[\"quantiles\"] = split_into_quantiles(\n",
    "        df_reduced_to_quantile[target], user_input[\"percentile_n_group\"]\n",
    "    )\n",
    "    quantile_lvls = sorted(df_reduced_to_quantile[\"quantiles\"].unique())\n",
    "    keep_this_quantile = quantile_lvls[user_input[\"percentile_group\"]]\n",
    "    df_reduced_to_quantile = df_reduced_to_quantile[\n",
    "        df_reduced_to_quantile[\"quantiles\"] == keep_this_quantile\n",
    "    ]\n",
    "\n",
    "    df_reduced_to_quantile = df_reduced_to_quantile.drop(columns=\"quantiles\")\n",
    "\n",
    "    # Report results\n",
    "    print(\n",
    "        f\"\\n - Shape before:\\t{df_after_row_filter.shape}\",\n",
    "        f\"\\n - Shape after: \\t{df_reduced_to_quantile.shape}\",\n",
    "        f\"\\n - Reducing data to percentiles {keep_this_quantile} means a removal of {df_after_row_filter.shape[0] - df_reduced_to_quantile.shape[0]} rows ({round((df_after_row_filter.shape[0] - df_reduced_to_quantile.shape[0])/df_after_row_filter.shape[0]*100, 2)}%)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not user_input[\"make_classification\"]:\n",
    "    if user_input[\"reduce_to_percentile\"]:\n",
    "        # Plot original distribution with inputded quantiles\n",
    "        plot_quantiles(\n",
    "            df_after_row_filter[user_input[\"target\"]],\n",
    "            user_input[\"percentile_n_group\"],\n",
    "            user_input[\"target\"],\n",
    "            current_dir,\n",
    "        )\n",
    "\n",
    "    # Plot distribution of subsetted quantile\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.histplot(df_reduced_to_quantile, x=target, ax=ax)\n",
    "    ax.set_title(f\"Final used values for {target}\")\n",
    "    plt.savefig(f\"{current_dir}/fig_histogram_{target}_final.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not plotting histograms because classification is used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified = df_reduced_to_quantile.copy()\n",
    "\n",
    "if user_input[\"make_classification\"]:\n",
    "    # Plot original distribution with inputded quantiles\n",
    "    plot_quantiles(\n",
    "        df_after_row_filter[target],\n",
    "        user_input[\"classification_groups\"],\n",
    "        user_input[\"target\"],\n",
    "        current_dir,\n",
    "    )\n",
    "\n",
    "    df_classified[target] = split_into_quantiles(\n",
    "        df_classified[target], user_input[\"classification_groups\"]\n",
    "    )\n",
    "\n",
    "    # Plot distribution of target variable\n",
    "    plt.figure()\n",
    "    df_classified[target].value_counts().sort_index().plot(kind=\"bar\")\n",
    "    plt.title(f\"Distribution of classified `{user_input['target']}`\")\n",
    "    plt.savefig(f\"{current_dir}/fig_histogram_{target}_classified.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No classification of target variable was made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_stratification = df_classified.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input[\"do_corr_plots\"] = False\n",
    "# user_input[\"plot_corr_of_dataset\"] = [\"nfi\", \"gee\", \"edo\", \"rmqs\", \"apt\", \"dem\"]\n",
    "user_input[\"plot_corr_of_dataset\"] = [\"nfi\"]\n",
    "df_corr = df_for_stratification.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_corr_plots\"]:\n",
    "    # CHECK IF TARGET IS CATEGORICAL\n",
    "    if user_input[\"make_classification\"]:\n",
    "        # To make classified levels into integers\n",
    "        # Replace each level with a number and\n",
    "        # Set the variable to be an integer\n",
    "        levels = df_corr[target].unique()\n",
    "        for i in range(len(levels)):\n",
    "            df_corr[target] = df_corr[target].replace(levels[i], i)\n",
    "        df_corr[target] = df_corr[target].astype(int)\n",
    "\n",
    "    # Loop through requested datasets\n",
    "    for ds in user_input[\"plot_corr_of_dataset\"]:\n",
    "        display(f\"----- Working on {ds}... -----\")\n",
    "        if ds == \"nfi\":\n",
    "            df_to_check = nfi_at_location_level.copy()\n",
    "        if ds == \"gee\":\n",
    "            df_to_check = gee_data.copy()\n",
    "        if ds == \"rmqs\":\n",
    "            df_to_check = rmqs_data.copy()\n",
    "        if ds == \"edo\":\n",
    "            df_to_check = edo_data.copy()\n",
    "        if ds == \"apt\":\n",
    "            df_to_check = apt_data.copy()\n",
    "        if ds == \"dem\":\n",
    "            df_to_check = dem_data.copy()\n",
    "\n",
    "        # Remove target from df_to_check and get colums\n",
    "        cols = df_to_check.drop(\n",
    "            columns=[user_input[\"target\"], \"idp\"], errors=\"ignore\"\n",
    "        ).columns.tolist() + [user_input[\"target\"]]\n",
    "\n",
    "        # Subset df_corr to only contain columns in cols\n",
    "        cols = sorted(cols)\n",
    "        df_corrplot = df_corr[cols]\n",
    "\n",
    "        # Save plots\n",
    "        dir_tmp = current_dir + \"/corr_plots/\" + ds\n",
    "        create_scatterplots(user_input[\"target\"], df_corrplot, dir_tmp, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell exists just to easier run from top to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Stratifcation Distribution\n",
    "\n",
    "- How to do this the right way: Sequential call for split and cvfolding\n",
    "- Then, record what strata were aggregated\n",
    "- Then in the end, take the initial dataframe again and aggregate the strata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(user_input[\"test_train_strata\"]) > 0:\n",
    "    df_aggregated_strata = aggregate_strata_with_too_little_obs(\n",
    "        Xy_in=df_for_stratification.copy(),\n",
    "        strata_vars=user_input[\"test_train_strata\"],\n",
    "        do_fold_too=True,\n",
    "        split_test=user_input[\"test_split\"],\n",
    "        cv_fold=user_input[\"cv_folds\"],\n",
    "        seed_nr=user_input[\"seed_nr\"],\n",
    "    )\n",
    "\n",
    "    display(f\"Shape of df_aggregated_strata: {df_aggregated_strata.shape}\")\n",
    "else:\n",
    "    df_aggregated_strata = df_for_stratification.copy()\n",
    "    print(\"No strata variables specified, so not aggregating strata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### based on Excel sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_dropping_cols = df_aggregated_strata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCEL-BASED COLUMN REMOVAL\n",
    "df_tmp = df_before_dropping_cols.copy()\n",
    "\n",
    "# Remove columns that are not needed as specified\n",
    "columns_to_remove = vars_described_in_sheet_and_in_df.query(\"remove == 'x'\")[\n",
    "    \"var\"\n",
    "].to_list()\n",
    "\n",
    "# Make sure that idp is only removed before running the random forest\n",
    "if \"idp\" in columns_to_remove:\n",
    "    columns_to_remove.remove(\"idp\")\n",
    "\n",
    "columns_to_remove = sorted(columns_to_remove)\n",
    "\n",
    "# Remove the columns from df_tmp\n",
    "df_tmp = df_tmp.drop(columns=columns_to_remove)\n",
    "\n",
    "print(f\"{len(columns_to_remove)} columns removed as specified in excel file:\")\n",
    "for column in columns_to_remove:\n",
    "    print(f\" - {column}\", end=\"\\n\")\n",
    "\n",
    "print(\"Shape of df_tmp:\", df_tmp.shape)\n",
    "\n",
    "df_dropping_excel_cols = df_tmp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### based on %NAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP COLUMNS WITH TOO MANY NA VALUES\n",
    "\n",
    "# Get temporary df for cell\n",
    "df_tmp = df_dropping_excel_cols.copy()\n",
    "\n",
    "# Unify encoding of missing data (NA into NaN)\n",
    "df_tmp = df_tmp.fillna(value=pd.NA)\n",
    "\n",
    "# Get number of rows of dataframe to calculate percentages\n",
    "n_rows = df_tmp.shape[0]\n",
    "\n",
    "print(\"Variables that were dropped because they have too many NAs:\")\n",
    "for my_col in sorted(df_tmp.columns):\n",
    "    n_na = df_tmp[my_col].isna().sum()\n",
    "    na_perc = n_na / n_rows\n",
    "\n",
    "    if na_perc > na_drop_threshold:\n",
    "        df_tmp = df_tmp.drop(my_col, axis=1)\n",
    "        print(f\" - {my_col:<29} with #NAs = {n_na:<5} | {round(na_perc*100)} %\")\n",
    "\n",
    "df_dropped_na_cols = df_tmp.copy()\n",
    "\n",
    "display(\"\")\n",
    "print(\n",
    "    f\"üëâ df shape changed from: {df_aggregated_strata.shape} to {df_dropped_na_cols.shape}\",\n",
    "    end=\"\",\n",
    ")\n",
    "print(\n",
    "    f\" = {df_aggregated_strata.shape[1] - df_dropped_na_cols.shape[1]} variables were dropped.\"\n",
    ")\n",
    "\n",
    "removed_vars = [\n",
    "    var for var in df_aggregated_strata.columns if var not in df_dropped_na_cols.columns\n",
    "]\n",
    "print(f\"The following {len(removed_vars)} variables were dropped: {removed_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get remaining columns with NA values for imputation later\n",
    "vars_with_na = df_dropped_na_cols.columns[df_dropped_na_cols.isna().any()].tolist()\n",
    "vars_with_na = vars_with_na\n",
    "print(\"Variables still containing NAs:\")\n",
    "for var in vars_with_na:\n",
    "    print(f\" - {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### based on user input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove variables that have mostly the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temporary df\n",
    "df_tmp = df_dropped_na_cols.copy()\n",
    "\n",
    "# Fix user removal input\n",
    "# If target in variables to remove, remove it\n",
    "if target in user_input_variable_removal:\n",
    "    user_input_variable_removal.remove(target)\n",
    "\n",
    "# If stratification variables in variables to remove, remove them.\n",
    "# They will be removed later.\n",
    "for var in test_train_strata:\n",
    "    if var in user_input_variable_removal:\n",
    "        user_input_variable_removal.remove(var)\n",
    "\n",
    "# Remove variables: Setting errors to ignore because some vars may have already been dropped:\n",
    "print(\n",
    "    \"Variables that have been selected to drop but have been dropped by the routine already: \"\n",
    ")\n",
    "for var in user_input_variable_removal:\n",
    "    if var not in df_tmp.columns:\n",
    "        print(var, end=\", \")\n",
    "\n",
    "df_tmp = df_tmp.drop(columns=user_input_variable_removal, errors=\"ignore\")\n",
    "\n",
    "# If idp is still in dataframe, remove now explicitly\n",
    "if \"idp\" in df_tmp.columns:\n",
    "    print(\"Removing idp from dataframe.\")\n",
    "    df_tmp = df_tmp.drop(columns=\"idp\")\n",
    "\n",
    "# Get list of variables that were dropped\n",
    "removed_vars = [var for var in df_dropped_na_cols.columns if var not in df_tmp.columns]\n",
    "\n",
    "df_dropped_user_cols = df_tmp.copy()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Shape before dropping user selected vars: {df_dropped_na_cols.shape}\")\n",
    "print(f\"Shape after dropping user selected vars: {df_dropped_user_cols.shape}\")\n",
    "print(f\"The following {len(removed_vars)} variables were removed: {removed_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variables to impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Output of this cell should be empty because categorical variables with NA values should not be in the data.\n",
    "\n",
    "# GET CATEGORICAL VARIABLES WITH NA VALUES\n",
    "# Get all categorical variables that have NAs in them\n",
    "# cats_with_na = vars_with_na[vars_with_na.isin(vars_to_ohe)].tolist()\n",
    "cats_with_na = [var for var in vars_with_na if var in vars_to_ohe]\n",
    "\n",
    "print(\"Categorical Variables that still have NA (NA will be turned into 'missing'):\")\n",
    "for var in cats_with_na:\n",
    "    print(\" \", var, end=\", \")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Replace NA values with \"missing\"\n",
    "for var in cats_with_na:\n",
    "    # df_dropped_user_cols[var] = df_dropped_user_cols[var].fillna(\"missing\")\n",
    "    df_dropped_user_cols[var][df_dropped_user_cols[var] == \"NA\"] = \"missing\"\n",
    "\n",
    "print(\"Variables encoded to be categorical:\")\n",
    "for var in vars_to_ohe:\n",
    "    if var in df_dropped_user_cols.columns:\n",
    "        df_dropped_user_cols[var] = df_dropped_user_cols[var].astype(str)\n",
    "        print(f\" - {var}\", end=\"\\n\")\n",
    "\n",
    "# Make sure idp is kept as int to merge with gee data later\n",
    "# df_dropped_user_cols[\"idp\"] = df_dropped_user_cols[\"idp\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET NUMERICAL VARIABLES WITH NA VALUES\n",
    "numerics_with_na = [\n",
    "    var\n",
    "    for var in df_dropped_user_cols.columns\n",
    "    if df_dropped_user_cols[var].dtype != \"O\"\n",
    "]  # No categorical variables\n",
    "numerics_with_na = [\n",
    "    var for var in numerics_with_na if var not in date_cols\n",
    "]  # No date time variables\n",
    "numerics_with_na = [\n",
    "    var for var in numerics_with_na if var in vars_with_na\n",
    "]  # Reduce to variables that hold NA values\n",
    "numerics_with_na = [\n",
    "    var for var in numerics_with_na if var != target\n",
    "]  # Make sure target is not in the list\n",
    "\n",
    "print(\"Numerical variables with NA values to be imputed:\")\n",
    "counter = 0\n",
    "for var in numerics_with_na:\n",
    "    print(f\" {counter}. {var}\")\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temporary df\n",
    "df_tmp = df_dropped_user_cols.copy()\n",
    "\n",
    "# Get all variables names before one-hot encoding\n",
    "all_var_names_before_ohe = sorted(df_tmp.columns.to_list())\n",
    "\n",
    "# Set variables to not ohe:\n",
    "my_vars_not_to_ohe = [\"test_train_strata\"]\n",
    "\n",
    "# Do the OHE\n",
    "df_tmp = do_ohe(df_tmp, my_vars_not_to_ohe, verbose=True)\n",
    "\n",
    "# Get all variables names after one-hot encoding\n",
    "all_var_names_after_ohe = sorted(df_tmp.columns.to_list())\n",
    "\n",
    "# Get variable dictionary\n",
    "var_ohe_dict = {}\n",
    "for var in all_var_names_before_ohe:\n",
    "    sub_vars = []\n",
    "\n",
    "    if var in all_var_names_after_ohe:\n",
    "        # If the variable was not ohe, it stays the same\n",
    "        var_ohe_dict[var] = [var]\n",
    "        continue\n",
    "    else:\n",
    "        # If the variable was ohe, search for pattern and add it\n",
    "        pattern = r\"^\" + var + r\"_.*\"\n",
    "        for sub_var in all_var_names_after_ohe:\n",
    "            # print(pattern, sub_var, re.match(pattern, sub_var))\n",
    "            if re.match(pattern, sub_var):\n",
    "                sub_vars.append(sub_var)\n",
    "    var_ohe_dict[var] = sub_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_splitting = df_tmp.copy()\n",
    "df_for_splitting.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_for_splitting.drop(target, axis=1),\n",
    "    df_for_splitting[target],\n",
    "    test_size=test_split,\n",
    "    random_state=seed_nr,\n",
    "    stratify=df_for_splitting[\"test_train_strata\"],\n",
    ")\n",
    "\n",
    "# Merge dataframes back for easier handling\n",
    "Xy_train_raw = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
    "Xy_test_raw = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n",
    "\n",
    "print(\n",
    "    f\"Shape of Xy_train_raw: {Xy_train_raw.shape}\",\n",
    "    f\"\\nShape of Xy_test_raw: {Xy_test_raw.shape}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NA Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes on imputation:\n",
    "# - OHE'd values are not imputed because by definition they hold no NA values!\n",
    "Xy_train_imputed, Xy_test_imputed, imputed_vars = impute_numerical_na(\n",
    "    Xy_train_raw,\n",
    "    Xy_test_raw,\n",
    "    target_in=user_input[\"target\"],\n",
    "    method=user_input[\"imputation_method\"],\n",
    "    n_neighbours=10,\n",
    "    vars_not_to_impute=test_train_strata,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\" - Imputed variables: {' | '.join(sorted(imputed_vars))}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After imputation, ordinal values are floats. Convert them back to int\n",
    "nfi_ordinal_vars = nfi_org.query(\"type == 'ord'\")[\"var\"].to_list()\n",
    "corrected_ordinals = []\n",
    "for var in nfi_ordinal_vars:\n",
    "    if var in Xy_train_imputed.columns:\n",
    "        Xy_train_imputed[var] = Xy_train_imputed[var].astype(int)\n",
    "        Xy_test_imputed[var] = Xy_test_imputed[var].astype(int)\n",
    "        corrected_ordinals.append(var)\n",
    "\n",
    "print(\n",
    "    f\" - Corrected ordinal variables from floats to integr: {' | '.join(sorted(corrected_ordinals))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_random_search\"]:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    # Get dataframes\n",
    "    Xy_train_final = Xy_train_imputed.copy()\n",
    "    test_train_strata = Xy_train_final[\"test_train_strata\"].to_list()\n",
    "    X_train_final = Xy_train_final.drop(columns=[target, \"test_train_strata\"])\n",
    "    y_train_final = Xy_train_final[target]\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [int(x) for x in np.linspace(start=10, stop=2500, num=10)],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", 0.2, 0.4, 0.6, 0.8],\n",
    "        # + [x for x in np.linspace(start=0.1, stop=0.8, num=1)],\n",
    "        \"max_depth\": [int(x) for x in np.linspace(1, 50, num=8)],\n",
    "        \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"bootstrap\": [True, False],\n",
    "    }\n",
    "\n",
    "    print(\"Parameter grid:\")\n",
    "    for key, value in param_grid.items():\n",
    "        print(f\" - {key}: {value}\")\n",
    "    display(\"\")\n",
    "\n",
    "    # Use StratifiedKFold with your stratifying variable\n",
    "    # stratified_kfold = StratifiedKFold(n_splits=user_input[\"cv_folds\"], shuffle=True)\n",
    "    stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    # Make sure the stratifying variable is used here\n",
    "    folds = list(stratified_kfold.split(X_train_final, test_train_strata))\n",
    "\n",
    "    # Create a base model\n",
    "    if user_input[\"make_classification\"]:\n",
    "        rf = RandomForestClassifier()\n",
    "    else:\n",
    "        rf = RandomForestRegressor()\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=1000,\n",
    "        cv=folds,\n",
    "        verbose=1,\n",
    "        random_state=seed_nr,\n",
    "        n_jobs=9,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    grid_search.fit(\n",
    "        X_train_final,\n",
    "        y_train_final,\n",
    "        sample_weight=get_weights_from_y(y_train_final, user_input[\"weight_method\"]),\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    plot_grid_search_results(\n",
    "        grid_search, filename=\"random_search_results.png\", save=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prescribed Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_prescribed_search\"]:\n",
    "    # Get dataframes\n",
    "    Xy_train_final = Xy_train_imputed.copy()\n",
    "    test_train_strata = Xy_train_final[\"test_train_strata\"].to_list()\n",
    "    X_train_final = Xy_train_final.drop(columns=[target, \"test_train_strata\"])\n",
    "    y_train_final = Xy_train_final[target]\n",
    "\n",
    "    # Use StratifiedKFold with your stratifying variable\n",
    "    # stratified_kfold = StratifiedKFold(n_splits=user_input[\"cv_folds\"], shuffle=True)\n",
    "    stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "    # Make sure the stratifying variable is used here\n",
    "    folds = list(stratified_kfold.split(X_train_final, test_train_strata))\n",
    "\n",
    "    # Create a base model\n",
    "    if user_input[\"make_classification\"]:\n",
    "        # CLASSIFICATION\n",
    "        rf = RandomForestClassifier()\n",
    "        param_grid = get_tune_grid_classification()\n",
    "        # Set the grid search model\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf,\n",
    "            param_grid=param_grid,\n",
    "            cv=folds,\n",
    "            n_jobs=9,\n",
    "            verbose=1,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "\n",
    "        # Fit the grid search to the data\n",
    "        grid_search.fit(\n",
    "            X_train_final,\n",
    "            y_train_final,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # REGRESSION\n",
    "        rf = RandomForestRegressor()\n",
    "        param_grid = get_tune_grid_regression()\n",
    "\n",
    "        # Set the grid search model\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf,\n",
    "            param_grid=param_grid,\n",
    "            cv=folds,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "\n",
    "        # Fit the grid search to the data\n",
    "        grid_search.fit(\n",
    "            X_train_final,\n",
    "            y_train_final,\n",
    "            sample_weight=get_weights_from_y(\n",
    "                y_train_final, user_input[\"weight_method\"]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # Print results\n",
    "    print(\"Parameter grid:\")\n",
    "    for key, value in param_grid.items():\n",
    "        print(f\" - {key}: {value}\")\n",
    "    display(\"\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    plot_grid_search_results(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record good values\n",
    "# Regression\n",
    "# best_params = {\n",
    "# 'n_estimators': 200,\n",
    "# 'max_features': 0.2,\n",
    "# 'max_depth': 25,\n",
    "# 'bootstrap': True\n",
    "# }\n",
    "# Classification\n",
    "# 3 groups: {'n_estimators': 500, 'max_features': 0.1, 'max_depth': 25, 'bootstrap': True, 'criterion': 'gini'}\n",
    "# 5 groups: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preset Best Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_best_rf_params(make_classification):\n",
    "    if not make_classification:\n",
    "        # REGRESSION -------------------------------------------------------------------\n",
    "        # Return best variables from previous search\n",
    "        best_params = {\n",
    "            \"n_estimators\": 500,\n",
    "            \"max_features\": 0.1,\n",
    "            \"max_depth\": 20,\n",
    "            \"bootstrap\": True,\n",
    "        }\n",
    "\n",
    "    if make_classification:\n",
    "        # CLASSIFICATION -------------------------------------------------------------------\n",
    "        best_params = {\n",
    "            \"n_estimators\": 500,\n",
    "            \"max_features\": 0.2,\n",
    "            \"max_depth\": 5,\n",
    "            \"bootstrap\": True,\n",
    "            \"criterion\": \"gini\",\n",
    "        }\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "if not user_input[\"do_prescribed_search\"] and not user_input[\"do_random_search\"]:\n",
    "    best_params = set_best_rf_params(user_input[\"make_classification\"])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ REFCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_ref\"]:\n",
    "    # --------------------------------------------------------\n",
    "    # Set parameters\n",
    "    # --------------------------------------------------------\n",
    "    # Debug\n",
    "    debug_stop = False\n",
    "    debug_stop_after_n_iterations = 10\n",
    "\n",
    "    # Folds\n",
    "    cv_folds = user_input[\"cv_folds\"]\n",
    "\n",
    "    # Number of features to remove\n",
    "    features_to_remove_above200 = 20\n",
    "    features_to_remove_above100 = 10\n",
    "    features_to_remove_above50 = 5\n",
    "    features_to_remove_above30 = 2\n",
    "    features_to_remove_below30 = 1\n",
    "\n",
    "    # Empty lists\n",
    "    ohe_vars_to_remove = []\n",
    "    non_ohe_vars_to_remove = []\n",
    "    new_ohe_vars_to_remove = []\n",
    "    new_non_ohe_vars_to_remove = []\n",
    "\n",
    "    ohe_vars_to_remove_n = 0\n",
    "    non_ohe_vars_to_remove_n = 0\n",
    "    new_ohe_vars_to_remove_n = 0\n",
    "    new_non_ohe_vars_to_remove_n = 0\n",
    "    # --------------------------------------------------------\n",
    "    # Prepare final dataframe:\n",
    "    df_cvmetrics_per_nfeatures = pd.DataFrame(\n",
    "        {\n",
    "            \"n_features\": [],\n",
    "            \"r2\": [],\n",
    "            \"r2_sd\": [],\n",
    "            \"rmse\": [],\n",
    "            \"rmse_sd\": [],\n",
    "            \"mae\": [],\n",
    "            \"mae_sd\": [],\n",
    "            \"vars_to_remove\": [],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Original number of features (not-ohe)\n",
    "    # Code below reduces the var_ohe_dict to keys where a value\n",
    "    # matches a column in X_train_imputed.\n",
    "    reduced_var_ohe_dict = {\n",
    "        key: value\n",
    "        for key, value in var_ohe_dict.items()\n",
    "        if any(col in Xy_train_imputed.columns for col in value)\n",
    "    }\n",
    "    # Remove target and strata from the dictionary\n",
    "    reduced_var_ohe_dict.pop(target, None)\n",
    "    reduced_var_ohe_dict.pop(\"test_train_strata\", None)\n",
    "\n",
    "    original_number_of_features = len(reduced_var_ohe_dict)\n",
    "    remaining_features_numbers = original_number_of_features\n",
    "\n",
    "    # Set iteration counter\n",
    "    iteration_count = 1\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # START REF-CV\n",
    "    # --------------------------------------------------------\n",
    "    while True:\n",
    "        # Set vectors to track metrics\n",
    "        if user_input[\"make_classification\"]:\n",
    "            v_accuracy = []\n",
    "            v_r2 = [np.nan]\n",
    "            v_rmse = [np.nan]\n",
    "            v_mae = [np.nan]\n",
    "        else:\n",
    "            v_accuracy = [np.nan]\n",
    "            v_r2 = []\n",
    "            v_rmse = []\n",
    "            v_mae = []\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # CROSS-VALIDATION\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "        # Remove variables of previous iteration\n",
    "        Xy_refcv = (\n",
    "            Xy_train_imputed.copy()\n",
    "            .drop(columns=ohe_vars_to_remove)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Get current number of features\n",
    "        remaining_features_numbers = (\n",
    "            original_number_of_features - non_ohe_vars_to_remove_n\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\\n‚≠ê Iteration {iteration_count} ---------------------------------------------------------\",\n",
    "            f\"\\n - Current Number of features: {original_number_of_features} - {non_ohe_vars_to_remove_n} = {remaining_features_numbers}\",\n",
    "        )\n",
    "\n",
    "        # If no more features to remove, break loop\n",
    "        if (remaining_features_numbers) == 0:\n",
    "            break\n",
    "\n",
    "        # Create folds\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=cv_folds, shuffle=True\n",
    "        )  # TODO: Check if seed should be fixed or not.\n",
    "\n",
    "        print(\"\\n - Do cross-validation...\", end=\" \")\n",
    "\n",
    "        # Create stratified folds\n",
    "        for fold, (train_index, test_index) in enumerate(\n",
    "            skf.split(Xy_refcv, Xy_refcv[\"test_train_strata\"])\n",
    "        ):\n",
    "            # Get current fold\n",
    "            Xy_refcv_train, Xy_refcv_val = (\n",
    "                Xy_refcv.iloc[train_index],\n",
    "                Xy_refcv.iloc[test_index],\n",
    "            )\n",
    "\n",
    "            # Preprocess data (Removed. Do this only on the original full dataset!)\n",
    "\n",
    "            # Split into X and y\n",
    "            X_train_if = Xy_refcv_train.drop(\n",
    "                columns=[target, \"test_train_strata\"],\n",
    "                errors=\"ignore\",\n",
    "            )\n",
    "            y_train_if = Xy_refcv_train[target]\n",
    "\n",
    "            X_val_if = Xy_refcv_val.drop(\n",
    "                columns=[target, \"test_train_strata\"],\n",
    "                errors=\"ignore\",\n",
    "            )\n",
    "            y_val_if = Xy_refcv_val[target]\n",
    "\n",
    "            # Print information\n",
    "            print(\n",
    "                f\"Fold {fold + 1} / {cv_folds}\",\n",
    "                # f\"\\n  - Fold {fold + 1} | {cv_folds}:\",\n",
    "                # f\"\\t | Validation/Test = {round(len(Xy_refcv_val) / (len(Xy_refcv_val) + len(Xy_refcv_train)) * 100)}/{round(len(Xy_refcv_train) / (len(Xy_refcv_val) + len(Xy_refcv_train)) * 100)}\",\n",
    "                # f\"\\t | Shape of X_train_if: {X_train_if.shape} and y_train_if: {y_train_if.shape}\",\n",
    "                # f\"\\t | Shape of X_val_if: {X_val_if.shape} and y_val_if: {y_val_if.shape}\",\n",
    "                end=\" | \",\n",
    "            )\n",
    "\n",
    "            # Fit model\n",
    "            print(f\"\\tFit model...\", end=\" \")\n",
    "            if user_input[\"make_classification\"]:\n",
    "                # CLASSIFICATION\n",
    "                rf = RandomForestClassifier(\n",
    "                    **best_params, random_state=seed_nr, n_jobs=-1\n",
    "                )\n",
    "                rf.fit(\n",
    "                    X_train_if,\n",
    "                    y_train_if,\n",
    "                )\n",
    "\n",
    "                # Get metrics on validation set\n",
    "                y_pred_val = rf.predict(X_val_if)\n",
    "                test_accuracy = accuracy_score(y_val_if, y_pred_val)\n",
    "                v_accuracy = v_accuracy + [test_accuracy]\n",
    "\n",
    "            else:\n",
    "                # REGRESSION\n",
    "                rf = RandomForestRegressor(\n",
    "                    **best_params, random_state=seed_nr, n_jobs=-1\n",
    "                )\n",
    "                rf.fit(\n",
    "                    X_train_if,\n",
    "                    y_train_if,\n",
    "                    sample_weight=get_weights_from_y(\n",
    "                        y_train_if, user_input[\"weight_method\"]\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                # Get metrics on validation set\n",
    "                y_pred_val = rf.predict(X_val_if)\n",
    "                v_r2 = v_r2 + [r2_score(y_val_if, y_pred_val)]\n",
    "                v_rmse = v_rmse + [np.sqrt(mean_squared_error(y_val_if, y_pred_val))]\n",
    "                v_mae = v_mae + [mean_absolute_error(y_val_if, y_pred_val)]\n",
    "\n",
    "            # --------------------------------------------------------\n",
    "            # End of fold\n",
    "            # --------------------------------------------------------\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # FEATURE IMPORTANCE\n",
    "        # --------------------------------------------------------\n",
    "        # Calculate feature importance\n",
    "        print(f\"\\n - Run model on full dataset...\", end=\"\")\n",
    "\n",
    "        # Fit Model on all data for feature importance\n",
    "        if user_input[\"make_classification\"]:\n",
    "            rf.fit(\n",
    "                Xy_refcv_train.drop(\n",
    "                    columns=[target, \"test_train_strata\"],\n",
    "                    errors=\"ignore\",\n",
    "                ),\n",
    "                Xy_refcv_train[target],\n",
    "            )\n",
    "        else:\n",
    "            rf.fit(\n",
    "                Xy_refcv_train.drop(\n",
    "                    columns=[target, \"test_train_strata\"],\n",
    "                    errors=\"ignore\",\n",
    "                ),\n",
    "                Xy_refcv_train[target],\n",
    "                sample_weight=get_weights_from_y(\n",
    "                    Xy_refcv_train[target], user_input[\"weight_method\"]\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        print(f\"\\n - Calculate feature importance...\\n\", end=\"\")\n",
    "        agg_vip = assessing_top_predictors(\n",
    "            rf_in=rf,\n",
    "            ignore_these=[target, \"test_train_strata\"],\n",
    "            X_train_in=Xy_refcv_train,\n",
    "            dict_ohe_in=var_ohe_dict,\n",
    "            with_aggregation=True,\n",
    "            n_predictors=20,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Set number of variables to remove\n",
    "        n_to_remove = features_to_remove_below30\n",
    "\n",
    "        if remaining_features_numbers > 30:\n",
    "            n_to_remove = features_to_remove_above30\n",
    "\n",
    "        if remaining_features_numbers > 50:\n",
    "            n_to_remove = features_to_remove_above50\n",
    "\n",
    "        if remaining_features_numbers > 100:\n",
    "            n_to_remove = features_to_remove_above100\n",
    "\n",
    "        if remaining_features_numbers > 200:\n",
    "            n_to_remove = features_to_remove_above200\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # VARIABLE REMOVAL\n",
    "        # TODO: Should we remove all sub-levels of an important aggregated variable or not?\n",
    "        # Get names and length of variables in their ohe form\n",
    "        new_ohe_vars_to_remove = agg_vip.tail(n_to_remove)[\"Vars_in_key\"].to_list()\n",
    "        # Unlist nested lists\n",
    "        new_ohe_vars_to_remove = [\n",
    "            item for sublist in new_ohe_vars_to_remove for item in sublist\n",
    "        ]\n",
    "        new_ohe_vars_to_remove_n = len(new_ohe_vars_to_remove)\n",
    "\n",
    "        # Add to list of variables to remove\n",
    "        ohe_vars_to_remove = new_ohe_vars_to_remove + ohe_vars_to_remove\n",
    "        ohe_vars_to_remove_n = len(ohe_vars_to_remove)\n",
    "\n",
    "        # Do the same for the non-ohe variable names\n",
    "        new_non_ohe_vars_to_remove = agg_vip.tail(n_to_remove)[\"Feature\"].to_list()\n",
    "        new_non_ohe_vars_to_remove_n = len(new_non_ohe_vars_to_remove)\n",
    "\n",
    "        # No unlisting needed\n",
    "        non_ohe_vars_to_remove = new_non_ohe_vars_to_remove + non_ohe_vars_to_remove\n",
    "        non_ohe_vars_to_remove_n = len(non_ohe_vars_to_remove)\n",
    "        # --------------------------------------------------------\n",
    "        # VARIABLE IN MODEL\n",
    "        ohe_vars_in_model = Xy_refcv_train.drop(\n",
    "            columns=[target, \"test_train_strata\"],\n",
    "            errors=\"ignore\",\n",
    "        ).columns.to_list()\n",
    "        ohe_vars_in_model_n = len(ohe_vars_in_model)\n",
    "\n",
    "        # Cross-check ohe_vars_in_model with the values in var_ohe_dict and return key if there is a match\n",
    "        non_ohe_vars_in_model = [\n",
    "            key\n",
    "            for key, value in var_ohe_dict.items()\n",
    "            if any(col in ohe_vars_in_model for col in value)\n",
    "        ]\n",
    "        non_ohe_vars_in_model = list(set(non_ohe_vars_in_model))\n",
    "        non_ohe_vars_in_model_n = len(non_ohe_vars_in_model)\n",
    "\n",
    "        print(\n",
    "            f\"\\n --- REMOVAL ---\",\n",
    "            f\"\\n - For one-hot-encoded variable names:\"\n",
    "            f\"\\n   - New variables to remove (ohe-encoded-names): {new_ohe_vars_to_remove_n}\\t|{new_ohe_vars_to_remove}\",\n",
    "            f\"\\n   - All variables to remove (ohe-encoded-names): {ohe_vars_to_remove_n}\\t|{ohe_vars_to_remove}\",\n",
    "            f\"\\n\\n - For original variable names:\",\n",
    "            f\"\\n   - New variables to remove (original-names): {new_non_ohe_vars_to_remove_n}\\t|{new_non_ohe_vars_to_remove}\",\n",
    "            f\"\\n   - All variables to remove (original-names): {non_ohe_vars_to_remove_n}\\t|{non_ohe_vars_to_remove}\",\n",
    "            f\"\\n\\n --- KEEPING ---\",\n",
    "            # f\"\\n\\n - Variables in model\",\n",
    "            f\"\\n   - ohe-encoded-names\\t{ohe_vars_in_model_n}\\t| {ohe_vars_in_model}\",\n",
    "            f\"\\n   - original-names\\t{non_ohe_vars_in_model_n}\\t| {non_ohe_vars_in_model}\",\n",
    "            f\"\\n\\n --- METRICS ---\",\n",
    "            f\"\\n   - r2: {round(np.mean(v_r2), 2)} (+- {round(np.std(v_r2), 2)})\",\n",
    "            f\" | rmse: {round(np.mean(v_rmse), 2)} (+- {round(np.std(v_rmse), 2)})\",\n",
    "            f\" | mae: {round(np.mean(v_mae), 2)} (+- {round(np.std(v_mae), 2)})\",\n",
    "            f\" | acc: {round(np.mean(v_accuracy), 2)} (+- {round(np.std(v_accuracy), 2)})\",\n",
    "        )\n",
    "\n",
    "        # Write to file\n",
    "        print(f\"\\n - Write info file...\\n\", end=\"\")\n",
    "        with open(f\"{current_dir}/refcv_log_removal.txt\", \"a\") as f:\n",
    "            f.write(\n",
    "                f\"\\n - Iteration {iteration_count} | {remaining_features_numbers}/{original_number_of_features} features in the model | Features removed:\"\n",
    "            )\n",
    "            for var in new_non_ohe_vars_to_remove:\n",
    "                f.write(f\"\\n\\t - {var}\")\n",
    "\n",
    "        with open(f\"{current_dir}/refcv_log_keeping.txt\", \"a\") as f:\n",
    "            f.write(\n",
    "                f\"\\n - Iteration {iteration_count} | {remaining_features_numbers}/{original_number_of_features} features in the model | Features kept:\"\n",
    "            )\n",
    "            for var in non_ohe_vars_in_model:\n",
    "                f.write(f\"\\n\\t - {var}\")\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Save to output\n",
    "        # --------------------------------------------------------\n",
    "        # Save rf metrics for current number of features\n",
    "\n",
    "        df_new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"n_features\": [remaining_features_numbers],\n",
    "                \"r2\": np.mean(v_r2),\n",
    "                \"r2_sd\": np.std(v_r2),\n",
    "                \"rmse\": np.mean(v_rmse),\n",
    "                \"rmse_sd\": np.std(v_rmse),\n",
    "                \"mae\": np.mean(v_mae),\n",
    "                \"mae_sd\": np.std(v_mae),\n",
    "                \"accuracy\": np.mean(v_accuracy),\n",
    "                \"accuracy_sd\": np.std(v_accuracy),\n",
    "                # Numbers\n",
    "                \"new_ohe_vars_to_remove_n\": new_ohe_vars_to_remove_n,\n",
    "                \"new_non_ohe_vars_to_remove_n\": new_non_ohe_vars_to_remove_n,\n",
    "                \"ohe_vars_to_remove_n\": ohe_vars_to_remove_n,\n",
    "                \"non_ohe_vars_to_remove_n\": non_ohe_vars_to_remove_n,\n",
    "                \"ohe_vars_in_model_n\": ohe_vars_in_model_n,\n",
    "                \"non_ohe_vars_in_model_n\": non_ohe_vars_in_model_n,\n",
    "                # Lists\n",
    "                \"new_ohe_vars_to_remove\": [new_ohe_vars_to_remove],\n",
    "                \"new_non_ohe_vars_to_remove\": [new_non_ohe_vars_to_remove],\n",
    "                \"ohe_vars_to_remove\": [ohe_vars_to_remove],\n",
    "                \"non_ohe_vars_to_remove\": [non_ohe_vars_to_remove],\n",
    "                \"ohe_vars_in_model\": [Xy_refcv_train.columns],\n",
    "                \"ohe_vars_in_model\": [ohe_vars_in_model],\n",
    "                \"non_ohe_vars_in_model\": [non_ohe_vars_in_model],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # display(df_new_row)\n",
    "\n",
    "        df_cvmetrics_per_nfeatures = pd.concat(\n",
    "            [df_cvmetrics_per_nfeatures, df_new_row], axis=0\n",
    "        )\n",
    "\n",
    "        iteration_count = iteration_count + 1\n",
    "\n",
    "        if debug_stop and iteration_count == debug_stop_after_n_iterations:\n",
    "            break\n",
    "    df_cvmetrics_per_nfeatures.to_csv(f\"{current_dir}/refcv_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_ref\"]:\n",
    "    # Get max number of features\n",
    "    x_max = df_cvmetrics_per_nfeatures[\"n_features\"].max()\n",
    "\n",
    "    if user_input[\"make_classification\"]:\n",
    "        # Start plotting\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(7, 3))\n",
    "        # PLOT: Accuracy ----------------------------------------------\n",
    "        # Get max accuracy\n",
    "        max_accuracy = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"accuracy\", ascending=False\n",
    "        )[\"accuracy\"].iloc[0]\n",
    "        # Get n_features at max accuracy\n",
    "        max_accuracy_features = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"accuracy\", ascending=False\n",
    "        ).iloc[0, 0]\n",
    "        axs.plot(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"],\n",
    "            df_cvmetrics_per_nfeatures[\"accuracy\"],\n",
    "        )\n",
    "        axs.fill_between(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"],\n",
    "            df_cvmetrics_per_nfeatures[\"accuracy\"]\n",
    "            - df_cvmetrics_per_nfeatures[\"accuracy_sd\"],\n",
    "            df_cvmetrics_per_nfeatures[\"accuracy\"]\n",
    "            + df_cvmetrics_per_nfeatures[\"accuracy_sd\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        axs.set_xlabel(\"Number of Features\")\n",
    "        axs.set_ylabel(\"Accuracy Score\")\n",
    "        axs.set_xlim(x_max, 0)\n",
    "        axs.set_ylim(0, (max_accuracy * 1.15))\n",
    "\n",
    "        # Add red vertical line for highest accuracy score\n",
    "        axs.axvline(x=max_accuracy_features, color=\"red\")\n",
    "\n",
    "        # Add text of max_accuracy_features to axs in red\n",
    "        axs.text(\n",
    "            x_max - 5,\n",
    "            max_accuracy * 0.1,\n",
    "            f\"Optimal Nr. of Features: {int(max_accuracy_features)} at Accuracy = {round(max_accuracy,2)}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "    else:\n",
    "        # Start plotting\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(7, 7))\n",
    "\n",
    "        # PLOT: R2 ----------------------------------------------\n",
    "        # Get max R2\n",
    "        max_r2 = df_cvmetrics_per_nfeatures.sort_values(by=\"r2\", ascending=False).iloc[\n",
    "            0, 1\n",
    "        ]\n",
    "        # Get n_features at max R2\n",
    "        max_r2_features = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"r2\", ascending=False\n",
    "        ).iloc[0, 0]\n",
    "        axs[0].plot(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"], df_cvmetrics_per_nfeatures[\"r2\"]\n",
    "        )\n",
    "        axs[0].fill_between(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"],\n",
    "            df_cvmetrics_per_nfeatures[\"r2\"] - df_cvmetrics_per_nfeatures[\"r2_sd\"],\n",
    "            df_cvmetrics_per_nfeatures[\"r2\"] + df_cvmetrics_per_nfeatures[\"r2_sd\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        axs[0].set_xlabel(\"Number of Features\")\n",
    "        axs[0].set_ylabel(\"R2 Score\")\n",
    "        axs[0].set_xlim(x_max, 0)\n",
    "        axs[0].set_ylim(0, (max_r2 + max_r2 * 0.1))\n",
    "\n",
    "        # Add red vertical line for highest R2 score\n",
    "        axs[0].axvline(x=max_r2_features, color=\"red\")\n",
    "\n",
    "        # Add text of max_r2_features to axs[0] in red\n",
    "        axs[0].text(\n",
    "            x_max - 5,\n",
    "            max_r2 * 0.1,\n",
    "            f\"Optimal Nr. of Features: {int(max_r2_features)} at R2 = {round(max_r2,2)}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "        # PLOT: RMSE ----------------------------------------------\n",
    "        # Get min rmse\n",
    "        min_rmse = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"rmse\", ascending=True\n",
    "        ).iloc[0, 3]\n",
    "        max_rmse = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"rmse\", ascending=False\n",
    "        ).iloc[0, 3]\n",
    "\n",
    "        # Get n_features at min rmse\n",
    "        min_rmse_features = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"rmse\", ascending=True\n",
    "        ).iloc[0, 0]\n",
    "\n",
    "        axs[1].plot(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"], df_cvmetrics_per_nfeatures[\"rmse\"]\n",
    "        )\n",
    "        axs[1].fill_between(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"],\n",
    "            df_cvmetrics_per_nfeatures[\"rmse\"] - df_cvmetrics_per_nfeatures[\"rmse_sd\"],\n",
    "            df_cvmetrics_per_nfeatures[\"rmse\"] + df_cvmetrics_per_nfeatures[\"rmse_sd\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        axs[1].set_xlabel(\"Number of Features\")\n",
    "        axs[1].set_ylabel(\"RMSE\")\n",
    "        axs[1].set_xlim(x_max, 0)\n",
    "        axs[1].set_ylim(0, (max_rmse + max_rmse * 0.1))\n",
    "\n",
    "        # Add red vertical line for lowest RMSE score\n",
    "        axs[1].axvline(x=min_rmse_features, color=\"red\")\n",
    "\n",
    "        # Add text\n",
    "        axs[1].text(\n",
    "            x_max - 5,\n",
    "            min_rmse * 0.1,\n",
    "            f\"Optimal Nr. of Features: {int(min_rmse_features)} at RMSE = {round(min_rmse,2)}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "        # PLOT: MAE ----------------------------------------------\n",
    "        min_mae = df_cvmetrics_per_nfeatures.sort_values(by=\"mae\", ascending=True).iloc[\n",
    "            0, 5\n",
    "        ]\n",
    "        max_mae = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"mae\", ascending=False\n",
    "        ).iloc[0, 5]\n",
    "        min_mae_features = df_cvmetrics_per_nfeatures.sort_values(\n",
    "            by=\"mae\", ascending=True\n",
    "        ).iloc[0, 0]\n",
    "\n",
    "        axs[2].plot(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"], df_cvmetrics_per_nfeatures[\"mae\"]\n",
    "        )\n",
    "        axs[2].fill_between(\n",
    "            df_cvmetrics_per_nfeatures[\"n_features\"],\n",
    "            df_cvmetrics_per_nfeatures[\"mae\"] - df_cvmetrics_per_nfeatures[\"mae_sd\"],\n",
    "            df_cvmetrics_per_nfeatures[\"mae\"] + df_cvmetrics_per_nfeatures[\"mae_sd\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        axs[2].set_xlabel(\"Number of Features\")\n",
    "        axs[2].set_ylabel(\"MAE\")\n",
    "        axs[2].set_xlim(x_max, 0)\n",
    "        axs[2].set_ylim(0, (max_mae + max_mae * 0.1))\n",
    "\n",
    "        # Add red vertical line for lowest RMSE score\n",
    "        axs[2].axvline(x=min_mae_features, color=\"red\")\n",
    "\n",
    "        # Add text\n",
    "        axs[2].text(\n",
    "            x_max - 5,\n",
    "            min_mae * 0.1,\n",
    "            f\"Optimal Nr. of Features: {int(min_mae_features)} at MAE = {round(min_mae,2)}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "\n",
    "    # LAYOUT\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{current_dir}/fig_refcv_results.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_ref\"]:\n",
    "    if user_input[\"make_classification\"]:\n",
    "        ohed_variables_in_best_model = (\n",
    "            df_cvmetrics_per_nfeatures.sort_values(by=\"accuracy\", ascending=False)\n",
    "            .head(1)[\"ohe_vars_in_model\"]\n",
    "            .values[0]\n",
    "        )\n",
    "        non_ohed_variables_in_best_model = (\n",
    "            df_cvmetrics_per_nfeatures.sort_values(by=\"accuracy\", ascending=False)\n",
    "            .head(1)[\"non_ohe_vars_in_model\"]\n",
    "            .values[0]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        ohed_variables_in_best_model = (\n",
    "            df_cvmetrics_per_nfeatures.sort_values(by=\"r2\", ascending=False)\n",
    "            .head(1)[\"ohe_vars_in_model\"]\n",
    "            .values[0]\n",
    "        )\n",
    "        non_ohed_variables_in_best_model = (\n",
    "            df_cvmetrics_per_nfeatures.sort_values(by=\"r2\", ascending=False)\n",
    "            .head(1)[\"non_ohe_vars_in_model\"]\n",
    "            .values[0]\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"Variables in best model (ohe): {ohed_variables_in_best_model}\",\n",
    "        f\"\\nVariables in best model (non-ohe): {non_ohed_variables_in_best_model}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If REF-CV was done, get the variables from the best model\n",
    "if user_input[\"do_ref\"]:\n",
    "    keep_these_vars = ohed_variables_in_best_model + [target, \"test_train_strata\"]\n",
    "\n",
    "    Xy_train_final = Xy_train_imputed.copy()[keep_these_vars]\n",
    "    Xy_test_final = Xy_test_imputed.copy()[keep_these_vars]\n",
    "else:\n",
    "    Xy_train_final = Xy_train_imputed.copy()\n",
    "    Xy_test_final = Xy_test_imputed.copy()\n",
    "\n",
    "# Make sure to remove stratification and target from X_train_final and X_test_final\n",
    "X_train_final = Xy_train_final.drop(columns=[target, \"test_train_strata\"])\n",
    "X_test_final = Xy_test_final.drop(columns=[target, \"test_train_strata\"])\n",
    "\n",
    "# Define y_train_final and y_test_final\n",
    "y_train_final = Xy_train_final[target]\n",
    "y_test_final = Xy_test_final[target]\n",
    "\n",
    "# Define Model\n",
    "if user_input[\"make_classification\"]:\n",
    "    # rf_best = RandomForestClassifier(**best_params, random_state=seed_nr, n_jobs=-1)\n",
    "    rf_best = RandomForestClassifier(**best_params, random_state=seed_nr, n_jobs=-1)\n",
    "    rf_best.fit(\n",
    "        X_train_final,\n",
    "        y_train_final,\n",
    "    )\n",
    "else:\n",
    "    rf_best = RandomForestRegressor(**best_params, random_state=seed_nr, n_jobs=-1)\n",
    "    rf_best.fit(\n",
    "        X_train_final,\n",
    "        y_train_final,\n",
    "        sample_weight=get_weights_from_y(y_train_final, user_input[\"weight_method\"]),\n",
    "    )\n",
    "\n",
    "display(rf_best)\n",
    "\n",
    "# Create Modobs\n",
    "\n",
    "if user_input[\"make_classification\"]:\n",
    "    model_evaluation_classification(\n",
    "        rf_best,\n",
    "        X_train_final,\n",
    "        y_train_final,\n",
    "        X_test_final,\n",
    "        y_test_final,\n",
    "        save_directory=current_dir,\n",
    "    )\n",
    "else:\n",
    "    model_evaluation_regression(\n",
    "        rf_best,\n",
    "        X_train_final,\n",
    "        y_train_final,\n",
    "        X_test_final,\n",
    "        y_test_final,\n",
    "        save_directory=current_dir,\n",
    "    )\n",
    "\n",
    "# Save model information\n",
    "filename = f\"{current_dir}/model_information.txt\"\n",
    "with open(filename, \"w\") as file:\n",
    "    file.write(f\"Model Information\")\n",
    "    file.write(\n",
    "        f\"\\n\\nModel Type: {'Classification' if user_input['make_classification'] else 'Regression'}\"\n",
    "    )\n",
    "    file.write(f\"\\n\\nShape of Train and Test Data:\")\n",
    "    file.write(f\"\\n - X train: {X_train_final.shape}\")\n",
    "    file.write(f\"\\n - y train: {y_train_final.shape}\")\n",
    "    file.write(f\"\\n - X test: {X_test_final.shape}\")\n",
    "    file.write(f\"\\n - y test: {y_test_final.shape}\")\n",
    "    file.write(f\"\\n\\nModel Parameters:\")\n",
    "    for key, value in best_params.items():\n",
    "        file.write(f\"\\n - {key}: {value}\")\n",
    "    file.write(f\"\\n\\nModel Features:\\n\\n\")\n",
    "    for var in X_train_final.columns:\n",
    "        file.write(f\" - {var}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input[\"do_ref\"]:\n",
    "    show_top_n = min(20, int(max_r2_features))\n",
    "else:\n",
    "    show_top_n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_top_predictors(X_train_fin, vars_to_ohe, rf_best, with_aggregation=False)\n",
    "df_featimp_noagg = assessing_top_predictors(\n",
    "    rf_in=rf_best,\n",
    "    ignore_these=[target, \"test_train_strata\"],\n",
    "    X_train_in=X_train_final,\n",
    "    dict_ohe_in=var_ohe_dict,\n",
    "    with_aggregation=False,\n",
    "    n_predictors=show_top_n,\n",
    "    verbose=True,\n",
    "    save_directory=current_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_top_predictors(X_train_fin, vars_to_ohe, rf_best, with_aggregation=True)\n",
    "df_featimp_withagg = assessing_top_predictors(\n",
    "    rf_in=rf_best,\n",
    "    ignore_these=[target, \"test_train_strata\"],\n",
    "    X_train_in=X_train_final,\n",
    "    dict_ohe_in=var_ohe_dict,\n",
    "    with_aggregation=True,\n",
    "    n_predictors=show_top_n,\n",
    "    verbose=True,\n",
    "    save_directory=current_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chime.success()\n",
    "# raise SystemExit(\"STOP! You reached the end of the script. ‚úã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots\n",
    "\n",
    "Improvements:\n",
    "\n",
    "- Only select top 9 to have nicer grid\n",
    "- Set common y-axis to have comparable scale (just take max of all) but may not apply to categorical variables that go in two directions! So needs smarter solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get levels in y_test_final\n",
    "if user_input[\"make_classification\"]:\n",
    "    y_test_final_levels = sorted(y_test_final.unique())\n",
    "    print(y_test_final_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PDP for the top n variables\n",
    "# Get top n variables\n",
    "n_pdps = 9\n",
    "top_vars_pdp_ohed = df_featimp_withagg.head(n_pdps)[\"Vars_in_key\"].to_list()\n",
    "top_vars_pdp_ohed = [item for sublist in top_vars_pdp_ohed for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelise predictions\n",
    "list_pdps = run_mp(\n",
    "    pdp_mp_wrapper,\n",
    "    y_test_final_levels,\n",
    "    combine_func=None,\n",
    "    num_cores=min(len(y_test_final_levels), 9),\n",
    "    progress_bar=True,\n",
    "    estimator=rf_best,\n",
    "    X=X_train_final,\n",
    "    features=top_vars_pdp_ohed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pdp_mp_wrapper(target, **kwargs):\n",
    "#     return PartialDependenceDisplay.from_estimator(target=target, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdp_subplots(ax, df_in, var_name, var_type, ymax=None):\n",
    "    if var_type == \"categorical\":\n",
    "        df = df_in[df_in[\"non_ohed_var\"] == var_name].copy()\n",
    "        pivot_df = df.pivot(index=\"ohed_var\", columns=\"x_values\", values=\"y_values\")\n",
    "        pivot_df[\"difference\"] = pivot_df[1] - pivot_df[0]\n",
    "\n",
    "        # Plot on the provided axis\n",
    "        ax.bar(pivot_df.index, pivot_df[\"difference\"])\n",
    "\n",
    "        ax.set_xlabel(f\"Levels in {var_name}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=6)\n",
    "        ax.set_ylabel(\"Difference in Y\")\n",
    "        if ymax is not None:\n",
    "            ax.axhline(0, linestyle=\"dotted\", color=\"gray\")\n",
    "            ax.set_ylim(-ymax * 1.2, ymax * 1.2)\n",
    "        ax.set_title(f\"{var_name}\")\n",
    "\n",
    "    else:\n",
    "        df_tmp = df_in[df_in[\"non_ohed_var\"] == var_name].copy()\n",
    "        df_tmp[\"x_values\"] = df_tmp[\"x_values\"].astype(float)\n",
    "\n",
    "        # Plot on the provided axis\n",
    "        ax.plot(df_tmp[\"x_values\"], df_tmp[\"y_values\"])\n",
    "        ax.set_xlabel(var_name)\n",
    "        ax.set_ylabel(\"Partial Dependence\")\n",
    "        if ymax is not None:\n",
    "            ax.axhline(0, linestyle=\"dotted\", color=\"gray\")\n",
    "            ax.set_ylim(-ymax * 1.2, ymax * 1.2)\n",
    "        ax.set_title(f\"{var_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregated_pdp(my_pdp, top_vars_pdp_ohed, var_ohe_dict, ymax=None):\n",
    "    # Get dictionary ------------------------------------------------------------------------\n",
    "    # Reduce var_ohe_dict to hold only keys where a value in the key is in top_vars_pdp_ohed\n",
    "    var_ohe_dict_reduced = {\n",
    "        key: value\n",
    "        for key, value in var_ohe_dict.items()\n",
    "        if any(col in top_vars_pdp_ohed for col in value)\n",
    "    }\n",
    "\n",
    "    # Flip dict for easier handling\n",
    "    dict_flipd = {\n",
    "        ohe: orig for orig, ohe_list in var_ohe_dict_reduced.items() for ohe in ohe_list\n",
    "    }\n",
    "\n",
    "    # Extract data from PDP object ------------------------------------------------------------\n",
    "    final_df = pd.DataFrame(\n",
    "        {\n",
    "            \"ohed_var\": [],\n",
    "            \"non_ohed_var\": [],\n",
    "            \"y_values\": [],\n",
    "            \"x_values\": [],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i in range(len(top_vars_pdp_ohed)):\n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                \"ohed_var\": top_vars_pdp_ohed[i],\n",
    "                \"non_ohed_var\": dict_flipd[top_vars_pdp_ohed[i]],\n",
    "                \"y_values\": my_pdp.pd_results[i][\"average\"][0].tolist(),\n",
    "                \"x_values\": my_pdp.pd_results[i][\"values\"][0].tolist(),\n",
    "            }\n",
    "        )\n",
    "        # Append new row to final_df\n",
    "        final_df = pd.concat([final_df, new_row], axis=0)\n",
    "\n",
    "    max_effect = np.max(final_df[\"y_values\"])\n",
    "    if ymax is None:\n",
    "        max_effect = None\n",
    "    df_groups = final_df.groupby(\"non_ohed_var\")\n",
    "\n",
    "    # Plot PDPs --------------------------------------------------------------------------------\n",
    "    # Create a figure with m rows x n columns of subplots\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 10))  # Adjust the figure size as needed\n",
    "    axs = axs.flatten()  # Flatten the array to easily iterate over it\n",
    "\n",
    "    # Iterate over groups and plot\n",
    "    ax_idx = 0\n",
    "    for name, group in df_groups:\n",
    "        if len(var_ohe_dict_reduced[name]) > 1:\n",
    "            # Make barplot\n",
    "            make_pdp_subplots(\n",
    "                ax=axs[ax_idx],\n",
    "                df_in=group,\n",
    "                var_name=name,\n",
    "                var_type=\"categorical\",\n",
    "                ymax=max_effect,\n",
    "            )\n",
    "        else:\n",
    "            # Make lineplot\n",
    "            make_pdp_subplots(\n",
    "                ax=axs[ax_idx],\n",
    "                df_in=group,\n",
    "                var_name=name,\n",
    "                var_type=\"numerical\",\n",
    "                ymax=max_effect,\n",
    "            )\n",
    "        ax_idx += 1\n",
    "        if ax_idx == 10:  # Stop plotting after 10 plots\n",
    "            break\n",
    "\n",
    "    # Turn off the last two axes\n",
    "    for ax in axs[10:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_pdps)):\n",
    "    display(f\"PDP for {y_test_final_levels[i]}\")\n",
    "    plot_aggregated_pdp(list_pdps[i], top_vars_pdp_ohed, var_ohe_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PDP for the top n variables\n",
    "# Get top n variables\n",
    "n_pdps = 9\n",
    "top_vars_pdp_ohed = df_featimp_withagg.head(n_pdps)[\"Vars_in_key\"].to_list()\n",
    "top_vars_pdp_ohed = [item for sublist in top_vars_pdp_ohed for item in sublist]\n",
    "\n",
    "# fig, axs = plt.subplots(figsize=(20, n_pdps * 15))\n",
    "fig, axs = plt.subplots(figsize=(15, 15))\n",
    "my_pdp = PartialDependenceDisplay.from_estimator(\n",
    "    rf_best,\n",
    "    X_train_final,\n",
    "    top_vars_pdp_ohed,\n",
    "    # sample_weight=get_weights_from_y(y_train_final, user_input[\"weight_method\"]),\n",
    "    n_cols=5,\n",
    "    # n_jobs=-1, # Adding this, slows down the process a lot...\n",
    "    ax=axs,\n",
    "    target=\"0-33%\",\n",
    ")\n",
    "\n",
    "print(f\"Top {n_pdps} variables for PDPs (ohe): {top_vars_pdp_ohed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce var_ohe_dict to hold only keys where a value in the key is in top_vars_pdp_ohed\n",
    "var_ohe_dict_reduced = {\n",
    "    key: value\n",
    "    for key, value in var_ohe_dict.items()\n",
    "    if any(col in top_vars_pdp_ohed for col in value)\n",
    "}\n",
    "# Flip dict for easier handling\n",
    "dict_flipd = {\n",
    "    ohe: orig for orig, ohe_list in var_ohe_dict_reduced.items() for ohe in ohe_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from PDP object\n",
    "final_df = pd.DataFrame(\n",
    "    {\n",
    "        \"ohed_var\": [],\n",
    "        \"non_ohed_var\": [],\n",
    "        \"y_values\": [],\n",
    "        \"x_values\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "for i in range(len(top_vars_pdp_ohed)):\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"ohed_var\": top_vars_pdp_ohed[i],\n",
    "            \"non_ohed_var\": dict_flipd[top_vars_pdp_ohed[i]],\n",
    "            \"y_values\": my_pdp.pd_results[i][\"average\"][0].tolist(),\n",
    "            \"x_values\": my_pdp.pd_results[i][\"values\"][0].tolist(),\n",
    "        }\n",
    "    )\n",
    "    # Append new row to final_df\n",
    "    final_df = pd.concat([final_df, new_row], axis=0)\n",
    "\n",
    "\n",
    "# Attach importance to sort and make sure the plotting order follows the importance\n",
    "# final_df = (\n",
    "#     pd.merge(\n",
    "#         final_df,\n",
    "#         df_featimp_withagg.rename(columns={\"Feature\": \"non_ohed_var\"})[\n",
    "#             [\"non_ohed_var\", \"Importance\"]\n",
    "#         ],\n",
    "#         on=\"non_ohed_var\",\n",
    "#         how=\"left\",\n",
    "#     )\n",
    "#     .sort_values(by=\"Importance\", ascending=False)\n",
    "#     .drop(columns=\"Importance\")\n",
    "# )\n",
    "\n",
    "max_effect = np.max(final_df[\"y_values\"])\n",
    "df_groups = final_df.groupby(\"non_ohed_var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with m rows x n columns of subplots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))  # Adjust the figure size as needed\n",
    "axs = axs.flatten()  # Flatten the array to easily iterate over it\n",
    "\n",
    "# Iterate over groups and plot\n",
    "ax_idx = 0\n",
    "for name, group in df_groups:\n",
    "    if len(var_ohe_dict_reduced[name]) > 1:\n",
    "        # Make barplot\n",
    "        make_pdp_subplots(\n",
    "            ax=axs[ax_idx], df_in=group, var_name=name, var_type=\"categorical\"\n",
    "        )\n",
    "    else:\n",
    "        # Make lineplot\n",
    "        make_pdp_subplots(\n",
    "            ax=axs[ax_idx], df_in=group, var_name=name, var_type=\"numerical\"\n",
    "        )\n",
    "    ax_idx += 1\n",
    "    if ax_idx == 10:  # Stop plotting after 10 plots\n",
    "        break\n",
    "\n",
    "# Turn off the last two axes\n",
    "for ax in axs[10:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chime.success()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Pickle model\n",
    "# with open(f\"{current_dir}/final_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(rf_best, f)\n",
    "\n",
    "# # Pickle test data\n",
    "# with open(f\"{current_dir}/X_test.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(X_test, f)\n",
    "\n",
    "# with open(f\"{current_dir}/y_test.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(y_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifna-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
